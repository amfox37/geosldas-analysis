{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54fe27b-0c64-45d8-aa97-ab32db88b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from mapper_functions import plot_global_tight_pcm, plot_global_tight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252ee9a-3ac2-4723-bc9c-6ef8e0922e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'LS_DAv8_M36'\n",
    "\n",
    "start_date = datetime(2000, 6, 1)\n",
    "end_date = datetime(2003, 6, 1)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y%m%d')\n",
    "end_date_str = end_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbc728-ae57-401d-9794-4538488447c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the netCDF file\n",
    "file_path = f'/discover/nobackup/amfox/Experiments/M21C_land_sweeper_DAv8_M36/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg/Y2001/M02/{expt_name}.catch_progn_incr.20010202.nc4'\n",
    "\n",
    "# Open the netCDF file\n",
    "dataset = xr.open_dataset(file_path)\n",
    "\n",
    "# Extract the lon and lat variables\n",
    "lon = dataset['lon']\n",
    "lat = dataset['lat']\n",
    "\n",
    "# Print the dimensions of the variables\n",
    "print(f\"Dimensions of lon: {lon.shape}\")\n",
    "print(f\"Dimensions of lat: {lat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513aeb91-2265-408c-a5ea-e52cefa83c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open each of the saved files\n",
    "\n",
    "#data_2015 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2015.npz', allow_pickle=True)\n",
    "#data_2016 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2016.npz', allow_pickle=True)\n",
    "#data_2017 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2017.npz', allow_pickle=True)\n",
    "#data_2018 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2018.npz', allow_pickle=True)\n",
    "#data_2019 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2019.npz', allow_pickle=True)\n",
    "#data_2020 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2020.npz', allow_pickle=True)\n",
    "data_2000 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2000.npz', allow_pickle=True)\n",
    "data_2001 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2001.npz', allow_pickle=True)\n",
    "data_2002 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2002.npz', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a04fe4-3702-4da2-ab6e-8b826a541c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and combine the data from each of the files\n",
    "date_time = np.concatenate((data_2000['date_time'], data_2001['date_time'], data_2002['date_time']))\n",
    "obs_species = np.concatenate((data_2000['obs_species'], data_2001['obs_species'], data_2002['obs_species']))\n",
    "obs_tilenum = np.concatenate((data_2000['obs_tilenum'], data_2001['obs_tilenum'], data_2002['obs_tilenum']))\n",
    "obs_lon = np.concatenate((data_2000['obs_lon'], data_2001['obs_lon'], data_2002['obs_lon']))\n",
    "obs_lat = np.concatenate((data_2000['obs_lat'], data_2001['obs_lat'], data_2002['obs_lat']))\n",
    "obs_obs = np.concatenate((data_2000['obs_obs'], data_2001['obs_obs'], data_2002['obs_obs']))\n",
    "obs_fcst = np.concatenate((data_2000['obs_fcst'], data_2001['obs_fcst'], data_2002['obs_fcst']))\n",
    "obs_ana = np.concatenate((data_2000['obs_ana'], data_2001['obs_ana'], data_2002['obs_ana']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbaf13-abe8-4c22-9371-1f4ece9d1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate obs minus fcst\n",
    "obs_minus_fcst = []\n",
    "obs_minus_ana = []\n",
    "for i in range(len(obs_obs)):\n",
    "    obs_minus_fcst_chunk = obs_obs[i] - obs_fcst[i]\n",
    "    obs_minus_fcst.append(obs_minus_fcst_chunk)\n",
    "    obs_minus_ana_chunk = obs_obs[i] - obs_ana[i]\n",
    "    obs_minus_ana.append(obs_minus_ana_chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973b55d0-ec23-4a42-9661-ea49dc2739d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to numpy arrays\n",
    "obs_minus_fcst = np.array(obs_minus_fcst)\n",
    "obs_minus_ana = np.array(obs_minus_ana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c08734-e507-4a4c-a815-4bc811886d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique tilenum values\n",
    "unique_tilenum = np.unique(obs_tilenum)\n",
    "\n",
    "# Find the number of unique tilenum values\n",
    "num_unique_tilenum = len(unique_tilenum)\n",
    "\n",
    "# Print the number of unique tilenum values\n",
    "print(f\"Number of unique tilenum values: {num_unique_tilenum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074bab8c-7585-4ee8-a365-8061c2959e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the arrays based on obs_tilenum\n",
    "sort_indices = np.argsort(obs_tilenum)\n",
    "sorted_obs_tilenum = obs_tilenum[sort_indices]\n",
    "sorted_obs_species = obs_species[sort_indices]\n",
    "sorted_obs_obs = obs_obs[sort_indices]\n",
    "sorted_obs_fcst = obs_fcst[sort_indices]\n",
    "sorted_obs_ana = obs_ana[sort_indices]\n",
    "sorted_obs_minus_fcst = obs_minus_fcst[sort_indices]\n",
    "sorted_obs_minus_ana = obs_minus_ana[sort_indices]\n",
    "sorted_date_time = date_time[sort_indices]\n",
    "\n",
    "# Find the unique tilenum values and their counts\n",
    "unique_tilenum, counts = np.unique(sorted_obs_tilenum, return_counts=True)\n",
    "\n",
    "# Calculate the indices where the groups should be split\n",
    "split_indices = np.cumsum(counts)[:-1]\n",
    "\n",
    "# Split the sorted arrays based on the split indices\n",
    "obs_species_grouped = np.split(sorted_obs_species, split_indices)\n",
    "obs_obs_grouped = np.split(sorted_obs_obs, split_indices)\n",
    "obs_fcst_grouped = np.split(sorted_obs_fcst, split_indices)\n",
    "obs_ana_grouped = np.split(sorted_obs_ana, split_indices)\n",
    "obs_minus_fcst_grouped = np.split(sorted_obs_minus_fcst, split_indices)\n",
    "obs_minus_ana_grouped = np.split(sorted_obs_minus_ana, split_indices)\n",
    "date_time_grouped = np.split(sorted_date_time, split_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082d1ef-770b-46fe-bb62-997bb9fcd11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the length of obs_obs_grouped\n",
    "print(f\"Length of obs_obs_grouped: {len(obs_obs_grouped)}\")\n",
    "\n",
    "# Print the number of unique obs_species values\n",
    "unique_species = np.unique(sorted_obs_species)\n",
    "num_unique_species = len(unique_species)\n",
    "print(f\"Number of unique species: {num_unique_species}\")\n",
    "print(f\"Unique species: {unique_species}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366362a4-ba8c-4b8b-acbf-0155d5edd2db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you have a multi-sensor experiment\n",
    "\n",
    "# Find the number of observations for each tilenum\n",
    "num_obs_smos = []\n",
    "num_obs_smap = []\n",
    "num_obs_ascat = []\n",
    "num_obs_snow = []\n",
    "\n",
    "for i in range(num_unique_tilenum):\n",
    "    num_obs_smos.append(len(obs_obs_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    num_obs_smap.append(len(obs_obs_grouped[i][np.logical_and(obs_species_grouped[i] > 4, obs_species_grouped[i] < 9)]))\n",
    "    num_obs_ascat.append(len(obs_obs_grouped[i][np.logical_and(obs_species_grouped[i] > 8, obs_species_grouped[i] < 12)]))\n",
    "    num_obs_snow.append(len(obs_obs_grouped[i][obs_species_grouped[i] > 11]))\n",
    "        \n",
    "#Calculate the mean of the observations for each tilenum\n",
    "mean_obs_smos = []\n",
    "mean_obs_smap = []\n",
    "mean_obs_ascat = []\n",
    "mean_obs_snow = []\n",
    "\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_smos.append(np.mean(obs_obs_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    mean_obs_smap.append(np.mean(obs_obs_grouped[i][np.logical_and(obs_species_grouped[i] > 4, obs_species_grouped[i] < 9)]))\n",
    "    mean_obs_ascat.append(np.mean(obs_obs_grouped[i][np.logical_and(obs_species_grouped[i] > 8, obs_species_grouped[i] < 12)]))\n",
    "    mean_obs_snow.append(np.mean(obs_obs_grouped[i][obs_species_grouped[i] > 11]))\n",
    "\n",
    "# Calculate the max of the snow obs, fcst, and ana for each tilenum\n",
    "max_obs_snow = []\n",
    "max_fcst_snow = []\n",
    "max_ana_snow = []\n",
    "\n",
    "for i in range(num_unique_tilenum):\n",
    "    obs_snow = obs_obs_grouped[i][obs_species_grouped[i] > 11]\n",
    "    fcst_snow = obs_fcst_grouped[i][obs_species_grouped[i] > 11]\n",
    "    ana_snow = obs_ana_grouped[i][obs_species_grouped[i] > 11]\n",
    "    \n",
    "    if obs_snow.size > 0:\n",
    "        max_obs_snow.append(np.max(obs_snow))\n",
    "    else:\n",
    "        max_obs_snow.append(np.nan)\n",
    "    \n",
    "    if fcst_snow.size > 0:\n",
    "        max_fcst_snow.append(np.max(fcst_snow))\n",
    "    else:\n",
    "        max_fcst_snow.append(np.nan)\n",
    "    \n",
    "    if ana_snow.size > 0:\n",
    "        max_ana_snow.append(np.max(ana_snow))\n",
    "    else:\n",
    "        max_ana_snow.append(np.nan)\n",
    "\n",
    "# Calculate the mean of the forecasts for each tilenum\n",
    "mean_fcst_smos = []\n",
    "mean_fcst_smap = []\n",
    "mean_fcst_ascat = []\n",
    "mean_fcst_snow = []\n",
    "\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_fcst_smos.append(np.mean(obs_fcst_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    mean_fcst_smap.append(np.mean(obs_fcst_grouped[i][np.logical_and(obs_species_grouped[i] > 4, obs_species_grouped[i] < 9)]))\n",
    "    mean_fcst_ascat.append(np.mean(obs_fcst_grouped[i][np.logical_and(obs_species_grouped[i] > 8, obs_species_grouped[i] < 12)]))\n",
    "    mean_fcst_snow.append(np.mean(obs_fcst_grouped[i][obs_species_grouped[i] > 11]))\n",
    "\n",
    "# Calculate the mean of the analyses for each tilenum\n",
    "mean_ana_smos = []\n",
    "mean_ana_smap = []\n",
    "mean_ana_ascat = []\n",
    "mean_ana_snow = []\n",
    "\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_ana_smos.append(np.mean(obs_ana_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    mean_ana_smap.append(np.mean(obs_ana_grouped[i][np.logical_and(obs_species_grouped[i] > 4, obs_species_grouped[i] < 9)]))\n",
    "    mean_ana_ascat.append(np.mean(obs_ana_grouped[i][np.logical_and(obs_species_grouped[i] > 8, obs_species_grouped[i] < 12)]))\n",
    "    mean_ana_snow.append(np.mean(obs_ana_grouped[i][obs_species_grouped[i] > 11]))\n",
    "\n",
    "# Calculate the mean of the obs minus fcst for each tilenum\n",
    "mean_obs_minus_fcst_smos = []\n",
    "mean_obs_minus_fcst_smap = []\n",
    "mean_obs_minus_fcst_ascat = []\n",
    "mean_obs_minus_fcst_snow = []\n",
    "\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_minus_fcst_smos.append(np.mean(obs_minus_fcst_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    mean_obs_minus_fcst_smap.append(np.mean(obs_minus_fcst_grouped[i][np.logical_and(obs_species_grouped[i] > 4, obs_species_grouped[i] < 9)]))\n",
    "    mean_obs_minus_fcst_ascat.append(np.mean(obs_minus_fcst_grouped[i][np.logical_and(obs_species_grouped[i] > 8, obs_species_grouped[i] < 12)]))\n",
    "    mean_obs_minus_fcst_snow.append(np.mean(obs_minus_fcst_grouped[i][obs_species_grouped[i] > 11]))\n",
    "\n",
    "# Calculate the mean of the obs minus ana for each tilenum\n",
    "mean_obs_minus_ana_smos = []\n",
    "mean_obs_minus_ana_smap = []\n",
    "mean_obs_minus_ana_ascat = []\n",
    "mean_obs_minus_ana_snow = []\n",
    "\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_minus_ana_smos.append(np.mean(obs_minus_ana_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    mean_obs_minus_ana_smap.append(np.mean(obs_minus_ana_grouped[i][np.logical_and(obs_species_grouped[i] > 4, obs_species_grouped[i] < 9)]))\n",
    "    mean_obs_minus_ana_ascat.append(np.mean(obs_minus_ana_grouped[i][np.logical_and(obs_species_grouped[i] > 8, obs_species_grouped[i] < 12)]))\n",
    "    mean_obs_minus_ana_snow.append(np.mean(obs_minus_ana_grouped[i][obs_species_grouped[i] > 11]))\n",
    "\n",
    "# Calculate the standard deviation of the obs_minus_fcst for each tilenum\n",
    "std_obs_minus_fcst_smos = []\n",
    "std_obs_minus_fcst_smap = []\n",
    "std_obs_minus_fcst_ascat = []\n",
    "std_obs_minus_fcst_snow = []\n",
    "\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_minus_fcst_smos.append(np.std(obs_minus_fcst_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    std_obs_minus_fcst_smap.append(np.std(obs_minus_fcst_grouped[i][np.logical_and(obs_species_grouped[i] > 4, obs_species_grouped[i] < 9)]))\n",
    "    std_obs_minus_fcst_ascat.append(np.std(obs_minus_fcst_grouped[i][np.logical_and(obs_species_grouped[i] > 8, obs_species_grouped[i] < 12)]))\n",
    "    std_obs_minus_fcst_snow.append(np.std(obs_minus_fcst_grouped[i][obs_species_grouped[i] > 11]))\n",
    "\n",
    "# Calculate the standard deviation of the obs_minus_ana for each tilenum\n",
    "std_obs_minus_ana_smos = []\n",
    "std_obs_minus_ana_smap = []\n",
    "std_obs_minus_ana_ascat = []\n",
    "std_obs_minus_ana_snow = []\n",
    "\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_minus_ana_smos.append(np.std(obs_minus_ana_grouped[i][obs_species_grouped[i] < 5]))\n",
    "    std_obs_minus_ana_smap.append(np.std(obs_minus_ana_grouped[i][np.logical_and(obs_species_grouped[i] > 4, obs_species_grouped[i] < 9)]))\n",
    "    std_obs_minus_ana_ascat.append(np.std(obs_minus_ana_grouped[i][np.logical_and(obs_species_grouped[i] > 8, obs_species_grouped[i] < 12)]))\n",
    "    std_obs_minus_ana_snow.append(np.std(obs_minus_ana_grouped[i][obs_species_grouped[i] > 11]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afec282b-5dd0-417c-a6aa-32f0d5e54a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign lon and lat to each tilenum\n",
    "lon_tilenum = []\n",
    "lat_tilenum = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    lon_tilenum.append(lon[int(unique_tilenum[i])])\n",
    "    lat_tilenum.append(lat[int(unique_tilenum[i])])\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "lon_tilenum = np.array(lon_tilenum)\n",
    "lat_tilenum = np.array(lat_tilenum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cffaab8a-e552-4534-a281-5d7dcf1a4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you have a multi-sensor experiment\n",
    "# Save all the calculated values to a file\n",
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_stats.npz',\n",
    "         unique_tilenum=unique_tilenum,\n",
    "         num_obs_smos=num_obs_smos,\n",
    "         num_obs_smap=num_obs_smap,\n",
    "         num_obs_ascat=num_obs_ascat,\n",
    "         num_obs_snow=num_obs_snow,\n",
    "         mean_obs_smos=mean_obs_smos,\n",
    "         mean_obs_smap=mean_obs_smap,\n",
    "         mean_obs_ascat=mean_obs_ascat,\n",
    "         mean_obs_snow=mean_obs_snow,\n",
    "         mean_fcst_smos=mean_fcst_smos,\n",
    "         mean_fcst_smap=mean_fcst_smap,\n",
    "         mean_fcst_ascat=mean_fcst_ascat,\n",
    "         mean_fcst_snow=mean_fcst_snow,\n",
    "         mean_ana_smos=mean_ana_smos,\n",
    "         mean_ana_smap=mean_ana_smap,\n",
    "         mean_ana_ascat=mean_ana_ascat,\n",
    "         mean_ana_snow=mean_ana_snow,\n",
    "         mean_obs_minus_fcst_smos=mean_obs_minus_fcst_smos,\n",
    "         mean_obs_minus_fcst_smap=mean_obs_minus_fcst_smap,\n",
    "         mean_obs_minus_fcst_ascat=mean_obs_minus_fcst_ascat,\n",
    "         mean_obs_minus_fcst_snow=mean_obs_minus_fcst_snow,\n",
    "         mean_obs_minus_ana_smos=mean_obs_minus_ana_smos,\n",
    "         mean_obs_minus_ana_smap=mean_obs_minus_ana_smap,\n",
    "         mean_obs_minus_ana_ascat=mean_obs_minus_ana_ascat,\n",
    "         mean_obs_minus_ana_snow=mean_obs_minus_ana_snow,\n",
    "         std_obs_minus_fcst_smos=std_obs_minus_fcst_smos,\n",
    "         std_obs_minus_fcst_smap=std_obs_minus_fcst_smap,\n",
    "         std_obs_minus_fcst_ascat=std_obs_minus_fcst_ascat,\n",
    "         std_obs_minus_fcst_snow=std_obs_minus_fcst_snow,\n",
    "         std_obs_minus_ana_smos=std_obs_minus_ana_smos\n",
    "         std_obs_minus_ana_smap=std_obs_minus_ana_smap,\n",
    "         std_obs_minus_ana_ascat=std_obs_minus_ana_ascat,\n",
    "         std_obs_minus_ana_snow=std_obs_minus_ana_snow,\n",
    "         max_obs_snow=max_obs_snow,\n",
    "         max_fcst_snow=max_fcst_snow,\n",
    "         max_ana_snow=max_ana_snow,\n",
    "         lon_tilenum=lon_tilenum,\n",
    "         lat_tilenum=lat_tilenum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaab4cd-2ad8-479b-8be1-b3055888b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_array = num_obs_snow\n",
    "test_array = np.array(test_array)\n",
    "#test_array[test_array < 1] = -999\n",
    "    \n",
    "obarray = np.empty([num_unique_tilenum, 3])\n",
    "obarray[:, 1] = lon_tilenum\n",
    "obarray[:, 2] = lat_tilenum\n",
    "obarray[:, 0] = test_array\n",
    "   \n",
    "plot_global_tight_pcm(obarray,False, True,'Number of snow Obs Assimilated','Total',0,300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ed649-64e9-4e08-a94a-b57155a14c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diag]",
   "language": "python",
   "name": "conda-env-.conda-diag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
