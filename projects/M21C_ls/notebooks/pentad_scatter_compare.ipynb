{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "365a02df",
   "metadata": {},
   "source": [
    "# Pentad scatter comparison\n",
    "\n",
    "This notebook compares two land-sweeper z-score statistic files by plotting scatter comparisons for five key variables (`o_mean`, `o_std`, `m_mean`, `m_std`, `n_data`). For ten randomly selected pentads we draw location-wise scatter plots contrasting the two datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c2dcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from geospatial_plotting import plot_region, REGION_BOUNDS\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd3f356",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = Path('../test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/stats')\n",
    "file_dedup = base_dir / 'M36_dedup_zscore_stats_2007_doy152_2024_doy151_W_75d_Nmin_20_sp_ALL_all_pentads.nc4'\n",
    "file_full = base_dir / 'M36_zscore_stats_2007_doy152_2024_doy90_W_75d_Nmin_20_sp_ALL_all_pentads.nc4'\n",
    "# file_full = base_dir / 'M36_python_dedup_zscore_stats_2007_doy152_2024_doy151_W_75d_Nmin_20_sp_ALL_all_pentads.nc4'\n",
    "file_dedup, file_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efa3f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_dedup = xr.open_dataset(file_dedup)\n",
    "ds_full = xr.open_dataset(file_full)\n",
    "ds_dedup, ds_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb78f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "dims_dedup = {name: ds_dedup.dims[name] for name in ds_dedup.dims}\n",
    "dims_full = {name: ds_full.dims[name] for name in ds_full.dims}\n",
    "dims_dedup, dims_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3cafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vars_to_compare = ['o_mean', 'o_std', 'm_mean', 'm_std', 'n_data']\n",
    "common_pentads = np.intersect1d(ds_dedup['pentad'].values, ds_full['pentad'].values)\n",
    "if common_pentads.size < 10:\n",
    "    raise ValueError('Not enough pentads to sample 10 unique entries.')\n",
    "rng = np.random.default_rng(42)\n",
    "selected_pentads = np.sort(rng.choice(common_pentads, size=10, replace=False))\n",
    "selected_pentads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcabd52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_points = 20000  # limit plotted points for readability\n",
    "rng = np.random.default_rng(123)\n",
    "\n",
    "for pentad in selected_pentads:\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.ravel()\n",
    "    for ax, var in zip(axes, vars_to_compare):\n",
    "        data_a = ds_dedup[var].sel(pentad=pentad).transpose('lon', 'lat', missing_dims='ignore').values.reshape(-1)\n",
    "        data_b = ds_full[var].sel(pentad=pentad).transpose('lon', 'lat', missing_dims='ignore').values.reshape(-1)\n",
    "        mask = np.isfinite(data_a) & np.isfinite(data_b)\n",
    "        data_a = data_a[mask]\n",
    "        data_b = data_b[mask]\n",
    "        if data_a.size == 0:\n",
    "            ax.text(0.5, 0.5, 'No overlapping data', ha='center', va='center', transform=ax.transAxes)\n",
    "            ax.set_axis_off()\n",
    "            continue\n",
    "        if data_a.size > max_points:\n",
    "            idx = rng.choice(data_a.size, size=max_points, replace=False)\n",
    "            data_a = data_a[idx]\n",
    "            data_b = data_b[idx]\n",
    "        ax.scatter(data_a, data_b, s=2, alpha=0.3, edgecolor='none')\n",
    "        combined = np.concatenate([data_a, data_b])\n",
    "        vmin, vmax = np.nanmin(combined), np.nanmax(combined)\n",
    "        if vmin == vmax:\n",
    "            vmin -= 1\n",
    "            vmax += 1\n",
    "        ax.plot([vmin, vmax], [vmin, vmax], color='black', linewidth=1, linestyle='--')\n",
    "        ax.set_title(var)\n",
    "        ax.set_xlabel('Deduplicated dataset')\n",
    "        ax.set_ylabel('Original dataset')\n",
    "    for leftover_ax in axes[len(vars_to_compare):]:\n",
    "        leftover_ax.set_visible(False)\n",
    "    fig.suptitle(f'Pentad {int(pentad)} scatter comparisons')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704cfa04",
   "metadata": {},
   "source": [
    "## Cross-file observation vs model tests\n",
    "\n",
    "We test whether deduplicated and original files yield different Gaussian summaries for the same quantities (observations and model). For each pentad/location we run Welch t-tests for mean differences and two-sided F-tests for variance differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0172e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "alpha = 0.05\n",
    "\n",
    "\n",
    "def compute_lon_lat(ds):\n",
    "    lon0 = float(ds['ll_lon'])\n",
    "    lat0 = float(ds['ll_lat'])\n",
    "    dlon = float(ds['d_lon'])\n",
    "    dlat = float(ds['d_lat'])\n",
    "    lon = lon0 + np.arange(ds.dims['lon']) * dlon\n",
    "    lat = lat0 + np.arange(ds.dims['lat']) * dlat\n",
    "    return lon, lat\n",
    "\n",
    "\n",
    "def reorder_dims(da):\n",
    "    target = [dim for dim in ('pentad', 'lon', 'lat') if dim in da.dims]\n",
    "    return da.transpose(*target, missing_dims='ignore')\n",
    "\n",
    "\n",
    "def compute_cross_significance(ds_a, ds_b, mean_key, std_key):\n",
    "    data_a = reorder_dims(ds_a[mean_key])\n",
    "    data_b = reorder_dims(ds_b[mean_key])\n",
    "    coords = data_a.coords\n",
    "    dims = data_a.dims\n",
    "\n",
    "    mu_a = data_a.values\n",
    "    mu_b = data_b.values\n",
    "    std_a = reorder_dims(ds_a[std_key]).values\n",
    "    std_b = reorder_dims(ds_b[std_key]).values\n",
    "    n_a = reorder_dims(ds_a['n_data']).values\n",
    "    n_b = reorder_dims(ds_b['n_data']).values\n",
    "\n",
    "    var_a = np.square(std_a)\n",
    "    var_b = np.square(std_b)\n",
    "\n",
    "    mean_p = np.full(mu_a.shape, np.nan, dtype=np.float64)\n",
    "    var_p = np.full(mu_a.shape, np.nan, dtype=np.float64)\n",
    "\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        se2 = var_a / n_a + var_b / n_b\n",
    "        diff = mu_a - mu_b\n",
    "        valid_mean = (n_a > 1) & (n_b > 1) & np.isfinite(se2) & (se2 > 0)\n",
    "        if np.any(valid_mean):\n",
    "            t_stat = np.full(mu_a.shape, np.nan, dtype=np.float64)\n",
    "            t_stat[valid_mean] = diff[valid_mean] / np.sqrt(se2[valid_mean])\n",
    "            term_a = np.zeros(mu_a.shape, dtype=np.float64)\n",
    "            term_b = np.zeros(mu_a.shape, dtype=np.float64)\n",
    "            valid_term_a = n_a > 1\n",
    "            valid_term_b = n_b > 1\n",
    "            term_a[valid_term_a] = (var_a[valid_term_a] / n_a[valid_term_a]) ** 2 / (n_a[valid_term_a] - 1)\n",
    "            term_b[valid_term_b] = (var_b[valid_term_b] / n_b[valid_term_b]) ** 2 / (n_b[valid_term_b] - 1)\n",
    "            denom = term_a + term_b\n",
    "            valid_dof = valid_mean & (denom > 0)\n",
    "            if np.any(valid_dof):\n",
    "                dof = np.full(mu_a.shape, np.nan, dtype=np.float64)\n",
    "                dof[valid_dof] = (se2[valid_dof] ** 2) / denom[valid_dof]\n",
    "                mean_p[valid_dof] = 2.0 * stats.t.sf(np.abs(t_stat[valid_dof]), dof[valid_dof])\n",
    "\n",
    "        valid_var = (n_a > 2) & (n_b > 2) & np.isfinite(var_a) & np.isfinite(var_b) & (var_a > 0) & (var_b > 0)\n",
    "        if np.any(valid_var):\n",
    "            f_stat = np.full(mu_a.shape, np.nan, dtype=np.float64)\n",
    "            f_stat[valid_var] = var_a[valid_var] / var_b[valid_var]\n",
    "            df1 = n_a - 1\n",
    "            df2 = n_b - 1\n",
    "            valid_df = valid_var & (df1 > 0) & (df2 > 0)\n",
    "            if np.any(valid_df):\n",
    "                cdf_vals = stats.f.cdf(f_stat[valid_df], df1[valid_df], df2[valid_df])\n",
    "                sf_vals = stats.f.sf(f_stat[valid_df], df1[valid_df], df2[valid_df])\n",
    "                var_p[valid_df] = 2.0 * np.minimum(cdf_vals, sf_vals)\n",
    "\n",
    "    mean_da = xr.DataArray(mean_p, coords=coords, dims=dims)\n",
    "    var_da = xr.DataArray(var_p, coords=coords, dims=dims)\n",
    "\n",
    "    mean_flags = (mean_da < alpha).where(np.isfinite(mean_da))\n",
    "    var_flags = (var_da < alpha).where(np.isfinite(var_da))\n",
    "\n",
    "    pentad_mean_frac = mean_flags.mean(dim=('lon', 'lat'), skipna=True)\n",
    "    pentad_var_frac = var_flags.mean(dim=('lon', 'lat'), skipna=True)\n",
    "    location_mean_frac = mean_flags.mean(dim='pentad', skipna=True)\n",
    "    location_var_frac = var_flags.mean(dim='pentad', skipna=True)\n",
    "\n",
    "    return {\n",
    "        'mean_flags': mean_flags,\n",
    "        'var_flags': var_flags,\n",
    "        'pentad_mean_frac': pentad_mean_frac,\n",
    "        'pentad_var_frac': pentad_var_frac,\n",
    "        'location_mean_frac': location_mean_frac,\n",
    "        'location_var_frac': location_var_frac,\n",
    "    }\n",
    "\n",
    "\n",
    "def dataarray_to_map_array(data_array, lon_vals, lat_vals):\n",
    "    da = data_array.transpose('lon', 'lat', missing_dims='ignore')\n",
    "    data = da.values\n",
    "    lon_grid, lat_grid = np.meshgrid(lon_vals, lat_vals, indexing='ij')\n",
    "    flat_vals = data.reshape(-1)\n",
    "    flat_lon = lon_grid.reshape(-1)\n",
    "    flat_lat = lat_grid.reshape(-1)\n",
    "    mask = np.isfinite(flat_vals)\n",
    "    return np.column_stack((flat_vals[mask], flat_lon[mask], flat_lat[mask]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac57116",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stats_pentads = common_pentads\n",
    "subset_dedup = ds_dedup.sel(pentad=stats_pentads)\n",
    "subset_full = ds_full.sel(pentad=stats_pentads)\n",
    "\n",
    "results = {\n",
    "    'Observations (o)': compute_cross_significance(subset_dedup, subset_full, 'o_mean', 'o_std'),\n",
    "    'Model (m)': compute_cross_significance(subset_dedup, subset_full, 'm_mean', 'm_std'),\n",
    "}\n",
    "results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bb7c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colors = {'Observations (o)': 'tab:blue', 'Model (m)': 'tab:orange'}\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), sharex=True)\n",
    "for label, res in results.items():\n",
    "    axes[0].plot(res['pentad_mean_frac'], label=label, color=colors[label])\n",
    "axes[0].set_ylabel('Fraction flagged')\n",
    "axes[0].set_title('Mean difference test (dedup vs original)')\n",
    "axes[0].legend()\n",
    "for label, res in results.items():\n",
    "    axes[1].plot(res['pentad_var_frac'], label=label, color=colors[label])\n",
    "axes[1].set_ylabel('Fraction flagged')\n",
    "axes[1].set_xlabel('Pentad index')\n",
    "axes[1].set_title('Variance difference test (dedup vs original)')\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e9fbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lon_vals, lat_vals = compute_lon_lat(ds_dedup)\n",
    "lon_vals, lat_vals = compute_lon_lat(ds_dedup)\n",
    "for label, res in results.items():\n",
    "    mean_array = dataarray_to_map_array(res['location_mean_frac'], lon_vals, lat_vals)\n",
    "    var_array = dataarray_to_map_array(res['location_var_frac'], lon_vals, lat_vals)\n",
    "\n",
    "    # replace exact-zero values in the fraction column with NaN for plotting\n",
    "    mean_zero_mask = np.isclose(mean_array[:, 0], 0.0)\n",
    "    var_zero_mask = np.isclose(var_array[:, 0], 0.0)\n",
    "    mean_array[mean_zero_mask, 0] = np.nan\n",
    "    var_array[var_zero_mask, 0] = np.nan\n",
    "\n",
    "    mean_title = f'{label}: mean-test fraction per location'\n",
    "    fig, _ = plot_region(\n",
    "        mean_array,\n",
    "        region_bounds=REGION_BOUNDS['global'],\n",
    "        meanflag=False,\n",
    "        plot_title=mean_title,\n",
    "        units='Fraction',\n",
    "        cmin=0.0,\n",
    "        cmax=1.0,\n",
    "    )\n",
    "    plt.show()\n",
    "    var_title = f'{label}: variance-test fraction per location'\n",
    "    fig, _ = plot_region(\n",
    "        var_array,\n",
    "        region_bounds=REGION_BOUNDS['global'],\n",
    "        meanflag=False,\n",
    "        plot_title=var_title,\n",
    "        units='Fraction',\n",
    "        cmin=0.0,\n",
    "        cmax=1.0,\n",
    "    )\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
