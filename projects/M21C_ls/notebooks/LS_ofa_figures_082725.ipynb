{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import sys;       sys.path.append('../util/shared/python/')\n",
    "from read_GEOSldas          import read_tilecoord, read_obs_param\n",
    "\n",
    "from mapper_functions import plot_aus_tight_pcm, plot_global_tight_pcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = {\n",
    "    \"SMOS\": [0, 1, 2, 3],\n",
    "    \"SMAP\": [4, 5, 6, 7],\n",
    "    \"ASCAT\": [8, 9, 10],\n",
    "    \"MODIS\": [11, 12]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the OL data files\n",
    "\n",
    "stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "'LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_OL_20000601_20240531.nc4'\n",
    "\n",
    "print('reading stats nc4 file '+stats_file_OL)\n",
    "stats_OL = {}\n",
    "with Dataset(stats_file_OL,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        print(f\"Reading variable: {key}\")\n",
    "        stats_OL[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "'LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_OL_200006_202405.pkl'\n",
    "\n",
    "with open(ts_stats_file_OL, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_OL = loaded_data\n",
    "date_vec_OL = loaded_data.get('date_vec', None)  \n",
    "date_vec = date_vec_OL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the DA data files\n",
    "stats_file_DA = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/M21C_land_sweeper/LS_DAv8_M36_v2/' \\\n",
    "'LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20000601_20240531.nc4'\n",
    "#stats_file_DA = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "#'LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20000601_20240331.nc4'\n",
    "\n",
    "print('reading stats nc4 file '+stats_file_DA)\n",
    "stats_DA = {}\n",
    "with Dataset(stats_file_DA,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_DA[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_DA = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/M21C_land_sweeper/LS_DAv8_M36_v2/' \\\n",
    "'LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_DA_200006_202405.pkl'\n",
    "#ts_stats_file_DA = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "#'LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_DA_200006_202403.pkl'\n",
    "\n",
    "with open(ts_stats_file_DA, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_DA = loaded_data\n",
    "date_vec_DA = loaded_data.get('date_vec', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of final compuation of selected diagnostic metrics for OL\n",
    " \n",
    "Nmin = 20\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OL['N_data']\n",
    "O_mean = stats_OL['O_mean']\n",
    "A_mean = stats_OL['A_mean']\n",
    "F_mean = stats_OL['F_mean']\n",
    "O_stdv = stats_OL['O_stdv']\n",
    "A_stdv = stats_OL['A_stdv']\n",
    "F_stdv = stats_OL['F_stdv']\n",
    "OmF_mean = stats_OL['OmF_mean']\n",
    "OmF_stdv = stats_OL['OmF_stdv']\n",
    "OmF_norm_mean = stats_OL['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_OL['OmF_norm_stdv']\n",
    "OmA_mean = stats_OL['OmA_mean']\n",
    "OmA_stdv = stats_OL['OmA_stdv']\n",
    "  \n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "\n",
    "OmF_mean_OL = OmF_mean\n",
    "OmF_stdv_OL = OmF_stdv\n",
    "OmF_norm_mean_OL = OmF_norm_mean\n",
    "OmF_norm_stdv_OL = OmF_norm_stdv\n",
    "OmA_mean_OL = OmA_mean\n",
    "OmA_stdv_OL = OmA_stdv\n",
    "N_data_OL = N_data\n",
    "\n",
    "group_metrics_OL = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OL[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_OL[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['Nobs_data'] = group_N_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample of final compuation of selected diagnostic metrics for DA\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_DA['N_data']\n",
    "O_mean = stats_DA['O_mean']\n",
    "A_mean = stats_DA['A_mean']\n",
    "F_mean = stats_DA['F_mean']\n",
    "O_stdv = stats_DA['O_stdv']\n",
    "A_stdv = stats_DA['A_stdv']\n",
    "F_stdv = stats_DA['F_stdv']\n",
    "OmF_mean = stats_DA['OmF_mean']\n",
    "OmF_stdv = stats_DA['OmF_stdv']\n",
    "OmF_norm_mean = stats_DA['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_DA['OmF_norm_stdv']\n",
    "OmA_mean = stats_DA['OmA_mean']\n",
    "OmA_stdv = stats_DA['OmA_stdv']\n",
    "\n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "OmF_mean_DA = OmF_mean\n",
    "OmF_stdv_DA = OmF_stdv\n",
    "OmF_norm_mean_DA = OmF_norm_mean\n",
    "OmF_norm_stdv_DA = OmF_norm_stdv\n",
    "OmA_mean_DA = OmA_mean\n",
    "OmA_stdv_DA = OmA_stdv\n",
    "N_data_DA = N_data\n",
    "\n",
    "group_metrics_DA = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_DA[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_DA[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['Nobs_data'] = group_N_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftc = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "      'LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/rc_out/LS_OLv8_M36.ldas_tilecoord.bin'\n",
    "tc = read_tilecoord(ftc)\n",
    "n_tile = tc['N_tile']\n",
    "lat = tc['com_lat']\n",
    "lon = tc['com_lon']\n",
    "\n",
    "map_array = np.empty([n_tile, 3])\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 1] = lon\n",
    "map_array[:, 2] = lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in species_groups.keys():\n",
    "\n",
    "    map_array[:, 0] = group_metrics_DA[group]['Nobs_data']\n",
    "\n",
    "    maxval = np.nanmax(map_array[:, 0])\n",
    "    minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "\n",
    "    # Plot group map\n",
    "    plot_global_tight_pcm(\n",
    "        map_array, \n",
    "        False, \n",
    "        True, \n",
    "        f'{group} Ndata: LS_DAv8_M36_200006_202404 \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "        'Cnt', \n",
    "    )\n",
    "\n",
    "# ASCAT = 6121\n",
    "# SMOS = 5047\n",
    "# SMAP = 3287\n",
    "\n",
    "for group in species_groups.keys():\n",
    "\n",
    "    map_array[:, 0] = group_metrics_DA[group]['Nobs_data']\n",
    "\n",
    "    if group == 'ASCAT':\n",
    "        map_array[:, 0] = map_array[:, 0] / 6121\n",
    "    elif group == 'SMOS':\n",
    "        map_array[:, 0] = map_array[:, 0] / 5047\n",
    "    elif group == 'SMAP':\n",
    "        map_array[:, 0] = map_array[:, 0] / 3287\n",
    "    elif group == 'MODIS':\n",
    "        map_array[:, 0] = map_array[:, 0] / 8700    \n",
    "\n",
    "    maxval = np.nanmax(map_array[:, 0])\n",
    "    minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "\n",
    "    # Plot group map\n",
    "    plot_global_tight_pcm(\n",
    "        map_array, \n",
    "        False, \n",
    "        True, \n",
    "        f'{group} Obs per day: LS_DAv8_M36_200006_202405 \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "        'Obs per day', \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stats_dict_to_arrays(stats_dict):\n",
    "    \"\"\"Convert dictionary of lists to numpy arrays\"\"\"\n",
    "    array_dict = {}\n",
    "    \n",
    "    for key in stats_dict.keys():\n",
    "        # Convert list to array and reshape\n",
    "        array_dict[key] = np.array(stats_dict[key])\n",
    "        \n",
    "        # Check if we need to handle missing values (-- in data)\n",
    "        if isinstance(array_dict[key][0], (list, np.ndarray)):\n",
    "            # Replace '--' with np.nan\n",
    "            temp_array = []\n",
    "            for row in array_dict[key]:\n",
    "                cleaned_row = [np.nan if x == '--' else float(x) for x in row]\n",
    "                temp_array.append(cleaned_row)\n",
    "            array_dict[key] = np.array(temp_array)\n",
    "    \n",
    "    return array_dict\n",
    "\n",
    "# Convert dictionary\n",
    "stats_dict_DA_arrays = convert_stats_dict_to_arrays(stats_dict_DA)\n",
    "stats_dict_OL_arrays = convert_stats_dict_to_arrays(stats_dict_OL)\n",
    "\n",
    "# Convert date vector to datetime objects\n",
    "date_vec_DA = [datetime.strptime(date, '%Y%m') for date in date_vec_DA]\n",
    "date_vec_OL = [datetime.strptime(date, '%Y%m') for date in date_vec_OL]\n",
    "\n",
    "# Print first few dates to verify\n",
    "print(\"Sample dates:\", date_vec_DA[:3])\n",
    "# Print the last few dates to verify\n",
    "print(\"Sample dates:\", date_vec_DA[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_group_stats(stats_dict, species_groups):\n",
    "    \"\"\"Calculate weighted statistics for each group\"\"\"\n",
    "    \n",
    "    n_times = len(stats_dict['OmF_mean'])\n",
    "    stats = ['O_mean','F_mean','OmF_mean', 'OmF_stdv', 'OmA_mean', 'OmA_stdv']\n",
    "    \n",
    "    # Initialize output dictionary\n",
    "    group_stats = {}\n",
    "    for group in species_groups.keys():\n",
    "        group_stats[group] = {stat: np.zeros(n_times) for stat in stats}\n",
    "        group_stats[group]['N_data'] = np.zeros(n_times)\n",
    "    \n",
    "    # Calculate weighted stats for each timestep\n",
    "    for t in range(n_times):\n",
    "        for group, indices in species_groups.items():\n",
    "            # Get weights for this group/time\n",
    "            weights = stats_dict['N_data'][t, indices]\n",
    "            total_weight = np.sum(weights)\n",
    "            \n",
    "            if total_weight > 0:\n",
    "                # Calculate weighted statistics\n",
    "                for stat in stats:\n",
    "                    values = stats_dict[stat][t, indices]\n",
    "                    group_stats[group][stat][t] = np.average(values, weights=weights)\n",
    "                group_stats[group]['N_data'][t] = total_weight\n",
    "            else:\n",
    "                # Set to NaN if no observations\n",
    "                for stat in stats:\n",
    "                    group_stats[group][stat][t] = np.nan\n",
    "                    \n",
    "    return group_stats\n",
    "\n",
    "# Calculate group means\n",
    "group_ts_DA = calculate_weighted_group_stats(stats_dict_DA_arrays, species_groups)\n",
    "group_ts_OL = calculate_weighted_group_stats(stats_dict_OL_arrays, species_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length of date_vec_DA\", len(date_vec_DA))\n",
    "print(\"length of date_vec\", len(date_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each species\n",
    "for group in species_groups.keys():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot OmF_mean for OL and DA\n",
    "    mean_O = np.nanmean(group_ts_OL[group]['O_mean'])\n",
    "    mean_F = np.nanmean(group_ts_OL[group]['F_mean'])\n",
    "    \n",
    "    plt.plot(date_vec_OL, group_ts_OL[group]['O_mean'], '--', label=f'{group} O_mean (Mean: {mean_O:.3f})')\n",
    "    plt.plot(date_vec_OL, group_ts_OL[group]['F_mean'], '-', label=f'{group} F_mean (Mean: {mean_F:.3f})')\n",
    "    \n",
    "    # Add black dotted line for Y = 0\n",
    "    # plt.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'O and F Mean for {group}: LS_OLv8_M36_200006_202405')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('O and F Mean')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set x-ticks to every 6 months\n",
    "    # Set x-ticks using datetime array\n",
    "    plt.xticks(date_vec_DA[::24], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"MODIS\", \"ASCAT\", \"SMOS\", \"SMAP\"]\n",
    "panel_labels = [\"(a)\", \"(b)\", \"(c)\", \"(d)\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 8), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, group, label in zip(axes, targets, panel_labels):\n",
    "    o_mean = group_ts_OL[group][\"O_mean\"]\n",
    "    f_mean = group_ts_OL[group][\"F_mean\"]\n",
    "    mean_o = np.nanmean(o_mean)\n",
    "    mean_f = np.nanmean(f_mean)\n",
    "\n",
    "    ax.plot(date_vec_OL, o_mean, \"--\", label=f\"O_mean ({mean_o:.3f})\")\n",
    "    ax.plot(date_vec_OL, f_mean, \"-\", label=f\"F_mean ({mean_f:.3f})\")\n",
    "    ax.set_title(f\"{group}: LS_OLv8_M36_200006–202405\", fontsize=11)\n",
    "    ax.set_ylabel(\"O & F Mean\")\n",
    "    ax.text(0.02, 0.92, label, transform=ax.transAxes)\n",
    "\n",
    "    if ax in axes[:2]:  # top row\n",
    "        ax.tick_params(labelbottom=False)\n",
    "    else:\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_xticks(date_vec_OL[::24])\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout(h_pad=0.3, w_pad=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each species\n",
    "for group in species_groups.keys():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot OmF_mean for OL and DA\n",
    "    mean_OL = np.nanmean(group_ts_OL[group]['OmF_mean'])\n",
    "    mean_DA = np.nanmean(group_ts_DA[group]['OmF_mean'])\n",
    "    \n",
    "    plt.plot(date_vec_OL, group_ts_OL[group]['OmF_mean'], '--', label=f'{group} OL (Mean: {mean_OL:.3f})')\n",
    "    plt.plot(date_vec_DA, group_ts_DA[group]['OmF_mean'], '-', label=f'{group} DA (Mean: {mean_DA:.3f})')\n",
    "    \n",
    "    # Add black dotted line for Y = 0\n",
    "    plt.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'O-F Mean for {group}: LS_DAv8_M36_200006_202405')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('O-F Mean')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set x-ticks to every 24 months\n",
    "    # Set x-ticks using datetime array\n",
    "    plt.xticks(date_vec_DA[::24], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = [\"MODIS\", \"ASCAT\", \"SMOS\", \"SMAP\"]\n",
    "panel_labels = [\"(a)\", \"(b)\", \"(c)\", \"(d)\"]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 8), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, group, label in zip(axes, targets, panel_labels):\n",
    "    ol_series = group_ts_OL[group][\"OmF_mean\"]\n",
    "    da_series = group_ts_DA[group][\"OmF_mean\"]\n",
    "    mean_ol = np.nanmean(ol_series)\n",
    "    mean_da = np.nanmean(da_series)\n",
    "\n",
    "    ax.plot(date_vec_OL, ol_series, \"--\", label=f\"OL (mean {mean_ol:.3f})\")\n",
    "    ax.plot(date_vec_DA, da_series, \"-\", label=f\"DA (mean {mean_da:.3f})\")\n",
    "    ax.axhline(0, color=\"black\", linestyle=\":\", linewidth=1)\n",
    "\n",
    "    ax.set_title(f\"{group}: LS_DAv8_M36_200006–202405\", fontsize=11)\n",
    "    ax.set_ylabel(\"O − F Mean\")\n",
    "    ax.text(0.02, 0.92, label, transform=ax.transAxes)\n",
    "\n",
    "    if ax in axes[:2]:\n",
    "        ax.tick_params(labelbottom=False)\n",
    "    else:\n",
    "        ax.set_xlabel(\"Date\")\n",
    "        ax.set_xticks(date_vec_DA[::24])\n",
    "        ax.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout(h_pad=0.3, w_pad=0.25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each species\n",
    "for group in species_groups.keys():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot OmF_mean for OL and DA\n",
    "    mean_OL = np.nanmean(group_ts_OL[group]['OmF_stdv'])\n",
    "    mean_DA = np.nanmean(group_ts_DA[group]['OmF_stdv'])\n",
    "    \n",
    "    plt.plot(date_vec_DA, group_ts_OL[group]['OmF_stdv'], '--', label=f'{group} OL (Mean: {mean_OL:.3f})')\n",
    "    plt.plot(date_vec_DA, group_ts_DA[group]['OmF_stdv'], '-', label=f'{group} DA (Mean: {mean_DA:.3f})')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'O-F StdDev for {group}: LS_DAv8_M36_200006_202405')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('O-F StdDev')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set y-axis minimum to zero\n",
    "    # plt.ylim(bottom=0)\n",
    "    \n",
    "    # Set x-ticks using datetime array\n",
    "    plt.xticks(date_vec_DA[::24], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with NaNs in the data\n",
    "for group in species_groups.keys():\n",
    "    group_ts_DA[group]['N_data'] = np.where(group_ts_DA[group]['N_data'] == 0, np.nan, group_ts_DA[group]['N_data'])\n",
    "\n",
    "# Plot time series of the number of observations for each group\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Nobs_data for DA for all groups on one figure\n",
    "for group in species_groups.keys():\n",
    "    plt.plot(date_vec_DA, group_ts_DA[group]['N_data'], label=f'{group} DA')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Number of Observations for All Groups (DA): LS_DAv8_M36_200006_202405')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Observations per Month')\n",
    "plt.legend()\n",
    "\n",
    "# Set x-ticks using datetime array\n",
    "plt.xticks(date_vec_DA[::24], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with NaNs\n",
    "for group in species_groups:\n",
    "    data = group_ts_DA[group]['N_data']\n",
    "    group_ts_DA[group]['N_data'] = np.where(data == 0, np.nan, data)\n",
    "\n",
    "# Stack all groups (rows = groups, cols = months)\n",
    "group_stack = np.vstack([group_ts_DA[g]['N_data'] for g in species_groups])\n",
    "\n",
    "# Total obs per month (ignores NaNs)\n",
    "total_obs = np.nansum(group_stack, axis=0)\n",
    "\n",
    "fig, (ax_top, ax_bottom) = plt.subplots(\n",
    "    2, 1, figsize=(11, 7), sharex=True, height_ratios=[1.1, 1]\n",
    ")\n",
    "\n",
    "# Top panel: total obs / month\n",
    "ax_top.plot(date_vec_DA, total_obs, color='k', lw=1)\n",
    "ax_top.set_ylabel('Total Obs / Month')\n",
    "ax_top.set_title('Number of Observations (DA): LS_DAv8_M36_200006–202405')\n",
    "ax_top.tick_params(labelbottom=False)  # suppress x ticklabels here\n",
    "\n",
    "# Bottom panel: per-group series\n",
    "for group in species_groups:\n",
    "    ax_bottom.plot(date_vec_DA, group_ts_DA[group]['N_data'], label=group)\n",
    "\n",
    "ax_bottom.set_ylabel('Obs / Month')\n",
    "ax_bottom.set_xlabel('Date')\n",
    "ax_bottom.legend(ncol=2, fontsize=9)\n",
    "\n",
    "# x ticks every ~24 months (adjust as you like)\n",
    "ax_bottom.set_xticks(date_vec_DA[::24])\n",
    "ax_bottom.tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout(h_pad=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(date_vec_DA))\n",
    "print(len(group_ts_DA['SMAP']['N_data']))\n",
    "print(len(group_ts_OL[group]['OmF_stdv']))\n",
    "print(len(group_ts_DA[group]['OmF_stdv']))\n",
    "\n",
    "\n",
    "group = 'MODIS'\n",
    "# Print the last 5 value of these arrays to verify\n",
    "print(\"Last 5 dates:\", date_vec_DA[-5:])\n",
    "print(\"Last 5 OL OmF_stdv:\", group_ts_OL[group]['OmF_stdv'][-5:])\n",
    "print(\"Last 5 DA OmF_stdv:\", group_ts_DA[group]['OmF_stdv'][-5:])\n",
    "print(\"Last 5 DA N_data:\", group_ts_DA[group]['N_data'][-5:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each species group\n",
    "for group in species_groups.keys():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Calculate normalized percent difference\n",
    "    norm_percent_diff = np.divide(\n",
    "        (group_ts_DA[group]['OmF_stdv'] - group_ts_OL[group]['OmF_stdv']),\n",
    "        group_ts_OL[group]['OmF_stdv'],\n",
    "        out=np.full_like(group_ts_OL[group]['OmF_stdv'], np.nan, dtype=float),\n",
    "        where=group_ts_OL[group]['OmF_stdv'] != 0\n",
    "    ) * 100\n",
    "    \n",
    "    mean_diff = np.nanmean(norm_percent_diff)\n",
    "    \n",
    "    # Plot normalized percent difference\n",
    "    plt.plot(date_vec_DA, norm_percent_diff, label=f'{group} (Mean: {mean_diff:.3f}%)')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'Normalized Percent Difference (OL - DA) for {group} OmF Stdv: LS_DAv8_M36_200006_202405')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Normalized Percent Difference (%)')\n",
    "    plt.axhline(y=0, color='black', linestyle=':', linewidth=1)  # Add black dotted line for Y = 0\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set x-ticks using datetime array\n",
    "    plt.xticks(date_vec_DA[::24], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first three groups on the same plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define the first three groups\n",
    "groups_to_plot = list(species_groups.keys())[:3]\n",
    "\n",
    "# Plot normalized percent difference for each group\n",
    "for group in groups_to_plot:\n",
    "    norm_percent_diff = np.divide(\n",
    "        (group_ts_DA[group]['OmF_stdv'] - group_ts_OL[group]['OmF_stdv']),\n",
    "        group_ts_OL[group]['OmF_stdv'],\n",
    "        out=np.full_like(group_ts_OL[group]['OmF_stdv'], np.nan, dtype=float),\n",
    "        where=group_ts_OL[group]['OmF_stdv'] != 0\n",
    "    ) * 100\n",
    "    \n",
    "    mean_diff = np.nanmean(norm_percent_diff)\n",
    "    plt.plot(date_vec_DA, norm_percent_diff, label=f'{group} (Mean: {mean_diff:.3f}%)')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Normalized Percent Difference (OL - DA): LS_DAv8_M36_200006_202405')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized Percent Difference (%)')\n",
    "plt.axhline(y=0, color='black', linestyle=':', linewidth=1)  # Add black dotted line for Y = 0\n",
    "plt.legend()\n",
    "\n",
    "# Set x-ticks using datetime array\n",
    "plt.xticks(date_vec_DA[::24], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first three groups on the same plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "# Add dotted vertical lines for specific dates\n",
    "highlight_dates = [\n",
    "    (datetime(2007, 6, 1), datetime(2010, 4, 30), 'I. ASCAT A'),\n",
    "    (datetime(2010, 5, 1), datetime(2013, 3, 31), 'II. ASCAT A & SMOS'),\n",
    "    (datetime(2013, 4, 1), datetime(2015, 3, 31), 'III. ASCAT A, B & SMOS'),\n",
    "    (datetime(2015, 4, 1), datetime(2019, 10, 31), 'IV. ASCAT A, B, SMOS & SMAP'),\n",
    "    (datetime(2019, 11, 1), datetime(2021, 11, 30), 'V. ASCAT A, B, C, SMOS & SMAP'),\n",
    "    (datetime(2021, 12, 1), datetime(2024, 5, 31), 'VI. ASCAT B, C, SMOS & SMAP')\n",
    "]\n",
    "\n",
    "for i, (start_date, end_date, label) in enumerate(highlight_dates):\n",
    "    color = 'lightgrey' if i % 2 == 0 else 'darkgrey'\n",
    "    plt.axvspan(start_date, end_date, color=color, alpha=0.5)\n",
    "    mid_date = start_date + (end_date - start_date) / 2\n",
    "    plt.text(mid_date, plt.ylim()[1] * 0.95, label, color='black', ha='center', va='top', fontsize=8, rotation=90)\n",
    "\n",
    "# Define the first three groups\n",
    "groups_to_plot = list(species_groups.keys())[:3]\n",
    "\n",
    "# Plot normalized percent difference for each group\n",
    "for group in groups_to_plot:\n",
    "    norm_percent_diff = np.divide(\n",
    "        (group_ts_DA[group]['OmF_stdv'] - group_ts_OL[group]['OmF_stdv']),\n",
    "        group_ts_OL[group]['OmF_stdv'],\n",
    "        out=np.full_like(group_ts_OL[group]['OmF_stdv'], np.nan, dtype=float),\n",
    "        where=group_ts_OL[group]['OmF_stdv'] != 0\n",
    "    ) * 100\n",
    "    \n",
    "    mean_diff = np.nanmean(norm_percent_diff)\n",
    "    plt.plot(date_vec_DA, norm_percent_diff, label=f'{group} (Mean: {mean_diff:.3f}%)')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Normalized Percent Difference (OL - DA): LS_DAv8_M36_200006_202405')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized Percent Difference (%)')\n",
    "plt.axhline(y=0, color='black', linestyle=':', linewidth=1)  # Add black dotted line for Y = 0\n",
    "plt.ylim(-25, 5)\n",
    "plt.legend()\n",
    "\n",
    "# Set x-ticks using datetime array\n",
    "plt.xticks(date_vec_DA[::24], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'SMAP'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA - OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'SMOS'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA - OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'ASCAT'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'm3 m-3', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'm3 m-3', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA - OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'm3 m-3', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'MODIS'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'Fraction', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'Fraction', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA - OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'Fraction', \n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the OL data files\n",
    "\n",
    "stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "'LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_OL_20070601_20100430.nc4'\n",
    "\n",
    "print('reading stats nc4 file '+stats_file_OL)\n",
    "stats_OL = {}\n",
    "with Dataset(stats_file_OL,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_OL[key] = value[:].filled(np.nan)\n",
    "\n",
    "# Sample of final compuation of selected diagnostic metrics for OL\n",
    " \n",
    "Nmin = 20\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OL['N_data']\n",
    "O_mean = stats_OL['O_mean']\n",
    "A_mean = stats_OL['A_mean']\n",
    "F_mean = stats_OL['F_mean']\n",
    "O_stdv = stats_OL['O_stdv']\n",
    "A_stdv = stats_OL['A_stdv']\n",
    "F_stdv = stats_OL['F_stdv']\n",
    "OmF_mean = stats_OL['OmF_mean']\n",
    "OmF_stdv = stats_OL['OmF_stdv']\n",
    "OmF_norm_mean = stats_OL['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_OL['OmF_norm_stdv']\n",
    "OmA_mean = stats_OL['OmA_mean']\n",
    "OmA_stdv = stats_OL['OmA_stdv']\n",
    "  \n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "\n",
    "OmF_mean_OL = OmF_mean\n",
    "OmF_stdv_OL = OmF_stdv\n",
    "OmF_norm_mean_OL = OmF_norm_mean\n",
    "OmF_norm_stdv_OL = OmF_norm_stdv\n",
    "OmA_mean_OL = OmA_mean\n",
    "OmA_stdv_OL = OmA_stdv\n",
    "N_data_OL = N_data\n",
    "\n",
    "group_metrics_OL_1 = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OL_1[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_OL_1[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_1[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_1[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_1[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_1[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_1[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_1[group]['Nobs_data'] = group_N_data        \n",
    "\n",
    "# Read in the OL data files\n",
    "\n",
    "stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "'LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_OL_20100501_20130331.nc4'\n",
    "\n",
    "print('reading stats nc4 file '+stats_file_OL)\n",
    "stats_OL = {}\n",
    "with Dataset(stats_file_OL,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_OL[key] = value[:].filled(np.nan)\n",
    "\n",
    "# Sample of final computation of selected diagnostic metrics for OL\n",
    " \n",
    "Nmin = 20\n",
    "\n",
    "# Then compute metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OL['N_data']\n",
    "O_mean = stats_OL['O_mean']\n",
    "A_mean = stats_OL['A_mean']\n",
    "F_mean = stats_OL['F_mean']\n",
    "O_stdv = stats_OL['O_stdv']\n",
    "A_stdv = stats_OL['A_stdv']\n",
    "F_stdv = stats_OL['F_stdv']\n",
    "OmF_mean = stats_OL['OmF_mean']\n",
    "OmF_stdv = stats_OL['OmF_stdv']\n",
    "OmF_norm_mean = stats_OL['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_OL['OmF_norm_stdv']\n",
    "OmA_mean = stats_OL['OmA_mean']\n",
    "OmA_stdv = stats_OL['OmA_stdv']\n",
    "  \n",
    "# Mask out data points with insufficient observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "\n",
    "OmF_mean_OL = OmF_mean\n",
    "OmF_stdv_OL = OmF_stdv\n",
    "OmF_norm_mean_OL = OmF_norm_mean\n",
    "OmF_norm_stdv_OL = OmF_norm_stdv\n",
    "OmA_mean_OL = OmA_mean\n",
    "OmA_stdv_OL = OmA_stdv\n",
    "N_data_OL = N_data\n",
    "\n",
    "group_metrics_OL_2 = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OL_2[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_OL_2[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_2[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_2[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_2[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_2[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_2[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_2[group]['Nobs_data'] = group_N_data        \n",
    "# Read in the OL data files\n",
    "\n",
    "stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "'LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_OL_20130401_20150331.nc4'\n",
    "\n",
    "print('reading stats nc4 file '+stats_file_OL)\n",
    "stats_OL = {}\n",
    "with Dataset(stats_file_OL,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_OL[key] = value[:].filled(np.nan)\n",
    "\n",
    "# Sample of final computation of selected diagnostic metrics for OL\n",
    " \n",
    "Nmin = 20\n",
    "\n",
    "# Then compute metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OL['N_data']\n",
    "O_mean = stats_OL['O_mean']\n",
    "A_mean = stats_OL['A_mean']\n",
    "F_mean = stats_OL['F_mean']\n",
    "O_stdv = stats_OL['O_stdv']\n",
    "A_stdv = stats_OL['A_stdv']\n",
    "F_stdv = stats_OL['F_stdv']\n",
    "OmF_mean = stats_OL['OmF_mean']\n",
    "OmF_stdv = stats_OL['OmF_stdv']\n",
    "OmF_norm_mean = stats_OL['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_OL['OmF_norm_stdv']\n",
    "OmA_mean = stats_OL['OmA_mean']\n",
    "OmA_stdv = stats_OL['OmA_stdv']\n",
    "  \n",
    "# Mask out data points with insufficient observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "\n",
    "OmF_mean_OL = OmF_mean\n",
    "OmF_stdv_OL = OmF_stdv\n",
    "OmF_norm_mean_OL = OmF_norm_mean\n",
    "OmF_norm_stdv_OL = OmF_norm_stdv\n",
    "OmA_mean_OL = OmA_mean\n",
    "OmA_stdv_OL = OmA_stdv\n",
    "N_data_OL = N_data\n",
    "\n",
    "group_metrics_OL_3 = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OL_3[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_OL_3[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_3[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_3[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_3[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_3[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_3[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_3[group]['Nobs_data'] = group_N_data        \n",
    "# Read in the OL data files for 20150701 to 20180331\n",
    "\n",
    "stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "'LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_OL_20150401_20191031.nc4'\n",
    "\n",
    "print('reading stats nc4 file ' + stats_file_OL)\n",
    "stats_OL = {}\n",
    "with Dataset(stats_file_OL, 'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_OL[key] = value[:].filled(np.nan)\n",
    "\n",
    "# Sample of final computation of selected diagnostic metrics for OL\n",
    "\n",
    "Nmin = 20\n",
    "\n",
    "# Then compute metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OL['N_data']\n",
    "O_mean = stats_OL['O_mean']\n",
    "A_mean = stats_OL['A_mean']\n",
    "F_mean = stats_OL['F_mean']\n",
    "O_stdv = stats_OL['O_stdv']\n",
    "A_stdv = stats_OL['A_stdv']\n",
    "F_stdv = stats_OL['F_stdv']\n",
    "OmF_mean = stats_OL['OmF_mean']\n",
    "OmF_stdv = stats_OL['OmF_stdv']\n",
    "OmF_norm_mean = stats_OL['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_OL['OmF_norm_stdv']\n",
    "OmA_mean = stats_OL['OmA_mean']\n",
    "OmA_stdv = stats_OL['OmA_stdv']\n",
    "\n",
    "# Mask out data points with insufficient observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[N_data < Nmin] = np.nan\n",
    "OmF_stdv[N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[N_data < Nmin] = np.nan\n",
    "OmA_stdv[N_data < Nmin] = np.nan\n",
    "N_data[N_data < Nmin] = 0\n",
    "\n",
    "OmF_mean_OL = OmF_mean\n",
    "OmF_stdv_OL = OmF_stdv\n",
    "OmF_norm_mean_OL = OmF_norm_mean\n",
    "OmF_norm_stdv_OL = OmF_norm_stdv\n",
    "OmA_mean_OL = OmA_mean\n",
    "OmA_stdv_OL = OmA_stdv\n",
    "N_data_OL = N_data\n",
    "\n",
    "group_metrics_OL_4 = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OL_4[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "\n",
    "    group_metrics_OL_4[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_4[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_4[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_4[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_4[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_4[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_4[group]['Nobs_data'] = group_N_data\n",
    "\n",
    "# Read in the OL data files for 20191101 to 20211031\n",
    "\n",
    "stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "'LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_OL_20191101_20211130.nc4'\n",
    "\n",
    "print('reading stats nc4 file ' + stats_file_OL)\n",
    "stats_OL = {}\n",
    "with Dataset(stats_file_OL, 'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_OL[key] = value[:].filled(np.nan)\n",
    "\n",
    "# Sample of final computation of selected diagnostic metrics for OL\n",
    "\n",
    "Nmin = 20\n",
    "\n",
    "# Then compute metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OL['N_data']\n",
    "O_mean = stats_OL['O_mean']\n",
    "A_mean = stats_OL['A_mean']\n",
    "F_mean = stats_OL['F_mean']\n",
    "O_stdv = stats_OL['O_stdv']\n",
    "A_stdv = stats_OL['A_stdv']\n",
    "F_stdv = stats_OL['F_stdv']\n",
    "OmF_mean = stats_OL['OmF_mean']\n",
    "OmF_stdv = stats_OL['OmF_stdv']\n",
    "OmF_norm_mean = stats_OL['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_OL['OmF_norm_stdv']\n",
    "OmA_mean = stats_OL['OmA_mean']\n",
    "OmA_stdv = stats_OL['OmA_stdv']\n",
    "\n",
    "# Mask out data points with insufficient observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[N_data < Nmin] = np.nan\n",
    "OmF_stdv[N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[N_data < Nmin] = np.nan\n",
    "OmA_stdv[N_data < Nmin] = np.nan\n",
    "N_data[N_data < Nmin] = 0\n",
    "\n",
    "OmF_mean_OL = OmF_mean\n",
    "OmF_stdv_OL = OmF_stdv\n",
    "OmF_norm_mean_OL = OmF_norm_mean\n",
    "OmF_norm_stdv_OL = OmF_norm_stdv\n",
    "OmA_mean_OL = OmA_mean\n",
    "OmA_stdv_OL = OmA_stdv\n",
    "N_data_OL = N_data\n",
    "\n",
    "group_metrics_OL_5 = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OL_5[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "\n",
    "    group_metrics_OL_5[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_5[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_5[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_5[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_5[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_5[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_5[group]['Nobs_data'] = group_N_data\n",
    "\n",
    "\n",
    "# Read in the OL data files for 20191101 to 20211031\n",
    "\n",
    "stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/' \\\n",
    "'LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_OL_20211201_20240531.nc4'\n",
    "\n",
    "print('reading stats nc4 file ' + stats_file_OL)\n",
    "stats_OL = {}\n",
    "with Dataset(stats_file_OL, 'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_OL[key] = value[:].filled(np.nan)\n",
    "\n",
    "# Sample of final computation of selected diagnostic metrics for OL\n",
    "\n",
    "Nmin = 20\n",
    "\n",
    "# Then compute metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OL['N_data']\n",
    "O_mean = stats_OL['O_mean']\n",
    "A_mean = stats_OL['A_mean']\n",
    "F_mean = stats_OL['F_mean']\n",
    "O_stdv = stats_OL['O_stdv']\n",
    "A_stdv = stats_OL['A_stdv']\n",
    "F_stdv = stats_OL['F_stdv']\n",
    "OmF_mean = stats_OL['OmF_mean']\n",
    "OmF_stdv = stats_OL['OmF_stdv']\n",
    "OmF_norm_mean = stats_OL['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_OL['OmF_norm_stdv']\n",
    "OmA_mean = stats_OL['OmA_mean']\n",
    "OmA_stdv = stats_OL['OmA_stdv']\n",
    "\n",
    "# Mask out data points with insufficient observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[N_data < Nmin] = np.nan\n",
    "OmF_stdv[N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[N_data < Nmin] = np.nan\n",
    "OmA_stdv[N_data < Nmin] = np.nan\n",
    "N_data[N_data < Nmin] = 0\n",
    "\n",
    "OmF_mean_OL = OmF_mean\n",
    "OmF_stdv_OL = OmF_stdv\n",
    "OmF_norm_mean_OL = OmF_norm_mean\n",
    "OmF_norm_stdv_OL = OmF_norm_stdv\n",
    "OmA_mean_OL = OmA_mean\n",
    "OmA_stdv_OL = OmA_stdv\n",
    "N_data_OL = N_data\n",
    "\n",
    "group_metrics_OL_6 = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OL_6[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "\n",
    "    group_metrics_OL_6[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_6[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_6[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_6[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_6[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_6[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL_6[group]['Nobs_data'] = group_N_data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the DA data files\n",
    "\n",
    "file_paths_DA = [\n",
    "    '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/M21C_land_sweeper/LS_DAv8_M36_v2/LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20070601_20100430.nc4',\n",
    "    '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/M21C_land_sweeper/LS_DAv8_M36_v2/LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20100501_20130331.nc4',\n",
    "    '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/M21C_land_sweeper/LS_DAv8_M36_v2/LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20130401_20150331.nc4',\n",
    "    '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/M21C_land_sweeper/LS_DAv8_M36_v2/LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20150401_20191031.nc4',\n",
    "    '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/M21C_land_sweeper/LS_DAv8_M36_v2/LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20191101_20211130.nc4',\n",
    "    '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/M21C_land_sweeper/LS_DAv8_M36_v2/LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20211201_20240531.nc4'\n",
    "]\n",
    "\n",
    "group_metrics_DA_list = []\n",
    "\n",
    "for stats_file_DA in file_paths_DA:\n",
    "    print('reading stats nc4 file ' + stats_file_DA)\n",
    "    stats_DA = {}\n",
    "    with Dataset(stats_file_DA, 'r') as nc:\n",
    "        for key, value in nc.variables.items():\n",
    "            stats_DA[key] = value[:].filled(np.nan)\n",
    "\n",
    "    # Sample of final computation of selected diagnostic metrics for DA\n",
    "\n",
    "    Nmin = 20\n",
    "\n",
    "    # Then compute metrics of O-F, O-A, etc. based on above computed\n",
    "    N_data = stats_DA['N_data']\n",
    "    O_mean = stats_DA['O_mean']\n",
    "    A_mean = stats_DA['A_mean']\n",
    "    F_mean = stats_DA['F_mean']\n",
    "    O_stdv = stats_DA['O_stdv']\n",
    "    A_stdv = stats_DA['A_stdv']\n",
    "    F_stdv = stats_DA['F_stdv']\n",
    "    OmF_mean = stats_DA['OmF_mean']\n",
    "    OmF_stdv = stats_DA['OmF_stdv']\n",
    "    OmF_norm_mean = stats_DA['OmF_norm_mean']\n",
    "    OmF_norm_stdv = stats_DA['OmF_norm_stdv']\n",
    "    OmA_mean = stats_DA['OmA_mean']\n",
    "    OmA_stdv = stats_DA['OmA_stdv']\n",
    "\n",
    "    # Mask out data points with insufficient observations using the Nmin threshold\n",
    "    # Do NOT apply to N_data\n",
    "    OmF_mean[N_data < Nmin] = np.nan\n",
    "    OmF_stdv[N_data < Nmin] = np.nan\n",
    "    OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "    OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "    OmA_mean[N_data < Nmin] = np.nan\n",
    "    OmA_stdv[N_data < Nmin] = np.nan\n",
    "    N_data[N_data < Nmin] = 0\n",
    "\n",
    "    OmF_mean_DA = OmF_mean\n",
    "    OmF_stdv_DA = OmF_stdv\n",
    "    OmF_norm_mean_DA = OmF_norm_mean\n",
    "    OmF_norm_stdv_DA = OmF_norm_stdv\n",
    "    OmA_mean_DA = OmA_mean\n",
    "    OmA_stdv_DA = OmA_stdv\n",
    "    N_data_DA = N_data\n",
    "\n",
    "    group_metrics_DA = {}\n",
    "\n",
    "    for group, species_indices in species_groups.items():\n",
    "        group_metrics_DA[group] = {}\n",
    "        group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "\n",
    "        group_metrics_DA[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "        group_metrics_DA[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "        group_metrics_DA[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "        group_metrics_DA[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "        group_metrics_DA[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "        group_metrics_DA[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "        group_metrics_DA[group]['Nobs_data'] = group_N_data\n",
    "\n",
    "    group_metrics_DA_list.append(group_metrics_DA)\n",
    "    \n",
    "# Unpack the list after the loop\n",
    "group_metrics_DA_1, group_metrics_DA_2, group_metrics_DA_3, group_metrics_DA_4, group_metrics_DA_5, group_metrics_DA_6 = group_metrics_DA_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'ASCAT'\n",
    "\n",
    "# Set observation counts from stored metrics for ASCAT and group_metrics_OL_1\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_1[group_name]['OmF_stdv'] - group_metrics_OL_1[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_1[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_1[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_1[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period I.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "group_name = 'ASCAT'\n",
    "\n",
    "# Set observation counts from stored metrics for ASCAT and group_metrics_OL_2\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_2[group_name]['OmF_stdv'] - group_metrics_OL_2[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_2[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_2[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_2[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period II.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics for ASCAT and group_metrics_OL_2\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_3[group_name]['OmF_stdv'] - group_metrics_OL_3[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_3[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_3[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_3[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period III.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "\n",
    "group_name = 'ASCAT'\n",
    "# Set observation counts from stored metrics for ASCAT and group_metrics_OL_4\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_4[group_name]['OmF_stdv'] - group_metrics_OL_4[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_4[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_4[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_4[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period IV.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "# Set observation counts from stored metrics for ASCAT and group_metrics_OL_5\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_5[group_name]['OmF_stdv'] - group_metrics_OL_5[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_5[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_5[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_5[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period V.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics for ASCAT and group_metrics_OL_5\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_6[group_name]['OmF_stdv'] - group_metrics_OL_6[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_6[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_5[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_6[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "# Plot group map\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period VI.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'SMOS'\n",
    "\n",
    "# Time period 2\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_2[group_name]['OmF_stdv'] - group_metrics_OL_2[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_2[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_2[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_2[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period II.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "\n",
    "# Time period 3\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_3[group_name]['OmF_stdv'] - group_metrics_OL_3[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_3[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_3[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_3[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period III.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "\n",
    "# Time period 4\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_4[group_name]['OmF_stdv'] - group_metrics_OL_4[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_4[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_4[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_4[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period IV.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "\n",
    "# Time period 5\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_5[group_name]['OmF_stdv'] - group_metrics_OL_5[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_5[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_5[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_5[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period V.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "# Time period VI.\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_6[group_name]['OmF_stdv'] - group_metrics_OL_6[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_6[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_6[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_6[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period VI.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'SMAP'\n",
    "\n",
    "# Time period 4\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_4[group_name]['OmF_stdv'] - group_metrics_OL_4[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_4[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_4[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_4[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period IV.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "\n",
    "# Time period 5\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_5[group_name]['OmF_stdv'] - group_metrics_OL_5[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_5[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_5[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_5[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period V.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")\n",
    "# Time period VI.\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_6[group_name]['OmF_stdv'] - group_metrics_OL_6[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL_6[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL_5[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL_6[group_name]['OmF_stdv'] != 0\n",
    ") * 100\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF StdDev {group_name} (Time period VI.) \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -60, \n",
    "    60\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
