{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Plot Theil–Sen trend maps from LS_theilsen_mk_states_increments.nc\n",
    "with flexible significance rendering (no stipple) and sensible precip units.\n",
    "\n",
    "Significance rendering styles:\n",
    "  - SIG_STYLE=\"fade\"    -> non-significant tiles faded (low alpha), uses SAME cmap/norm as base\n",
    "  - SIG_STYLE=\"outline\" -> thin black halo around significant tiles\n",
    "  - SIG_STYLE=\"contour\" -> boundary line (requires quick grid)\n",
    "  - SIG_STYLE=\"mask\"    -> semi-transparent grey overlay where NOT significant\n",
    "\"\"\"\n",
    "\n",
    "import struct\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from geospatial_plotting import plot_region, REGION_BOUNDS\n",
    "\n",
    "# -----------------------------\n",
    "# Config\n",
    "# -----------------------------\n",
    "NC_TRENDS   = \"LS_theilsen_mk_states_increments.nc\"\n",
    "FILE_TILECO = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/rc_out/LS_OLv8_M36.ldas_tilecoord.bin\"\n",
    "\n",
    "VARS          = [\"SFMC\", \"RZMC\", \"SNOW\", \"PREC\"]\n",
    "\n",
    "ALPHA         = 0.05\n",
    "APPLY_SIG     = False\n",
    "USE_STRICT_SIG_FOR_DELTA = True\n",
    "PLOT_MASKS    = True\n",
    "\n",
    "# How to draw significance on the main maps (no stipple):\n",
    "# \"fade\" | \"outline\" | \"contour\" | \"mask\"\n",
    "SIG_STYLE     = \"mask\"\n",
    "\n",
    "REGION        = \"global\"\n",
    "\n",
    "# Units / scaling\n",
    "SEC_PER_YEAR  = 365.25 * 24 * 3600.0\n",
    "VAR_SCALE     = {\n",
    "    \"SFMC\": 1.0,\n",
    "    \"RZMC\": 1.0,\n",
    "    \"SNOW\": 1.0,\n",
    "    \"PREC\": SEC_PER_YEAR,   # mm/s → mm/yr (per decade kept)\n",
    "}\n",
    "VAR_UNITS     = {\n",
    "    \"SFMC\": \"per decade\",\n",
    "    \"RZMC\": \"per decade\",\n",
    "    \"SNOW\": \"per decade\",\n",
    "    \"PREC\": \"mm/yr per decade\",\n",
    "}\n",
    "\n",
    "QUANT_CLIP_MAIN  = 0.995\n",
    "QUANT_CLIP_DELTA = 0.995\n",
    "\n",
    "FNAME_MAIN = \"{var}_{mode}_trend_map.png\"     # mode in {\"CNTL\",\"DA\",\"DELTA\"}\n",
    "FNAME_MASK = \"{var}_{mode}_sigmask.png\"\n",
    "NC_MASKS   = \"trend_significance_masks.nc\"\n",
    "\n",
    "# -----------------------------\n",
    "# tilecoord reader\n",
    "# -----------------------------\n",
    "def read_tilecoord(fname):\n",
    "    \"\"\"Read GEOS-LDAS tilecoord Fortran binary (little-endian).\"\"\"\n",
    "    int_precision = 'i'\n",
    "    float_precision = 'f'\n",
    "    machfmt = '<'\n",
    "    tile_coord = {}\n",
    "    with open(fname, 'rb') as ifp:\n",
    "        _ = struct.unpack(f'{machfmt}i', ifp.read(4))[0]\n",
    "        tile_coord['N_tile'] = struct.unpack(f'{machfmt}i', ifp.read(4))[0]\n",
    "        _ = struct.unpack(f'{machfmt}i', ifp.read(4))[0]\n",
    "        Nt = tile_coord['N_tile']\n",
    "        fields = ['tile_id','typ','pfaf','com_lon','com_lat','min_lon','max_lon',\n",
    "                  'min_lat','max_lat','i_indg','j_indg','frac_cell','frac_pfaf',\n",
    "                  'area','elev']\n",
    "        for field in fields:\n",
    "            _ = struct.unpack(f'{machfmt}i', ifp.read(4))[0]\n",
    "            dtype = int_precision if field in ['tile_id','typ','pfaf','i_indg','j_indg'] else float_precision\n",
    "            arr = np.frombuffer(ifp.read(Nt*4), dtype=f'{machfmt}{dtype}')\n",
    "            arr = arr.astype(np.float64 if dtype=='f' else np.int32)\n",
    "            tile_coord[field] = arr\n",
    "            _ = struct.unpack(f'{machfmt}i', ifp.read(4))[0]\n",
    "    return tile_coord\n",
    "\n",
    "# -----------------------------\n",
    "# helpers\n",
    "# -----------------------------\n",
    "def signif_mask(p, alpha=ALPHA):\n",
    "    p = np.asarray(p)\n",
    "    return np.isfinite(p) & (p < alpha)\n",
    "\n",
    "def robust_sym_limit(arrays, q=0.995):\n",
    "    pool = []\n",
    "    for a in arrays:\n",
    "        if a is None:\n",
    "            continue\n",
    "        a = np.asarray(a)\n",
    "        if a.size:\n",
    "            a = a[np.isfinite(a)]\n",
    "            if a.size:\n",
    "                pool.append(np.abs(a))\n",
    "    if not pool:\n",
    "        return 1.0\n",
    "    return float(np.nanquantile(np.concatenate(pool), q))\n",
    "\n",
    "def make_map_array(values, lon, lat, mask=None):\n",
    "    z = np.asarray(values, dtype=float)\n",
    "    if mask is not None:\n",
    "        z = np.where(mask, z, np.nan)\n",
    "    m = np.empty((lon.shape[0], 3), dtype=float)\n",
    "    m.fill(np.nan)\n",
    "    m[:, 0] = z\n",
    "    m[:, 1] = lon\n",
    "    m[:, 2] = lat\n",
    "    return m\n",
    "\n",
    "def quick_grid(lon, lat, vals, res=1.0):\n",
    "    \"\"\"Nearest-neighbor grid for masks; res in degrees. For 'contour' style.\"\"\"\n",
    "    long = np.arange(-180, 180 + res, res)\n",
    "    latg = np.arange(-90,   90 + res, res)\n",
    "    LON, LAT = np.meshgrid(long, latg)\n",
    "    li = np.searchsorted(long, lon) - 1\n",
    "    lj = np.searchsorted(latg, lat) - 1\n",
    "    li = np.clip(li, 0, long.size - 1)\n",
    "    lj = np.clip(lj, 0, latg.size - 1)\n",
    "    Z = np.full_like(LON, np.nan, dtype=float)\n",
    "    Z[lj, li] = vals\n",
    "    return long, latg, Z\n",
    "\n",
    "def get_ax_cmap_norm(ax):\n",
    "    \"\"\"\n",
    "    Try to recover the cmap & norm used by plot_region's base artist (pcolormesh/PathCollection/etc.).\n",
    "    Returns (cmap, norm) or (None, None) if not found.\n",
    "    \"\"\"\n",
    "    # look through collections first (scatter/pcolormesh end up here), then images\n",
    "    for coll in getattr(ax, \"collections\", []):\n",
    "        if hasattr(coll, \"get_cmap\") and hasattr(coll, \"get_norm\"):\n",
    "            cmap = coll.get_cmap()\n",
    "            norm = coll.get_norm()\n",
    "            if cmap is not None and norm is not None:\n",
    "                return cmap, norm\n",
    "    for im in getattr(ax, \"images\", []):\n",
    "        if hasattr(im, \"get_cmap\") and hasattr(im, \"get_norm\"):\n",
    "            cmap = im.get_cmap()\n",
    "            norm = im.get_norm()\n",
    "            if cmap is not None and norm is not None:\n",
    "                return cmap, norm\n",
    "    return None, None\n",
    "\n",
    "# -----------------------------\n",
    "# significance rendering (no stipple)\n",
    "# -----------------------------\n",
    "def draw_sig_fade(ax, map_array, lon, lat, sig_mask, cmap, norm):\n",
    "    \"\"\"\n",
    "    Re-draw the tile colors using the SAME cmap/norm as the base layer:\n",
    "      - significant tiles at alpha=1\n",
    "      - non-significant tiles at alpha=0.25\n",
    "    \"\"\"\n",
    "    sig = np.asarray(sig_mask, dtype=bool)\n",
    "    nonsig = ~sig\n",
    "    ok_sig    = np.isfinite(lon) & np.isfinite(lat) & sig\n",
    "    ok_nonsig = np.isfinite(lon) & np.isfinite(lat) & nonsig\n",
    "\n",
    "    # cartopy transform (optional)\n",
    "    xtra = {}\n",
    "    try:\n",
    "        import cartopy.crs as ccrs\n",
    "        if hasattr(ax, \"projection\"):\n",
    "            xtra[\"transform\"] = ccrs.PlateCarree()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    v = map_array[:, 0]\n",
    "\n",
    "    # Compute *exact* RGBA using the base layer's cmap & norm\n",
    "    if ok_nonsig.any():\n",
    "        colors_ns = cmap(norm(v[ok_nonsig]))\n",
    "        ax.scatter(lon[ok_nonsig], lat[ok_nonsig],\n",
    "                   s=7, marker='s', facecolors=colors_ns, edgecolors='none',\n",
    "                   alpha=0.25, zorder=6, **xtra)\n",
    "    if ok_sig.any():\n",
    "        colors_s = cmap(norm(v[ok_sig]))\n",
    "        ax.scatter(lon[ok_sig], lat[ok_sig],\n",
    "                   s=7, marker='s', facecolors=colors_s, edgecolors='none',\n",
    "                   alpha=1.0, zorder=7, **xtra)\n",
    "\n",
    "def draw_sig_outline(ax, lon, lat, sig_mask):\n",
    "    sig = np.asarray(sig_mask, dtype=bool)\n",
    "    ok = np.isfinite(lon) & np.isfinite(lat) & sig\n",
    "    xtra = {}\n",
    "    try:\n",
    "        import cartopy.crs as ccrs\n",
    "        if hasattr(ax, \"projection\"):\n",
    "            xtra[\"transform\"] = ccrs.PlateCarree()\n",
    "    except Exception:\n",
    "        pass\n",
    "    if ok.any():\n",
    "        ax.scatter(lon[ok], lat[ok],\n",
    "                   s=12, facecolors='none', edgecolors='k',\n",
    "                   linewidths=0.25, zorder=9, **xtra)\n",
    "\n",
    "def draw_sig_contour(ax, lon, lat, sig_mask, res=1.0):\n",
    "    ok = np.isfinite(lon) & np.isfinite(lat)\n",
    "    if not ok.any():\n",
    "        return\n",
    "    xtra = {}\n",
    "    try:\n",
    "        import cartopy.crs as ccrs\n",
    "        if hasattr(ax, \"projection\"):\n",
    "            xtra[\"transform\"] = ccrs.PlateCarree()\n",
    "    except Exception:\n",
    "        pass\n",
    "    Zmask = np.asarray(sig_mask, dtype=bool).astype(float)\n",
    "    lg, tg, Z = quick_grid(lon[ok], lat[ok], Zmask[ok], res=res)\n",
    "    ax.contour(lg, tg, Z, levels=[0.5], linewidths=0.8, colors='k', zorder=9, **xtra)\n",
    "\n",
    "def draw_sig_mask(ax, lon, lat, sig_mask):\n",
    "    nonsig = ~np.asarray(sig_mask, dtype=bool)\n",
    "    ok = np.isfinite(lon) & np.isfinite(lat) & nonsig\n",
    "    xtra = {}\n",
    "    try:\n",
    "        import cartopy.crs as ccrs\n",
    "        if hasattr(ax, \"projection\"):\n",
    "            xtra[\"transform\"] = ccrs.PlateCarree()\n",
    "    except Exception:\n",
    "        pass\n",
    "    if ok.any():\n",
    "        ax.scatter(lon[ok], lat[ok],\n",
    "                   s=2, marker='s', c='#9e9e9e',\n",
    "                   alpha=0.1, linewidths=0, zorder=8, **xtra)\n",
    "\n",
    "# -----------------------------\n",
    "# plotting\n",
    "# -----------------------------\n",
    "def plot_one(var, mode, ds, lon, lat, cmin=None, cmax=None, mask=None, title_extra=\"\", sig_mask=None):\n",
    "    units_label = VAR_UNITS.get(var, \"per decade\")\n",
    "    scale = VAR_SCALE.get(var, 1.0)\n",
    "\n",
    "    if mode in (\"CNTL\", \"DA\"):\n",
    "        vals = ds[f\"{var}_slope_{mode}\"].values\n",
    "    elif mode == \"DELTA\":\n",
    "        vals = ds[f\"{var}_slope_DA\"].values - ds[f\"{var}_slope_CNTL\"].values\n",
    "    else:\n",
    "        raise ValueError(mode)\n",
    "\n",
    "    vals_plot = vals * scale\n",
    "    map_array = make_map_array(vals_plot, lon, lat, mask=mask)\n",
    "\n",
    "    vmax = np.nanmax(map_array[:, 0])\n",
    "    vmin = np.nanmin(map_array[:, 0])\n",
    "\n",
    "    # Draw base layer (plot_region likely sets its own cmap & norm internally)\n",
    "    fig, ax = plot_region(\n",
    "        map_array,\n",
    "        region_bounds=REGION_BOUNDS[REGION],\n",
    "        meanflag=True,\n",
    "        plot_title=(f\"{var} {mode} trend ({units_label}){title_extra}\\n\"\n",
    "                    f\"(Max: {vmax:.3g}  Min: {vmin:.3g})\"),\n",
    "        units=units_label,\n",
    "        cmin=cmin,\n",
    "        cmax=cmax,\n",
    "    )\n",
    "\n",
    "    # Recover the EXACT cmap & norm used by the base layer\n",
    "    cmap, norm = get_ax_cmap_norm(ax)\n",
    "    # Fallback if we couldn't find them for any reason\n",
    "    if norm is None:\n",
    "        norm = mcolors.Normalize(vmin=cmin, vmax=cmax)\n",
    "    if cmap is None:\n",
    "        cmap = cm.get_cmap(\"viridis\")\n",
    "\n",
    "    # Significance overlay\n",
    "    if sig_mask is not None:\n",
    "        if SIG_STYLE == \"fade\":\n",
    "            draw_sig_fade(ax, map_array, lon, lat, sig_mask, cmap=cmap, norm=norm)\n",
    "        elif SIG_STYLE == \"outline\":\n",
    "            draw_sig_outline(ax, lon, lat, sig_mask)\n",
    "        elif SIG_STYLE == \"contour\":\n",
    "            draw_sig_contour(ax, lon, lat, sig_mask, res=1.0)\n",
    "        elif SIG_STYLE == \"mask\":\n",
    "            draw_sig_mask(ax, lon, lat, sig_mask)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    outfile = FNAME_MAIN.format(var=var, mode=mode)\n",
    "    fig.savefig(outfile, dpi=180)\n",
    "    # plt.close(fig)\n",
    "    return outfile\n",
    "\n",
    "def plot_mask(var, mode, mask_arr, lon, lat, title_note=\"p<0.05\"):\n",
    "    vals = mask_arr.astype(float)\n",
    "    map_array = make_map_array(vals, lon, lat, mask=None)\n",
    "    fig, ax = plot_region(\n",
    "        map_array,\n",
    "        region_bounds=REGION_BOUNDS[REGION],\n",
    "        meanflag=True,\n",
    "        plot_title=(f\"{var} {mode} significance mask ({title_note})\\n\"\n",
    "                    f\"(1=significant, 0=not)\"),\n",
    "        units=\"Binary mask\",\n",
    "        cmin=0.0,\n",
    "        cmax=1.0,\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "    outfile = FNAME_MASK.format(var=var, mode=mode)\n",
    "    fig.savefig(outfile, dpi=180)\n",
    "    # plt.close(fig)\n",
    "    return outfile\n",
    "\n",
    "# -----------------------------\n",
    "# main\n",
    "# -----------------------------\n",
    "def main():\n",
    "    ds = xr.open_dataset(NC_TRENDS)\n",
    "\n",
    "    tc = read_tilecoord(FILE_TILECO)\n",
    "    print(f\"N_tile (tilecoord) = {tc['N_tile']}\")\n",
    "    n_tile = int(tc[\"N_tile\"])\n",
    "    lat = np.asarray(tc[\"com_lat\"])\n",
    "    lon = np.asarray(tc[\"com_lon\"])\n",
    "\n",
    "    assert lat.shape[0] == n_tile and lon.shape[0] == n_tile, \"Tilecoord lon/lat length mismatch\"\n",
    "    for v in VARS:\n",
    "        for sfx in (\"CNTL\",\"DA\"):\n",
    "            assert f\"{v}_slope_{sfx}\" in ds and f\"{v}_p_{sfx}\" in ds, f\"Missing {v} {sfx} fields\"\n",
    "\n",
    "    mask_ds_vars = {}\n",
    "    outputs = []\n",
    "\n",
    "    for var in VARS:\n",
    "        s_c = ds[f\"{var}_slope_CNTL\"].values\n",
    "        s_d = ds[f\"{var}_slope_DA\"].values\n",
    "        p_c = ds[f\"{var}_p_CNTL\"].values\n",
    "        p_d = ds[f\"{var}_p_DA\"].values\n",
    "\n",
    "        sig_c = signif_mask(p_c, alpha=ALPHA)\n",
    "        sig_d = signif_mask(p_d, alpha=ALPHA)\n",
    "        sig_delta_any  = sig_c | sig_d\n",
    "        sig_delta_both = sig_c & sig_d\n",
    "        sig_delta = sig_delta_both if USE_STRICT_SIG_FOR_DELTA else sig_delta_any\n",
    "\n",
    "        mask_ds_vars[f\"{var}_sig_CNTL\"]       = ((\"tile\",), sig_c.astype(\"i1\"))\n",
    "        mask_ds_vars[f\"{var}_sig_DA\"]         = ((\"tile\",), sig_d.astype(\"i1\"))\n",
    "        mask_ds_vars[f\"{var}_sig_DELTA_any\"]  = ((\"tile\",), sig_delta_any.astype(\"i1\"))\n",
    "        mask_ds_vars[f\"{var}_sig_DELTA_both\"] = ((\"tile\",), sig_delta_both.astype(\"i1\"))\n",
    "\n",
    "        mask_cntl  = sig_c     if APPLY_SIG else None\n",
    "        mask_da    = sig_d     if APPLY_SIG else None\n",
    "        mask_d     = sig_delta if APPLY_SIG else None\n",
    "\n",
    "        scale = VAR_SCALE.get(var, 1.0)\n",
    "        lim_main  = robust_sym_limit([s_c * scale, s_d * scale], q=QUANT_CLIP_MAIN)\n",
    "        delta     = (s_d - s_c) * scale\n",
    "        lim_delta = robust_sym_limit([delta], q=QUANT_CLIP_DELTA)\n",
    "\n",
    "        t_extra = \" [sig mask]\" if APPLY_SIG else \"\"\n",
    "\n",
    "        outputs.append(\n",
    "            plot_one(var, \"CNTL\", ds, lon, lat,\n",
    "                     cmin=-lim_main, cmax=+lim_main,\n",
    "                     mask=mask_cntl, title_extra=t_extra, sig_mask=sig_c)\n",
    "        )\n",
    "        outputs.append(\n",
    "            plot_one(var, \"DA\", ds, lon, lat,\n",
    "                     cmin=-lim_main, cmax=+lim_main,\n",
    "                     mask=mask_da, title_extra=t_extra, sig_mask=sig_d)\n",
    "        )\n",
    "        outputs.append(\n",
    "            plot_one(var, \"DELTA\", ds, lon, lat,\n",
    "                     cmin=-lim_delta, cmax=+lim_delta,\n",
    "                     mask=mask_d, title_extra=t_extra, sig_mask=sig_delta)\n",
    "        )\n",
    "\n",
    "        if PLOT_MASKS:\n",
    "            outputs.append(plot_mask(var, \"CNTL\",        sig_c,          lon, lat, title_note=f\"p<{ALPHA}\"))\n",
    "            outputs.append(plot_mask(var, \"DA\",          sig_d,          lon, lat, title_note=f\"p<{ALPHA}\"))\n",
    "            outputs.append(plot_mask(var, \"DELTA_any\",   sig_delta_any,  lon, lat, title_note=f\"p<{ALPHA} (DA or CNTL)\"))\n",
    "            outputs.append(plot_mask(var, \"DELTA_both\",  sig_delta_both, lon, lat, title_note=f\"p<{ALPHA} (DA & CNTL)\"))\n",
    "\n",
    "    coords = {\n",
    "        \"tile\": np.arange(n_tile, dtype=np.int64),\n",
    "        \"lat\":  ((\"tile\",), lat),\n",
    "        \"lon\":  ((\"tile\",), lon),\n",
    "    }\n",
    "    mask_ds = xr.Dataset(\n",
    "        data_vars=mask_ds_vars,\n",
    "        coords=coords,\n",
    "        attrs={\n",
    "            \"description\": \"Significance masks derived from MK p-values (1=significant, 0=not).\",\n",
    "            \"alpha\": ALPHA,\n",
    "            \"note\": \"DELTA_any = (sig_CNTL OR sig_DA), DELTA_both = (sig_CNTL AND sig_DA).\",\n",
    "            \"precip_units_note\": \"Precip slopes converted for plotting only: mm/s per decade → mm/yr per decade.\",\n",
    "        },\n",
    "    )\n",
    "    mask_ds.to_netcdf(NC_MASKS)\n",
    "    print(f\"Wrote masks NetCDF: {NC_MASKS}\")\n",
    "\n",
    "    print(\"Wrote figures:\")\n",
    "    for o in outputs:\n",
    "        print(\"  -\", o)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- Trend map summary stats (area-weighted), save to CSV --------\n",
    "import csv\n",
    "from typing import Dict, Tuple\n",
    "\n",
    "# Which named regions from REGION_BOUNDS to summarize (must exist in your module)\n",
    "REGIONS_TO_SUM = [\"global\"]  # e.g., [\"global\", \"NA\", \"EU\", \"AUS\"] if you have them defined\n",
    "\n",
    "def region_mask(lon, lat, bounds):\n",
    "    \"\"\"bounds = [min_lon, max_lon, min_lat, max_lat] in Plate Carree.\"\"\"\n",
    "    lo0, lo1, la0, la1 = bounds\n",
    "    # handle dateline wrap simply: assume bounds are in [-180, 180]\n",
    "    return (lon >= lo0) & (lon <= lo1) & (lat >= la0) & (lat <= la1)\n",
    "\n",
    "def aw_mean(x, w):\n",
    "    m = np.isfinite(x) & np.isfinite(w) & (w > 0)\n",
    "    if not m.any(): return np.nan\n",
    "    return np.nansum(x[m] * w[m]) / np.nansum(w[m])\n",
    "\n",
    "def aw_median(x, w):\n",
    "    # quantile with weights (approx via sorting)\n",
    "    m = np.isfinite(x) & np.isfinite(w) & (w > 0)\n",
    "    if not m.any(): return np.nan\n",
    "    xs = x[m]; ws = w[m]\n",
    "    order = np.argsort(xs)\n",
    "    xs = xs[order]; ws = ws[order]\n",
    "    c = np.cumsum(ws) / np.sum(ws)\n",
    "    return xs[np.searchsorted(c, 0.5)]\n",
    "\n",
    "def frac_area(mask, w):\n",
    "    m = np.isfinite(w) & (w > 0)\n",
    "    if not m.any(): return np.nan\n",
    "    return float(np.nansum(w[m] * (mask[m].astype(float))) / np.nansum(w[m]))\n",
    "\n",
    "def pearsonr_masked(a, b, w=None):\n",
    "    m = np.isfinite(a) & np.isfinite(b)\n",
    "    if not m.any(): return np.nan\n",
    "    if w is None:\n",
    "        a0 = a[m] - np.nanmean(a[m])\n",
    "        b0 = b[m] - np.nanmean(b[m])\n",
    "        denom = (np.sqrt(np.nansum(a0*a0)) * np.sqrt(np.nansum(b0*b0)))\n",
    "        return float(np.nan if denom == 0 else np.nansum(a0*b0)/denom)\n",
    "    else:\n",
    "        ww = w[m]\n",
    "        a1 = a[m]; b1 = b[m]\n",
    "        mu_a = np.nansum(ww*a1)/np.nansum(ww)\n",
    "        mu_b = np.nansum(ww*b1)/np.nansum(ww)\n",
    "        da = a1 - mu_a; db = b1 - mu_b\n",
    "        num = np.nansum(ww*da*db)\n",
    "        den = np.sqrt(np.nansum(ww*da*da) * np.nansum(ww*db*db))\n",
    "        return float(np.nan if den == 0 else num/den)\n",
    "\n",
    "def summarize_for_region(var, ds, lon, lat, area_w, bounds, scale_prec=SEC_PER_YEAR):\n",
    "    \"\"\"\n",
    "    Returns dict of stats for one var in one region.\n",
    "    - Slopes are per decade; PREC converted to mm/yr per decade.\n",
    "    \"\"\"\n",
    "    # read base arrays\n",
    "    s_c = ds[f\"{var}_slope_CNTL\"].values\n",
    "    s_d = ds[f\"{var}_slope_DA\"].values\n",
    "    p_c = ds[f\"{var}_p_CNTL\"].values\n",
    "    p_d = ds[f\"{var}_p_DA\"].values\n",
    "\n",
    "    # unit conversion for plotting-consistent readout\n",
    "    if var == \"PREC\":\n",
    "        s_c = s_c * scale_prec\n",
    "        s_d = s_d * scale_prec\n",
    "\n",
    "    # region clip\n",
    "    R = region_mask(lon, lat, bounds)\n",
    "    if not R.any():\n",
    "        return None\n",
    "    w = area_w.copy()\n",
    "    w[~R] = np.nan\n",
    "\n",
    "    # significance masks\n",
    "    sig_c = np.isfinite(p_c) & (p_c < ALPHA)\n",
    "    sig_d = np.isfinite(p_d) & (p_d < ALPHA)\n",
    "\n",
    "    # base stats\n",
    "    out = {\n",
    "        \"area_frac_sig_CNTL\": frac_area(sig_c & R, area_w),\n",
    "        \"area_frac_sig_DA\":   frac_area(sig_d & R, area_w),\n",
    "        \"aw_mean_slope_CNTL\": aw_mean(s_c, w),\n",
    "        \"aw_mean_slope_DA\":   aw_mean(s_d, w),\n",
    "        \"aw_median_slope_CNTL\": aw_median(s_c, w),\n",
    "        \"aw_median_slope_DA\":   aw_median(s_d, w),\n",
    "    }\n",
    "\n",
    "    # sign agreement where both significant\n",
    "    both = R & sig_c & sig_d\n",
    "    agree = both & (np.sign(s_c) == np.sign(s_d))\n",
    "    out[\"area_frac_both_sig\"] = frac_area(both, area_w)\n",
    "    out[\"area_frac_both_sig_and_agree\"] = frac_area(agree, area_w)\n",
    "\n",
    "    # delta stats (DA - CNTL)\n",
    "    d = s_d - s_c\n",
    "    out[\"aw_mean_delta\"]   = aw_mean(d, w)\n",
    "    out[\"aw_median_delta\"] = aw_median(d, w)\n",
    "    out[\"area_frac_delta_pos\"] = frac_area((d > 0) & R, area_w)\n",
    "\n",
    "    # relationship to PREC (only for moisture vars)\n",
    "    if var in (\"SFMC\", \"RZMC\"):\n",
    "        # compare Δ(SM) vs PREC_C or PREC_DA? Usually forcings similar; use CNTL by default\n",
    "        p_ref = ds[\"PREC_slope_CNTL\"].values * scale_prec\n",
    "        out[\"corr_deltaSM_vs_PREC\"] = pearsonr_masked(d, p_ref, w=w)\n",
    "\n",
    "    return out\n",
    "\n",
    "def write_summary_csv(summary: Dict[Tuple[str,str], Dict], path=\"trend_summary.csv\"):\n",
    "    # Collect all keys\n",
    "    all_keys = sorted({k for d in summary.values() for k in d.keys()})\n",
    "    with open(path, \"w\", newline=\"\") as f:\n",
    "        wtr = csv.writer(f)\n",
    "        wtr.writerow([\"var\",\"region\"] + all_keys)\n",
    "        for (var, region), stats in summary.items():\n",
    "            wtr.writerow([var, region] + [stats.get(k, np.nan) for k in all_keys])\n",
    "    print(f\"Wrote {path}\")\n",
    "\n",
    "def run_trend_summary():\n",
    "    ds = xr.open_dataset(NC_TRENDS)\n",
    "    tc = read_tilecoord(FILE_TILECO)\n",
    "    lon = np.asarray(tc[\"com_lon\"])\n",
    "    lat = np.asarray(tc[\"com_lat\"])\n",
    "    # area from tilecoord (m^2); convert to km^2 for readability but it cancels in fractions\n",
    "    area_w = np.asarray(tc.get(\"area\", np.ones_like(lon)))\n",
    "    if not np.isfinite(area_w).any():\n",
    "        area_w = np.ones_like(lon)\n",
    "\n",
    "    summary = {}\n",
    "    for var in VARS:\n",
    "        for region in REGIONS_TO_SUM:\n",
    "            bounds = REGION_BOUNDS[region]\n",
    "            stats = summarize_for_region(var, ds, lon, lat, area_w, bounds)\n",
    "            if stats is not None:\n",
    "                summary[(var, region)] = stats\n",
    "\n",
    "    write_summary_csv(summary, \"trend_summary.csv\")\n",
    "    return summary\n",
    "\n",
    "# Run it\n",
    "if __name__ == \"__main__\":\n",
    "    s = run_trend_summary()\n",
    "    # quick human-readable dump\n",
    "    for (var, region), d in s.items():\n",
    "        print(f\"\\n[{var} @ {region}]\")\n",
    "        for k, v in d.items():\n",
    "            print(f\"  {k}: {v:.4g}\" if isinstance(v, float) else f\"  {k}: {v}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "regrid",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
