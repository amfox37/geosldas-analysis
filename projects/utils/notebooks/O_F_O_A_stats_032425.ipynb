{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dateutil.relativedelta import relativedelta\n",
    "# from my_functions import read_obsfcstana_extend_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'LS_DAv8_M36'\n",
    "\n",
    "start_date = datetime(2020, 1, 2)\n",
    "end_date = datetime(2020, 1, 6)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y%m%d')\n",
    "end_date_str = end_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize arrays\n",
    "max_tilenum = 112573\n",
    "max_speciesnum = 13\n",
    "\n",
    "obs_cnt  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "obs_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "obs2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "fcst_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "fcst2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "ana_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "ana2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "omf_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "omf2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "oma_sum  = np.zeros((max_tilenum + 1, max_speciesnum + 1))\n",
    "oma2_sum = np.zeros((max_tilenum + 1, max_speciesnum + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_obsfcstana_extend_datetime(path, file_name, printflag=False):\n",
    "    # Define precisions\n",
    "    int_precision = 'int32'\n",
    "    float_precision = 'float32'\n",
    "    logical_precision = 'int32'\n",
    "\n",
    "    # Initialize lists for outputs\n",
    "    date_time_list = []\n",
    "    obs_assim_list = []\n",
    "    obs_species_list = []\n",
    "    obs_tilenum_list = []\n",
    "    obs_lon_list = []\n",
    "    obs_lat_list = []\n",
    "    obs_obs_list = []\n",
    "    obs_obsvar_list = []\n",
    "    obs_fcst_list = []\n",
    "    obs_fcstvar_list = []\n",
    "    obs_ana_list = []\n",
    "    obs_anavar_list = []\n",
    "\n",
    "    machfmt = 'b'\n",
    "    file_ext = '.bin'\n",
    "    # Build full file paths (note: file already includes the path)\n",
    "    files = [os.path.join(root, file) \n",
    "             for root, dirs, files in os.walk(path) \n",
    "             for file in files if file.startswith(file_name) and file.endswith(file_ext)]\n",
    "\n",
    "    if printflag:\n",
    "        print(files)\n",
    "\n",
    "    mode = 'rb' if machfmt == 'b' else 'rl'\n",
    "\n",
    "    for file in files:\n",
    "        with open(file, mode) as ifp:  # file already includes the path\n",
    "            if printflag:\n",
    "                print('Reading file', file, '...')\n",
    "            \n",
    "            # Read header and time stamp data\n",
    "            _ = np.fromfile(ifp, int_precision, 1)  # fortran_tag\n",
    "            N_obs = int(np.fromfile(ifp, int_precision, 1))\n",
    "            # Read time components\n",
    "            year    = np.fromfile(ifp, int_precision, 1)\n",
    "            month   = np.fromfile(ifp, int_precision, 1)\n",
    "            day     = np.fromfile(ifp, int_precision, 1)\n",
    "            hour    = np.fromfile(ifp, int_precision, 1)\n",
    "            minute  = np.fromfile(ifp, int_precision, 1)\n",
    "            second  = np.fromfile(ifp, int_precision, 1)\n",
    "            dofyr   = np.fromfile(ifp, int_precision, 1)\n",
    "            pentad  = np.fromfile(ifp, int_precision, 1)\n",
    "            _ = np.fromfile(ifp, int_precision, 1)  # fortran_tag\n",
    "\n",
    "            # Create a single dictionary for the timestamp info and extend the list\n",
    "            date_time_tmp = {\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'day': day,\n",
    "                'hour': hour,\n",
    "                'min': minute,\n",
    "                'sec': second,\n",
    "                'dofyr': dofyr,\n",
    "                'pentad': pentad\n",
    "            }\n",
    "            date_time_list.extend([date_time_tmp] * N_obs) \n",
    "\n",
    "            # Read observation assimilation flag\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            tmp_data = np.fromfile(ifp, logical_precision, N_obs)\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            # Vectorized conversion: nonzero becomes 1, else 0.\n",
    "            tmp_data2 = (tmp_data != 0).astype(np.int32).reshape(-1, 1)\n",
    "            obs_assim_list.append(tmp_data2)\n",
    "\n",
    "            # Read species information\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_species_list.append(np.fromfile(ifp, int_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            \n",
    "            # Read tile number information\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_tilenum_list.append(np.fromfile(ifp, int_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read longitude\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_lon_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read latitude\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_lat_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            \n",
    "            # Read observation value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_obs_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read observation variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_obsvar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read forecast value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_fcst_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read forecast variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_fcstvar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read analysis value\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_ana_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "            # Read analysis variance\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "            obs_anavar_list.append(np.fromfile(ifp, float_precision, N_obs))\n",
    "            _ = np.fromfile(ifp, int_precision, 1)\n",
    "\n",
    "    # After processing all files, concatenate lists into numpy arrays\n",
    "    obs_assim = np.concatenate(obs_assim_list) if obs_assim_list else np.array([])\n",
    "    obs_species = np.concatenate(obs_species_list) if obs_species_list else np.array([])\n",
    "    obs_tilenum = np.concatenate(obs_tilenum_list) if obs_tilenum_list else np.array([])\n",
    "    obs_lon = np.concatenate(obs_lon_list) if obs_lon_list else np.array([])\n",
    "    obs_lat = np.concatenate(obs_lat_list) if obs_lat_list else np.array([])\n",
    "    obs_obs = np.concatenate(obs_obs_list) if obs_obs_list else np.array([])\n",
    "    obs_obsvar = np.concatenate(obs_obsvar_list) if obs_obsvar_list else np.array([])\n",
    "    obs_fcst = np.concatenate(obs_fcst_list) if obs_fcst_list else np.array([])\n",
    "    obs_fcstvar = np.concatenate(obs_fcstvar_list) if obs_fcstvar_list else np.array([])\n",
    "    obs_ana = np.concatenate(obs_ana_list) if obs_ana_list else np.array([])\n",
    "    obs_anavar = np.concatenate(obs_anavar_list) if obs_anavar_list else np.array([])\n",
    "\n",
    "    return (date_time_list, obs_species, obs_tilenum, obs_lon, obs_lat, \n",
    "            obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily statistics in observation space\n",
    "\n",
    "# Define the path directory\n",
    "path = f'/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg'\n",
    "\n",
    "# Define the common file name start\n",
    "file_name_start = f'{expt_name}.ens_avg.ldas_ObsFcstAna.'\n",
    "\n",
    "# Define the print flag\n",
    "printflag = False\n",
    "\n",
    "# Loop over the dates\n",
    "current_date = start_date\n",
    "\n",
    "while current_date <= end_date:\n",
    "    # Define the file name for the current date\n",
    "    file_name = file_name_start + current_date.strftime('%Y%m')\n",
    "    \n",
    "    # Call the read_obsfcstana function for the current file\n",
    "    date_time, species, tilenum, lon, lat, obs, obsvar, fcst, fcstvar, ana, anavar = read_obsfcstana_extend_datetime(path, file_name, printflag)\n",
    "\n",
    "    # Increment the current date by one day\n",
    "    current_date += timedelta(days=1) \n",
    "\n",
    "    # Convert to list of datetime objects\n",
    "    datetime_list = [\n",
    "        datetime(\n",
    "            int(entry['year'][0]),\n",
    "            int(entry['month'][0]),\n",
    "            int(entry['day'][0]),\n",
    "            int(entry['hour'][0]),\n",
    "            int(entry['min'][0]),\n",
    "            int(entry['sec'][0])\n",
    "        )\n",
    "        for entry in date_time\n",
    "    ]\n",
    "\n",
    "    # Convert to numpy array of datetime objects\n",
    "    datetime_array = np.array(datetime_list)\n",
    "\n",
    "    # Calculate the difference between the observation and forecast and observation and analysis\n",
    "    omf = obs - fcst\n",
    "    oma = obs - ana \n",
    "\n",
    "    # Find unique species values and their number\n",
    "    unique_species, counts = np.unique(species, return_counts=True)\n",
    "    num_unique_species = len(unique_species)\n",
    "\n",
    "    # Find unique tilenum values\n",
    "    unique_tilenum = np.unique(tilenum)\n",
    "\n",
    "    # Find the number of unique tilenum values\n",
    "    num_unique_tilenum = len(unique_tilenum)\n",
    "\n",
    "    # Print the number of unique tilenum values\n",
    "    print(f\"Number of unique tilenum values: {num_unique_tilenum}\")\n",
    "\n",
    "    # Sort the arrays based on tilenum\n",
    "    sort_indices = np.argsort(tilenum)\n",
    "    sorted_tilenum = tilenum[sort_indices]\n",
    "    sorted_species = species[sort_indices]\n",
    "    sorted_obs = obs[sort_indices]\n",
    "    sorted_fcst = fcst[sort_indices]\n",
    "    sorted_ana = ana[sort_indices]\n",
    "    sorted_omf = omf[sort_indices]\n",
    "    sorted_oma = oma[sort_indices]\n",
    "    sorted_datetime_array = datetime_array[sort_indices]\n",
    "\n",
    "    # Find the unique tilenum values and their counts\n",
    "    unique_tilenum, counts = np.unique(sorted_tilenum, return_counts=True)\n",
    "\n",
    "    # Calculate the indices where the groups should be split\n",
    "    split_indices = np.cumsum(counts)[:-1]\n",
    "\n",
    "    # Split the sorted arrays based on the split indices\n",
    "    tilenum_tile = np.split(sorted_tilenum, split_indices)\n",
    "    species_tile = np.split(sorted_species, split_indices)\n",
    "    obs_tile = np.split(sorted_obs, split_indices)\n",
    "    fcst_tile = np.split(sorted_fcst, split_indices)\n",
    "    ana_tile = np.split(sorted_ana, split_indices)\n",
    "    omf_tile = np.split(sorted_omf, split_indices)\n",
    "    oma_tile = np.split(sorted_oma, split_indices)\n",
    "    datetime_tile = np.split(sorted_datetime_array, split_indices)\n",
    "\n",
    "    # Loop over the unique tiles\n",
    "\n",
    "    for i in range(num_unique_tilenum):\n",
    "        tc = int(tilenum_tile[i][0])  # Current tile number\n",
    "\n",
    "        # Create a dictionary to store indices for each species in the current tile\n",
    "        species_indices_dict = {sc: np.where(species_tile[i] == sc)[0] for sc in unique_species}\n",
    "\n",
    "        for sc in unique_species:\n",
    "            species_indices = species_indices_dict[sc]\n",
    "\n",
    "            if len(species_indices) > 0:\n",
    "                sc = int(sc)  # Current species number\n",
    "                obs_cnt[tc, sc] += len(species_indices)\n",
    "                obs_sum[tc, sc] += np.sum(obs_tile[i][species_indices])\n",
    "                obs2_sum[tc, sc] += np.sum(obs_tile[i][species_indices]**2)\n",
    "                fcst_sum[tc, sc] += np.sum(fcst_tile[i][species_indices])\n",
    "                fcst2_sum[tc, sc] += np.sum(fcst_tile[i][species_indices]**2)\n",
    "                ana_sum[tc, sc] += np.sum(ana_tile[i][species_indices])\n",
    "                ana2_sum[tc, sc] += np.sum(ana_tile[i][species_indices]**2)\n",
    "                omf_sum[tc, sc] += np.sum(omf_tile[i][species_indices])\n",
    "                omf2_sum[tc, sc] += np.sum(omf_tile[i][species_indices]**2)\n",
    "                oma_sum[tc, sc] += np.sum(oma_tile[i][species_indices])\n",
    "                oma2_sum[tc, sc] += np.sum(oma_tile[i][species_indices]**2)\n",
    "\n",
    "    current_date += relativedelta(months=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sums and sums of squares to a file\n",
    "\n",
    "output_filename = f'{expt_name}_{start_date_str}_{end_date_str}_sum_sumofsquares.npz'\n",
    "\n",
    "np.savez(output_filename, obs_cnt=obs_cnt, obs_sum=obs_sum, obs2_sum=obs2_sum, fcst_sum=fcst_sum, fcst2_sum=fcst2_sum, ana_sum=ana_sum, ana2_sum=ana2_sum, omf_sum=omf_sum, omf2_sum=omf2_sum, oma_sum=oma_sum, oma2_sum=oma2_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation in observation space\n",
    "\n",
    "obs_mean = np.zeros_like(obs_cnt)\n",
    "obs_var = np.zeros_like(obs_cnt)\n",
    "obs_std = np.zeros_like(obs_cnt)\n",
    "fcst_mean = np.zeros_like(obs_cnt)\n",
    "fcst_var = np.zeros_like(obs_cnt)\n",
    "fcst_std = np.zeros_like(obs_cnt)\n",
    "ana_mean = np.zeros_like(obs_cnt)\n",
    "ana_var = np.zeros_like(obs_cnt)\n",
    "ana_std = np.zeros_like(obs_cnt)\n",
    "omf_mean = np.zeros_like(obs_cnt)\n",
    "omf_var = np.zeros_like(obs_cnt)\n",
    "omf_std = np.zeros_like(obs_cnt)\n",
    "oma_mean = np.zeros_like(obs_cnt)\n",
    "oma_var = np.zeros_like(obs_cnt)\n",
    "oma_std = np.zeros_like(obs_cnt)\n",
    "\n",
    "# Avoid division by zero\n",
    "valid_mask = obs_cnt > 1\n",
    "\n",
    "# Calculate the mean only for valid entries\n",
    "obs_mean[valid_mask] = obs_sum[valid_mask] / obs_cnt[valid_mask]\n",
    "fcst_mean[valid_mask] = fcst_sum[valid_mask] / obs_cnt[valid_mask]\n",
    "ana_mean[valid_mask] = ana_sum[valid_mask] / obs_cnt[valid_mask]\n",
    "omf_mean[valid_mask] = omf_sum[valid_mask] / obs_cnt[valid_mask]\n",
    "oma_mean[valid_mask] = oma_sum[valid_mask] / obs_cnt[valid_mask]\n",
    "\n",
    "# Calculate variance using the MATLAB approach for valid entries\n",
    "obs_var[valid_mask] = (obs2_sum[valid_mask] - obs_cnt[valid_mask] * obs_mean[valid_mask]**2) / (obs_cnt[valid_mask] - 1)\n",
    "fcst_var[valid_mask] = (fcst2_sum[valid_mask] - obs_cnt[valid_mask] * fcst_mean[valid_mask]**2) / (obs_cnt[valid_mask] - 1)\n",
    "ana_var[valid_mask] = (ana2_sum[valid_mask] - obs_cnt[valid_mask] * ana_mean[valid_mask]**2) / (obs_cnt[valid_mask] - 1)\n",
    "omf_var[valid_mask] = (omf2_sum[valid_mask] - obs_cnt[valid_mask] * omf_mean[valid_mask]**2) / (obs_cnt[valid_mask] - 1)\n",
    "oma_var[valid_mask] = (oma2_sum[valid_mask] - obs_cnt[valid_mask] * oma_mean[valid_mask]**2) / (obs_cnt[valid_mask] - 1)\n",
    "\n",
    "# Calculate the standard deviation\n",
    "obs_std[valid_mask] = np.sqrt(obs_var[valid_mask])\n",
    "fcst_std[valid_mask] = np.sqrt(fcst_var[valid_mask])\n",
    "ana_std[valid_mask] = np.sqrt(ana_var[valid_mask])\n",
    "omf_std[valid_mask] = np.sqrt(omf_var[valid_mask])\n",
    "oma_std[valid_mask] = np.sqrt(oma_var[valid_mask])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all output into one file using experiment name, start and end date\n",
    "output_filename = f\"{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_stats.npz\"\n",
    "\n",
    "np.savez(\n",
    "    output_filename,\n",
    "    obs_mean=obs_mean,\n",
    "    obs_std=obs_std,\n",
    "    fcst_mean=fcst_mean,\n",
    "    fcst_std=fcst_std,\n",
    "    ana_mean=ana_mean,\n",
    "    ana_std=ana_std,\n",
    "    omf_mean=omf_mean,\n",
    "    omf_std=omf_std,\n",
    "    oma_mean=oma_mean,\n",
    "    oma_std=oma_std\n",
    ")\n",
    "\n",
    "print(f\"Output saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
