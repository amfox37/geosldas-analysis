{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhdf.SD import SD, SDC\n",
    "import numpy as np\n",
    "import os\n",
    "from mapper_functions import plot_global_tight_pcm, plot_NA_tight_pcm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def inspect_hdf4_data(filepath):\n",
    "    \"\"\"Inspect HDF4 data content and metadata\"\"\"\n",
    "    \n",
    "    # Open file\n",
    "    hdf = SD(filepath, SDC.READ)\n",
    "    \n",
    "    # Get snow cover dataset\n",
    "    snow_cover = hdf.select('Day_CMG_Snow_Cover')\n",
    "    \n",
    "    # Get metadata\n",
    "    attrs = snow_cover.attributes()\n",
    "    \n",
    "    # Print information\n",
    "    print(\"\\nDataset Information:\")\n",
    "    print(f\"Shape: {snow_cover.info()[2]}\")\n",
    "    print(f\"Data type: {snow_cover.info()[3]}\")\n",
    "    \n",
    "    print(\"\\nAttributes:\")\n",
    "    for key, value in attrs.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Get data\n",
    "    data = snow_cover.get()\n",
    "    \n",
    "    print(\"\\nData Statistics:\")\n",
    "    print(f\"Min value: {np.min(data)}\")\n",
    "    print(f\"Max value: {np.max(data)}\")\n",
    "    print(f\"Mean value: {np.mean(data)}\")\n",
    "    \n",
    "    hdf.end()\n",
    "    return data, attrs\n",
    "\n",
    "# Usage\n",
    "filepath = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/MYD10C1.A2005196.061.hdf\"\n",
    "snow_cover_data, metadata = inspect_hdf4_data(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_modis_scf_hdf(fname, lon_min, lon_max, lat_min, lat_max, clear_index=20, snow_spatial=2):\n",
    "    \"\"\"Read MODIS Snow Cover Fraction from HDF4 file.\"\"\"\n",
    "    \n",
    "    # Constants\n",
    "    CMG_N_lon = 7200\n",
    "    CMG_N_lat = 3600\n",
    "    CMG_ll_lon = -180.0\n",
    "    CMG_ll_lat = -90.0\n",
    "    CMG_ur_lon = 180.0\n",
    "    CMG_ur_lat = 90.0\n",
    "    CMG_dlon = 0.05\n",
    "    CMG_dlat = 0.05\n",
    "    \n",
    "    # QC Parameters\n",
    "    qc_snow_cover_max = 100\n",
    "    qc_clear_index_min = clear_index\n",
    "    qc_snow_spatial_max = snow_spatial\n",
    "    \n",
    "    # Calculate array indices for lat/lon bounds\n",
    "    start_lon = int((lon_min - CMG_ll_lon)/CMG_dlon)\n",
    "    start_lat = int((CMG_ur_lat - lat_max)/CMG_dlat)\n",
    "    end_lon = int((lon_max - CMG_ll_lon)/CMG_dlon)\n",
    "    end_lat = int((CMG_ur_lat - lat_min)/CMG_dlat)\n",
    "    \n",
    "    N_lon = end_lon - start_lon + 1\n",
    "    N_lat = end_lat - start_lat + 1\n",
    "    \n",
    "    # Read HDF file\n",
    "    hdf = SD(fname, SDC.READ)\n",
    "    \n",
    "    # Read datasets\n",
    "    snow_cover = hdf.select('Day_CMG_Snow_Cover')[start_lat:end_lat+1, start_lon:end_lon+1]\n",
    "    clear_index = hdf.select('Day_CMG_Clear_Index')[start_lat:end_lat+1, start_lon:end_lon+1]\n",
    "    snow_spatial_qa = hdf.select('Snow_Spatial_QA')[start_lat:end_lat+1, start_lon:end_lon+1]\n",
    "    \n",
    "    # Generate lat/lon arrays\n",
    "    lon_ind = np.arange(N_lon)\n",
    "    lat_ind = np.arange(N_lat)\n",
    "    \n",
    "    lon_c = CMG_ll_lon + 0.5*CMG_dlon + (start_lon + lon_ind)*CMG_dlon\n",
    "    lat_c = CMG_ur_lat - 0.5*CMG_dlat - (start_lat + lat_ind)*CMG_dlat\n",
    "    \n",
    "    # Apply QC and normalize SCF\n",
    "    valid_mask = ((snow_cover <= qc_snow_cover_max) & \n",
    "                 (clear_index > qc_clear_index_min) & \n",
    "                 (snow_spatial_qa <= qc_snow_spatial_max))\n",
    "    \n",
    "    # Create output arrays\n",
    "    lon_out = []\n",
    "    lat_out = []\n",
    "    scf_out = []\n",
    "    \n",
    "    for i in range(N_lon):\n",
    "        for j in range(N_lat):\n",
    "            if valid_mask[j,i]:\n",
    "                scf = float(snow_cover[j,i])/float(clear_index[j,i])\n",
    "                lon_out.append(lon_c[i])\n",
    "                lat_out.append(lat_c[j])\n",
    "                scf_out.append(scf)\n",
    "    \n",
    "    hdf.end()\n",
    "    \n",
    "    return np.array(lon_out), np.array(lat_out), np.array(scf_out)\n",
    "\n",
    "# Usage over CONUS\n",
    "lon_min = -125.0\n",
    "lon_max = 66.0\n",
    "lat_min = -20.0\n",
    "lat_max = 50.0\n",
    "fname = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/MYD10C1.A2005196.061.hdf\"\n",
    "lon_out, lat_out, scf_out = read_modis_scf_hdf(fname, lon_min, lon_max, lat_min, lat_max)\n",
    "# Print the first 10 values\n",
    "print(\"Longitude:\", lon_out[:10])\n",
    "print(\"Latitude:\", lat_out[:10])\n",
    "print(\"SCF:\", scf_out[:10])\n",
    "\n",
    "map_array = np.zeros((len(lon_out), 3))\n",
    "# Fill in the map_array with the data\n",
    "map_array[:, 1] = lon_out\n",
    "map_array[:, 2] = lat_out\n",
    "# Fill in the first column with the snow cover fraction\n",
    "map_array[:, 0] = scf_out\n",
    "\n",
    "# Plot the data\n",
    "plot_global_tight_pcm(map_array, False, False, f'MYD10C1.A2005197.061.hdf:\\n MODIS Snow Cover Fraction', 'scf', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "def parse_modis_filename(filename):\n",
    "    \"\"\"Parse MODIS filename to get date\"\"\"\n",
    "    # Extract date portion (assume fixed format)\n",
    "    date_str = filename.split('.A')[1].split('.')[0]\n",
    "    \n",
    "    # Split into year and doy\n",
    "    year = int(date_str[:4])\n",
    "    doy_base = int(date_str[4:6])  # 19\n",
    "    i = int(date_str[6:])          # 0-9\n",
    "    \n",
    "    # Combine base DOY and i\n",
    "    doy = doy_base * 10 + i\n",
    "    \n",
    "    # Convert to datetime\n",
    "    date = datetime(year, 1, 1) + timedelta(days=doy-1)\n",
    "    \n",
    "    return date\n",
    "\n",
    "# Example usage\n",
    "filename = \"MOD10C1.A2005090.061.hdf\"\n",
    "date = parse_modis_filename(filename)\n",
    "print(f\"Date: {date.strftime('%Y-%m-%d')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage over CONUS\n",
    "lon_min = -125.0\n",
    "lon_max = -66.0\n",
    "lat_min = 24.0\n",
    "lat_max = 50.0\n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "for i in range(10):\n",
    "    fname = f\"MYD10C1.A200519{i}.061.hdf\"\n",
    "    path_fname = os.path.join(path, fname)\n",
    "    date = parse_modis_filename(fname)\n",
    "\n",
    "    # Read the data\n",
    "    lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max)\n",
    "    \n",
    "    map_array = np.zeros((len(lon_out), 3))\n",
    "    map_array[:, 1] = lon_out\n",
    "    map_array[:, 2] = lat_out\n",
    "    map_array[:, 0] = scf_out\n",
    "    \n",
    "    # Plot the data\n",
    "   #  plot_NA_tight_pcm(map_array, True, False, f\"{fname}:\\n MODIS SCF {date.strftime('%Y-%m-%d')}\", 'scf', 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import xarray as xr\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def load_ease_grid(ease_path):\n",
    "    \"\"\"Load EASE grid data\"\"\"\n",
    "    lats = np.fromfile(f'{ease_path}/EASE2_M36km.lats.964x406x1.double', \n",
    "                      dtype=np.float64).reshape((406,964))\n",
    "    lons = np.fromfile(f'{ease_path}/EASE2_M36km.lons.964x406x1.double', \n",
    "                      dtype=np.float64).reshape((406,964))\n",
    "    return lats, lons\n",
    "\n",
    "def load_grid(grid_type='ease', ease_path=None):\n",
    "    \"\"\"\n",
    "    Load lat/lon grid for either 'ease' or 'modis'.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    grid_type : str\n",
    "        'ease' or 'modis'\n",
    "    ease_path : str\n",
    "        Path to EASE grid files (required if grid_type='ease')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    lat_2d, lon_2d : np.ndarray\n",
    "        2D arrays of latitude and longitude\n",
    "    \"\"\"\n",
    "    if grid_type == 'ease':\n",
    "        if ease_path is None:\n",
    "            raise ValueError(\"ease_path must be provided for EASE grid\")\n",
    "        lats = np.fromfile(f'{ease_path}/EASE2_M36km.lats.964x406x1.double', \n",
    "                           dtype=np.float64).reshape((406, 964))\n",
    "        lons = np.fromfile(f'{ease_path}/EASE2_M36km.lons.964x406x1.double', \n",
    "                           dtype=np.float64).reshape((406, 964))\n",
    "        return lats, lons\n",
    "    elif grid_type == 'modis':\n",
    "        nlat, nlon = 3600, 7200\n",
    "        res = 0.05\n",
    "        lat_array = 90 - res * (np.arange(nlat) + 0.5)\n",
    "        lon_array = -180 + res * (np.arange(nlon) + 0.5)\n",
    "        lon_2d, lat_2d = np.meshgrid(lon_array, lat_array)\n",
    "        return lat_2d, lon_2d\n",
    "    else:\n",
    "        raise ValueError(f\"Unrecognized grid type: {grid_type}\")\n",
    "\n",
    "def create_grid_mapping(array, lat_2d, lon_2d):\n",
    "    \"\"\"Map array data (val, lon, lat) to a given lat/lon grid\"\"\"\n",
    "    grid = np.full(lat_2d.shape, -9998., dtype=np.float64)\n",
    "    for i in range(len(array)):\n",
    "        val, lon, lat = array[i]\n",
    "        if not np.isnan(val):\n",
    "            row = np.abs(lat_2d[:, 0] - lat).argmin()\n",
    "            col = np.abs(lon_2d[0, :] - lon).argmin()\n",
    "            if row < grid.shape[0] and col < grid.shape[1]:\n",
    "                grid[row, col] = val\n",
    "    return grid\n",
    "\n",
    "def create_grid_mapping_vectorized(array, lat_2d, lon_2d):\n",
    "    \"\"\"Fast mapping using vectorized nearest-neighbor indexing\"\"\"\n",
    "    # Get 1D lat/lon axes\n",
    "    lat_axis = lat_2d[:, 0]\n",
    "    lon_axis = lon_2d[0, :]\n",
    "\n",
    "    # Extract values\n",
    "    vals = array[:, 0]\n",
    "    lons = array[:, 1]\n",
    "    lats = array[:, 2]\n",
    "\n",
    "    # Filter out NaNs early\n",
    "    valid_mask = ~np.isnan(vals)\n",
    "    vals = vals[valid_mask]\n",
    "    lons = lons[valid_mask]\n",
    "    lats = lats[valid_mask]\n",
    "\n",
    "    # Convert to row/col indices using searchsorted\n",
    "    row_idx = np.searchsorted(lat_axis[::-1], lats, side='left')\n",
    "    col_idx = np.searchsorted(lon_axis, lons, side='left')\n",
    "\n",
    "    # Convert row index from reversed lat_axis to normal indexing\n",
    "    row_idx = len(lat_axis) - row_idx - 1\n",
    "\n",
    "    # Clip to bounds to prevent out-of-bounds indexing\n",
    "    row_idx = np.clip(row_idx, 0, lat_2d.shape[0] - 1)\n",
    "    col_idx = np.clip(col_idx, 0, lon_2d.shape[1] - 1)\n",
    "\n",
    "    # Initialize output grid\n",
    "    grid = np.full(lat_2d.shape, -9998., dtype=np.float64)\n",
    "\n",
    "    # Assign values\n",
    "    grid[row_idx, col_idx] = vals\n",
    "\n",
    "    return grid    \n",
    "\n",
    "def plot_region(array, lon_min, lon_max, lat_min, lat_max, \n",
    "                grid_type='ease',\n",
    "                ease_path='../test_data',\n",
    "                saveflag=False, \n",
    "                meanflag=False, \n",
    "                plot_title='regional_plot', \n",
    "                units='na', \n",
    "                cmin=None, \n",
    "                cmax=None, \n",
    "                cmap=None,\n",
    "                output_dir='./plots',\n",
    "                save_fmt='png',\n",
    "                save_dpi=600,\n",
    "                star_lon=None,\n",
    "                star_lat=None):\n",
    "    \"\"\"\n",
    "    Plot data for specified region using either EASE or MODIS grid.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array : np.ndarray\n",
    "        Array of shape (n,3) with values, lons, lats\n",
    "    grid_type : str\n",
    "        Either 'ease' or 'modis'\n",
    "    \"\"\"\n",
    "    \n",
    "    lat_2d, lon_2d = load_grid(grid_type=grid_type, ease_path=ease_path)\n",
    "    grid = create_grid_mapping_vectorized(array, lat_2d, lon_2d)\n",
    "    \n",
    "    # Handle counts/percentages\n",
    "    if 'Number' in plot_title or 'Percent' in plot_title:\n",
    "        grid[grid == -9998] = 0\n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean = np.nanmean(array[:, 0])\n",
    "    std = np.nanstd(array[:, 0])\n",
    "    textstr = format_stats(mean, std, units, plot_title)\n",
    "    \n",
    "    # Set up colormap\n",
    "    if cmin is None or cmax is None:\n",
    "        cmin, cmax, cmap = colorbar_info(array)\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('RdBu_r' if cmin < 0 else 'viridis', 20).copy()\n",
    "    else:\n",
    "        cmap = plt.get_cmap(cmap)\n",
    "    cmap.set_under('lightgrey')\n",
    "    \n",
    "    # Create plot\n",
    "    fig = plt.figure(figsize=(10, 6))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=0))\n",
    "    \n",
    "    # Set region extent\n",
    "    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # Add map features\n",
    "    setup_map_features(ax)\n",
    "    \n",
    "    # Plot data\n",
    "    sc = ax.pcolormesh(lon_2d, lat_2d, grid, \n",
    "                       transform=ccrs.PlateCarree(), \n",
    "                       cmap=cmap, \n",
    "                       vmin=cmin, \n",
    "                       vmax=cmax)\n",
    "    \n",
    "    # Add star if star_lon/lat provided\n",
    "    if star_lon is not None and star_lat is not None:\n",
    "        ax.plot(star_lon, star_lat, 'r*', markersize=10, transform=ccrs.PlateCarree())\n",
    "    \n",
    "    # Add colorbar and labels\n",
    "    setup_colorbar(sc, ax, cmin, cmax, units)\n",
    "    plt.title(plot_title, fontsize=18)\n",
    "    \n",
    "    if meanflag:\n",
    "        ax.text(0.38, 0.05, textstr, fontsize=14, transform=ax.transAxes, ha='left')\n",
    "    \n",
    "    if saveflag:\n",
    "        save_plot(plot_title)\n",
    "\n",
    "    # Overlay EASE grid lines (only if grid_type is 'modis')\n",
    "    if grid_type == 'modis':\n",
    "        ease_lat, ease_lon = load_grid(grid_type='ease', ease_path=ease_path)\n",
    "\n",
    "        # Plot EASE latitude lines\n",
    "        for i in range(0, ease_lat.shape[0], 1):  # every 1 rows\n",
    "            ax.plot(ease_lon[i, :], ease_lat[i, :], color='grey', linewidth=0.5, alpha=0.6,\n",
    "                    transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot EASE longitude lines\n",
    "        for j in range(0, ease_lon.shape[1], 1):  # every 1 columns\n",
    "            ax.plot(ease_lon[:, j], ease_lat[:, j], color='grey', linewidth=0.5, alpha=0.6,\n",
    "                    transform=ccrs.PlateCarree())    \n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return grid\n",
    "\n",
    "def plot_region_scatter(array, lon_min, lon_max, lat_min, lat_max, \n",
    "                grid_type='ease',\n",
    "                ease_path='../test_data',\n",
    "                saveflag=False, \n",
    "                meanflag=False, \n",
    "                plot_title='regional_plot', \n",
    "                units='na', \n",
    "                cmin=None, \n",
    "                cmax=None, \n",
    "                cmap=None,\n",
    "                output_dir='./plots',\n",
    "                save_fmt='png',\n",
    "                save_dpi=600,\n",
    "                star_lon=None,\n",
    "                star_lat=None,\n",
    "                point_size=6):\n",
    "    \"\"\"\n",
    "    Plot data for specified region using either EASE or MODIS grid.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    array : np.ndarray\n",
    "        Array of shape (n,3) with values, lons, lats\n",
    "    grid_type : str\n",
    "        Either 'ease' or 'modis'\n",
    "    \"\"\"  \n",
    "    \n",
    "    # Calculate statistics\n",
    "    mean = np.nanmean(array[:, 0])\n",
    "    std = np.nanstd(array[:, 0])\n",
    "    textstr = format_stats(mean, std, units, plot_title)\n",
    "\n",
    "    # Extract values\n",
    "    lons = array[:, 1]\n",
    "    lats = array[:, 2]\n",
    "    vals = array[:, 0]\n",
    "    \n",
    "    # Set up colormap\n",
    "    if cmin is None or cmax is None:\n",
    "        cmin, cmax, cmap = colorbar_info(array)\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('RdBu_r' if cmin < 0 else 'viridis', 20).copy()\n",
    "    else:\n",
    "        cmap = plt.get_cmap(cmap)\n",
    "    cmap.set_under('lightgrey')\n",
    "    \n",
    "    # Create plot\n",
    "    fig = plt.figure(figsize=(15, 9))\n",
    "    ax = fig.add_subplot(1, 1, 1, projection=ccrs.PlateCarree(central_longitude=0))\n",
    "    \n",
    "    # Set region extent\n",
    "    ax.set_extent([lon_min, lon_max, lat_min, lat_max], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    # Add map features\n",
    "    setup_map_features(ax)\n",
    "    \n",
    "    # Plot data\n",
    "    sc = ax.scatter(lons, lats, c=vals, s=point_size, cmap=cmap, \n",
    "                    vmin=cmin, vmax=cmax, edgecolor='none',\n",
    "                    transform=ccrs.PlateCarree())\n",
    "    \n",
    "    # Add star if star_lon/lat provided\n",
    "    if star_lon is not None and star_lat is not None:\n",
    "        ax.plot(star_lon, star_lat, 'r*', markersize=10, transform=ccrs.PlateCarree())\n",
    "    \n",
    "    # Add colorbar and labels\n",
    "    setup_colorbar(sc, ax, cmin, cmax, units)\n",
    "    plt.title(plot_title, fontsize=18)\n",
    "    \n",
    "    if meanflag:\n",
    "        ax.text(0.38, 0.05, textstr, fontsize=14, transform=ax.transAxes, ha='left')\n",
    "    \n",
    "    if saveflag:\n",
    "        save_plot(plot_title)  \n",
    "\n",
    "    # Overlay EASE grid lines (only if grid_type is 'modis')\n",
    "    if grid_type == 'modis':\n",
    "        ease_lat, ease_lon = load_grid(grid_type='ease', ease_path=ease_path)\n",
    "\n",
    "        # Plot EASE latitude lines\n",
    "        for i in range(0, ease_lat.shape[0], 1):  # every 1 rows\n",
    "            ax.plot(ease_lon[i, :], ease_lat[i, :], color='grey', linewidth=0.5, alpha=0.6,\n",
    "                    transform=ccrs.PlateCarree())\n",
    "\n",
    "        # Plot EASE longitude lines\n",
    "        for j in range(0, ease_lon.shape[1], 1):  # every 1 columns\n",
    "            ax.plot(ease_lon[:, j], ease_lat[:, j], color='grey', linewidth=0.5, alpha=0.6,\n",
    "                    transform=ccrs.PlateCarree())  \n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "def format_stats(mean, std, units, plot_title):\n",
    "    \"\"\"Format statistics string\"\"\"\n",
    "    if 'Relative $\\Delta$ StdDev' in plot_title:\n",
    "        return f'Mean = {mean:.1f}±{std:.1f} {units}'\n",
    "    \n",
    "    def format_number(num):\n",
    "        if abs(num) < 0.01:\n",
    "            return f'{num:.4f}'\n",
    "        elif abs(num) < 1.0:\n",
    "            return f'{num:.2f}'\n",
    "        return f'{num:.3g}'\n",
    "    \n",
    "    return f'Mean = {format_number(mean)}±{format_number(std)} {units}'\n",
    "\n",
    "def setup_map_features(ax):\n",
    "    \"\"\"Set up map features and gridlines\"\"\"\n",
    "    #gl = ax.gridlines(crs=ccrs.PlateCarree(central_longitude=0), \n",
    "    #                 draw_labels=True,\n",
    "    #                 linewidth=1, \n",
    "    #                 color='gray', \n",
    "    #                 alpha=0.5, \n",
    "    #                 linestyle='-')\n",
    "    #gl.xlabel_style = {'size': 5, 'color': 'black'}\n",
    "    #gl.ylabel_style = {'size': 5, 'color': 'black'}\n",
    "    ax.tick_params(labelbottom=False, labeltop=False, \n",
    "                  labelleft=False, labelright=False)\n",
    "    ax.add_feature(cfeature.LAND, facecolor='lightgrey')\n",
    "    ax.add_feature(cfeature.COASTLINE)\n",
    "    ax.add_feature(cfeature.BORDERS)\n",
    "\n",
    "def setup_colorbar(sc, ax, cmin, cmax, units):\n",
    "    \"\"\"Set up colorbar\"\"\"\n",
    "    cbar = plt.colorbar(sc, ax=ax, orientation=\"horizontal\", \n",
    "                       pad=.05, fraction=0.04)\n",
    "    cbar.set_ticks(np.arange(cmin, cmax+0.000000001, (cmax-cmin)/4))\n",
    "    cbar.ax.tick_params(labelsize=10)\n",
    "    cbar.set_label(f'({units})', fontsize=12)\n",
    " \n",
    "\n",
    "def save_plot(plot_title, output_dir='./plots', fmt='png', dpi=600):\n",
    "    \"\"\"\n",
    "    Save plot to specified directory\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    plot_title : str\n",
    "        Title of plot used for filename\n",
    "    output_dir : str or Path\n",
    "        Directory to save plots\n",
    "    fmt : str\n",
    "        File format (png, pdf, jpg)\n",
    "    dpi : int\n",
    "        Resolution for raster formats\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    output_path = Path(output_dir)\n",
    "    output_path.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Clean filename\n",
    "    clean_title = re.sub('[^0-9a-zA-Z]+', '_', plot_title)\n",
    "    \n",
    "    # Construct full save path\n",
    "    savename = output_path / f\"{clean_title}.{fmt}\"\n",
    "    print(f\"Saving figure as {savename}\")\n",
    "    \n",
    "    # Save with specified parameters\n",
    "    plt.savefig(savename, dpi=dpi, bbox_inches='tight', format=fmt)\n",
    "\n",
    "def colorbar_info(array):\n",
    "\n",
    "    # Compute and print some stats for the data\n",
    "    # -----------------------------------------\n",
    "    stdev = np.nanstd(array[:,0])  # Standard deviation\n",
    "    omean = np.nanmean(array[:, 0]) # Mean of the data\n",
    "    datmi = np.nanmin(array[:, 0])  # Min of the data\n",
    "    datma = np.nanmax(array[:, 0])  # Max of the data\n",
    "    abmm = np.nanmax(np.abs(array[:, 0])) # Abs max of the data\n",
    "\n",
    "    # Min max for colorbar\n",
    "    # --------------------\n",
    "    if np.nanmin(array[:, 0]) < 0:\n",
    "        cmax = abmm\n",
    "        cmin = abmm * -1\n",
    "        cmap = 'RdBu'\n",
    "    else:\n",
    "        cmax = datma\n",
    "        cmin = datmi\n",
    "        cmap = 'viridis'\n",
    "\n",
    "    return cmin, cmax, cmap    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage over CONUS\n",
    "lon_min = -125.0\n",
    "lon_max = -66.0\n",
    "lat_min = 24.0\n",
    "lat_max = 50.0\n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "scf_dict = {}\n",
    "\n",
    "for i in range(182, 213):\n",
    "    fname = f\"MYD10C1.A2005{i:03d}.061.hdf\"\n",
    "    path_fname = os.path.join(path, fname)\n",
    "    date = parse_modis_filename(fname)\n",
    "    \n",
    "    # Read the data\n",
    "    lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "    # Update dictionary with higher values\n",
    "    for lon, lat, scf in zip(lon_out, lat_out, scf_out):\n",
    "        key = (lat, lon)\n",
    "        if key not in scf_dict or scf > scf_dict[key]:\n",
    "            scf_dict[key] = scf\n",
    "    \n",
    "    # map_array = np.zeros((len(lon_out), 3))\n",
    "    # map_array[:, 1] = lon_out\n",
    "    # map_array[:, 2] = lat_out\n",
    "    # map_array[:, 0] = scf_out\n",
    "    \n",
    "    # # Plot the data\n",
    "    # plot_region(map_array, \n",
    "    #        lon_min, lon_max,\n",
    "    #        lat_min, lat_max,\n",
    "    #        grid_type='modis',\n",
    "    #        meanflag=False,\n",
    "    #        saveflag=False,\n",
    "    #        units='SCF',\n",
    "    #        plot_title=f\"{fname} over CONUS:\\n MODIS SCF {date.strftime('%Y-%m-%d')}\")\n",
    "    \n",
    "    # # Convert final dictionary to arrays\n",
    "    # lats, lons = zip(*scf_dict.keys())\n",
    "    # scfs = list(scf_dict.values())\n",
    "    # scf_array = np.array([scfs, lons, lats]).T\n",
    "\n",
    "    # # Plot the final dictionary\n",
    "    # plot_region(scf_array, \n",
    "    #         lon_min, lon_max,\n",
    "    #         lat_min, lat_max,\n",
    "    #         grid_type='modis',\n",
    "    #         meanflag=True,\n",
    "    #         saveflag=False,\n",
    "    #         units='SCF',\n",
    "    #         plot_title=f\"Max MODIS SCF over CONUS:\\n MODIS SCF {date.strftime('%Y-%m')}\")\n",
    "    \n",
    "\n",
    "# Convert final dictionary to arrays\n",
    "lats, lons = zip(*scf_dict.keys())\n",
    "scfs = list(scf_dict.values())\n",
    "scf_array = np.array([scfs, lons, lats]).T\n",
    "\n",
    "# Plot the final dictionary\n",
    "plot_region_scatter(scf_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=True,\n",
    "        saveflag=False,\n",
    "        units='SCF',\n",
    "        plot_title=f\"Max MYD10C1 SCF over CONUS:\\n MODIS SCF {date.strftime('%B %Y')}\",\n",
    "        point_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage over Greenbelt\n",
    "# lon_value = -76.87\n",
    "# lat_value = 39.0\n",
    "\n",
    "lon_min = -77.87\n",
    "lon_max = -75.87\n",
    "lat_min = 38.0\n",
    "lat_max = 40.0\n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "scf_dict = {}\n",
    "count_dict = {}\n",
    "gt09_dict = {}\n",
    "\n",
    "\n",
    "for i in range(182, 213):\n",
    "    fname = f\"MOD10C1.A2005{i:03d}.061.hdf\"\n",
    "    path_fname = os.path.join(path, fname)\n",
    "    date = parse_modis_filename(fname)\n",
    "    \n",
    "    # Read the data\n",
    "    lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "    # Update dictionary with higher values\n",
    "    for lon, lat, scf in zip(lon_out, lat_out, scf_out):\n",
    "        key = (lat, lon)\n",
    "\n",
    "        # Track max SCF per pixel\n",
    "        if key not in scf_dict or scf > scf_dict[key]:\n",
    "            scf_dict[key] = scf\n",
    "\n",
    "        # Count all observations\n",
    "        count_dict[key] = count_dict.get(key, 0) + 1   \n",
    "\n",
    "        # Count SCF > 0.9\n",
    "        if scf > 0.9:\n",
    "            gt09_dict[key] = gt09_dict.get(key, 0) + 1\n",
    "\n",
    "    map_array = np.zeros((len(lon_out), 3))\n",
    "    map_array[:, 1] = lon_out\n",
    "    map_array[:, 2] = lat_out\n",
    "    map_array[:, 0] = scf_out\n",
    "\n",
    "    plot_region_scatter(map_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='SCF',\n",
    "        plot_title=f\"MOD10C1 SCF over Mid-Atlantic: {date.strftime('%Y-%m-%d')}\",\n",
    "        star_lon=-76.87,\n",
    "        star_lat=39.0,\n",
    "        point_size=50,\n",
    "        cmin=0,\n",
    "        cmax=1)  \n",
    "    \n",
    "# Extract to arrays\n",
    "lats, lons, scfs, counts, gt09s = [], [], [], [], []\n",
    "for (lat, lon), scf in scf_dict.items():\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "    scfs.append(scf)\n",
    "    counts.append(count_dict[(lat, lon)])\n",
    "    gt09s.append(gt09_dict.get((lat, lon), 0))\n",
    "\n",
    "scf_array = np.array([scfs, lons, lats]).T\n",
    "count_array = np.array([counts, lons, lats]).T\n",
    "gt09_array = np.array([gt09s, lons, lats]).T    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the final dictionary\n",
    "plot_region_scatter(scf_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='SCF',\n",
    "        plot_title=f\"Max Monthly MOD10C1 SCF over Mid-Atlantic:\\n {date.strftime('%Y-%m')}\",\n",
    "        star_lon=-76.87,\n",
    "        star_lat=39.0,\n",
    "        point_size=50,\n",
    "        cmin=0,\n",
    "        cmax=1,\n",
    "        cmap='Blues')    \n",
    "\n",
    "# Plot the final dictionary\n",
    "plot_region_scatter(scf_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='SCF',\n",
    "        plot_title=f\"Max MOD10C1 over Mid-Atlantic:\\n {date.strftime('%B %Y')}\",\n",
    "        star_lon=-76.87,\n",
    "        star_lat=39.0,\n",
    "        point_size=80,\n",
    "        cmin=0,\n",
    "        cmax=1)    \n",
    "\n",
    "\n",
    "# Plot the final dictionary\n",
    "plot_region_scatter(count_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='Number',\n",
    "        plot_title=f\"Number of MOD10C1 over Mid-Atlantic:\\n {date.strftime('%B %Y')}\",\n",
    "        star_lon=-76.87,\n",
    "        star_lat=39.0,\n",
    "        point_size=80,\n",
    "        cmin=0,\n",
    "        cmax=28)  \n",
    "\n",
    "# Plot the final dictionary\n",
    "plot_region_scatter(gt09_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='Number',\n",
    "        plot_title=f\"Number of MOD10C1 > 0.9 over Mid-Atlantic:\\n {date.strftime('%B %Y')}\",\n",
    "        star_lon=-76.87,\n",
    "        star_lat=39.0,\n",
    "        point_size=80,\n",
    "        cmin=0,\n",
    "        cmax=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage over CONUS\n",
    "lon_min = -95.0\n",
    "lon_max = -75.0\n",
    "lat_min = 29.0\n",
    "lat_max = 41.0\n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "scf_dict = {}\n",
    "count_dict = {}\n",
    "gt09_dict = {}\n",
    "\n",
    "\n",
    "for i in range(182, 213):\n",
    "    fname = f\"MOD10C1.A2005{i:03d}.061.hdf\"\n",
    "    path_fname = os.path.join(path, fname)\n",
    "    date = parse_modis_filename(fname)\n",
    "    \n",
    "    # Read the data\n",
    "    lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max)\n",
    "\n",
    "    # Update dictionary with higher values\n",
    "    for lon, lat, scf in zip(lon_out, lat_out, scf_out):\n",
    "        key = (lat, lon)\n",
    "\n",
    "        # Track max SCF per pixel\n",
    "        if key not in scf_dict or scf > scf_dict[key]:\n",
    "            scf_dict[key] = scf\n",
    "\n",
    "        # Count all observations\n",
    "        count_dict[key] = count_dict.get(key, 0) + 1   \n",
    "\n",
    "        # Count SCF > 0.9\n",
    "        if scf > 0.9:\n",
    "            gt09_dict[key] = gt09_dict.get(key, 0) + 1\n",
    "\n",
    "    map_array = np.zeros((len(lon_out), 3))\n",
    "    map_array[:, 1] = lon_out\n",
    "    map_array[:, 2] = lat_out\n",
    "    map_array[:, 0] = scf_out\n",
    "\n",
    "    plot_region_scatter(map_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='SCF',\n",
    "        plot_title=f\"MOD10C1 SCF over Southeastern US: {date.strftime('%Y-%m-%d')}\",\n",
    "        point_size=6,\n",
    "        cmin=0,\n",
    "        cmax=1)  \n",
    "    \n",
    "# Extract to arrays\n",
    "lats, lons, scfs, counts, gt09s = [], [], [], [], []\n",
    "for (lat, lon), scf in scf_dict.items():\n",
    "    lats.append(lat)\n",
    "    lons.append(lon)\n",
    "    scfs.append(scf)\n",
    "    counts.append(count_dict[(lat, lon)])\n",
    "    gt09s.append(gt09_dict.get((lat, lon), 0))\n",
    "\n",
    "scf_array = np.array([scfs, lons, lats]).T\n",
    "count_array = np.array([counts, lons, lats]).T\n",
    "gt09_array = np.array([gt09s, lons, lats]).T   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the final dictionary\n",
    "plot_region_scatter(scf_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='SCF',\n",
    "        plot_title=f\"Max MOD10C1 over Southeastern US:\\n {date.strftime('%B %Y')}\",\n",
    "        point_size=6,\n",
    "        cmin=0,\n",
    "        cmax=1)    \n",
    "\n",
    "\n",
    "# Plot the final dictionary\n",
    "plot_region_scatter(count_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='Number',\n",
    "        plot_title=f\"Number of MOD10C1 over Southeastern US:\\n {date.strftime('%B %Y')}\",\n",
    "        point_size=6,\n",
    "        cmin=0,\n",
    "        cmax=28)  \n",
    "\n",
    "# Plot the final dictionary\n",
    "plot_region_scatter(gt09_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='Number',\n",
    "        plot_title=f\"Number of MOD10C1 > 0.9 over Southeastern US:\\n {date.strftime('%B %Y')}\",\n",
    "        point_size=6,\n",
    "        cmin=0,\n",
    "        cmax=2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage over CONUS\n",
    "lon_min = -95.0\n",
    "lon_max = -75.0\n",
    "lat_min = 29.0\n",
    "lat_max = 41.0\n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "# Initialize storage for each clear_idx iteration\n",
    "results = {}\n",
    "\n",
    "for clear_idx in [10, 20, 50, 90]:\n",
    "\n",
    "    scf_dict = {}\n",
    "    count_dict = {}\n",
    "    gt09_dict = {}\n",
    "\n",
    "\n",
    "    for i in range(182, 213):\n",
    "        fname = f\"MOD10C1.A2005{i:03d}.061.hdf\"\n",
    "        path_fname = os.path.join(path, fname)\n",
    "        date = parse_modis_filename(fname)\n",
    "        \n",
    "        # Read the data\n",
    "        lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max, clear_index=clear_idx)\n",
    "\n",
    "        # Update dictionary with higher values\n",
    "        for lon, lat, scf in zip(lon_out, lat_out, scf_out):\n",
    "            key = (lat, lon)\n",
    "\n",
    "            # Track max SCF per pixel\n",
    "            if key not in scf_dict or scf > scf_dict[key]:\n",
    "                scf_dict[key] = scf\n",
    "\n",
    "            # Count all observations\n",
    "            count_dict[key] = count_dict.get(key, 0) + 1   \n",
    "\n",
    "            # Count SCF > 0.9\n",
    "            if scf > 0.9:\n",
    "                gt09_dict[key] = gt09_dict.get(key, 0) + 1\n",
    "        \n",
    "    # Extract to arrays\n",
    "    lats, lons, scfs, counts, gt09s = [], [], [], [], []\n",
    "    for (lat, lon), scf in scf_dict.items():\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "        scfs.append(scf)\n",
    "        counts.append(count_dict[(lat, lon)])\n",
    "        gt09s.append(gt09_dict.get((lat, lon), 0))\n",
    "\n",
    "    scf_array = np.array([scfs, lons, lats]).T\n",
    "    count_array = np.array([counts, lons, lats]).T\n",
    "    gt09_array = np.array([gt09s, lons, lats]).T \n",
    "   \n",
    "    # Plot the final dictionary\n",
    "    plot_region_scatter(scf_array, \n",
    "            lon_min, lon_max,\n",
    "            lat_min, lat_max,\n",
    "            grid_type='modis',\n",
    "            meanflag=False,\n",
    "            saveflag=False,\n",
    "            units='SCF',\n",
    "            plot_title=f\"Max MOD10C1 over Southeastern US: {date.strftime('%B %Y')}\\n  QC_Clear_Index_Min: {clear_idx}\",\n",
    "            point_size=6,\n",
    "            cmin=0,\n",
    "            cmax=1)    \n",
    "\n",
    "    # Plot the final dictionary\n",
    "    plot_region_scatter(count_array, \n",
    "            lon_min, lon_max,\n",
    "            lat_min, lat_max,\n",
    "            grid_type='modis',\n",
    "            meanflag=False,\n",
    "            saveflag=False,\n",
    "            units='Number',\n",
    "            plot_title=f\"Number of MOD10C1 over Southeastern US: {date.strftime('%B %Y')}\\n  QC_Clear_Index_Min: {clear_idx}\",\n",
    "            point_size=6,\n",
    "            cmin=0,\n",
    "            cmax=28)  \n",
    "\n",
    "    # Plot the final dictionary\n",
    "    plot_region_scatter(gt09_array, \n",
    "            lon_min, lon_max,\n",
    "            lat_min, lat_max,\n",
    "            grid_type='modis',\n",
    "            meanflag=False,\n",
    "            saveflag=False,\n",
    "            units='Number',\n",
    "            plot_title=f\"Number of MOD10C1 > 0.9 over Southeastern US: {date.strftime('%B %Y')}\\n  QC_Clear_Index_Min: {clear_idx}\",\n",
    "            point_size=6,\n",
    "            cmin=0,\n",
    "            cmax=2) \n",
    "\n",
    "    # Store arrays for this clear_idx in dictionary\n",
    "    results[clear_idx] = {\n",
    "        'lons': np.array(lons),\n",
    "        'lats': np.array(lats),\n",
    "        'scfs': np.array(scfs),\n",
    "        'counts': np.array(counts)\n",
    "    }\n",
    "\n",
    "# Now results[clear_idx] contains all arrays for that threshold\n",
    "# Example access: results[20]['scfs'] gets SCF values for clear_idx=20    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Usage over CONUS\n",
    "lon_min = -95.0\n",
    "lon_max = -75.0\n",
    "lat_min = 29.0\n",
    "lat_max = 41.0\n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "# Initialize storage for each clear_idx iteration\n",
    "results = {}\n",
    "\n",
    "for clear_idx in range(0, 96, 5):\n",
    "\n",
    "    scf_dict = {}     # highest SCF per pixel\n",
    "    count_dict = {}   # total observations per pixel\n",
    "    gt09_dict = {}    # count of SCF > 0.9 per pixel\n",
    "\n",
    "    for i in range(182, 213):  \n",
    "        fname = f\"MOD10C1.A2005{i:03d}.061.hdf\" \n",
    "        path_fname = os.path.join(path, fname)\n",
    "        date = parse_modis_filename(fname)\n",
    "        \n",
    "        # Read the data\n",
    "        lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max, clear_index=clear_idx)\n",
    "\n",
    "        # Update dictionary with higher values\n",
    "        for lon, lat, scf in zip(lon_out, lat_out, scf_out):\n",
    "            key = (lat, lon)\n",
    "\n",
    "            # Track max SCF per pixel\n",
    "            if key not in scf_dict or scf > scf_dict[key]:\n",
    "                scf_dict[key] = scf\n",
    "\n",
    "            # Count all observations\n",
    "            count_dict[key] = count_dict.get(key, 0) + 1   \n",
    "\n",
    "            # Count SCF > 0.9\n",
    "            if scf > 0.9:\n",
    "                gt09_dict[key] = gt09_dict.get(key, 0) + 1\n",
    "\n",
    "    # Extract to arrays\n",
    "    lats, lons, scfs, counts, gt09s = [], [], [], [], []\n",
    "    for (lat, lon), scf in scf_dict.items():\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "        scfs.append(scf)\n",
    "        counts.append(count_dict[(lat, lon)])\n",
    "        gt09s.append(gt09_dict.get((lat, lon), 0))\n",
    "\n",
    "    # Store arrays for this clear_idx in dictionary\n",
    "    results[clear_idx] = {\n",
    "        'lons': np.array(lons),\n",
    "        'lats': np.array(lats),\n",
    "        'scfs': np.array(scfs),\n",
    "        'counts': np.array(counts),\n",
    "        'gt09': np.array(gt09s)\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage over CONUS - repeat with different spatial qc\n",
    "lon_min = -95.0\n",
    "lon_max = -75.0\n",
    "lat_min = 29.0\n",
    "lat_max = 41.0\n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "# Initialize storage for each clear_idx iteration\n",
    "results_spatial_qc = {}\n",
    "\n",
    "for clear_idx in range(0, 96, 5):\n",
    "\n",
    "    scf_dict = {}     # highest SCF per pixel\n",
    "    count_dict = {}   # total observations per pixel\n",
    "    gt09_dict = {}    # count of SCF > 0.9 per pixel\n",
    "\n",
    "    for i in range(182, 213):  \n",
    "        fname = f\"MOD10C1.A2005{i:03d}.061.hdf\" \n",
    "        path_fname = os.path.join(path, fname)\n",
    "        date = parse_modis_filename(fname)\n",
    "        \n",
    "        # Read the data\n",
    "        lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max, \n",
    "                                                       clear_index=clear_idx, snow_spatial=1)\n",
    "\n",
    "        # Update dictionary with higher values\n",
    "        for lon, lat, scf in zip(lon_out, lat_out, scf_out):\n",
    "            key = (lat, lon)\n",
    "\n",
    "            # Track max SCF per pixel\n",
    "            if key not in scf_dict or scf > scf_dict[key]:\n",
    "                scf_dict[key] = scf\n",
    "\n",
    "            # Count all observations\n",
    "            count_dict[key] = count_dict.get(key, 0) + 1   \n",
    "\n",
    "            # Count SCF > 0.9\n",
    "            if scf > 0.9:\n",
    "                gt09_dict[key] = gt09_dict.get(key, 0) + 1\n",
    "\n",
    "    # Extract to arrays\n",
    "    lats, lons, scfs, counts, gt09s = [], [], [], [], []\n",
    "    for (lat, lon), scf in scf_dict.items():\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "        scfs.append(scf)\n",
    "        counts.append(count_dict[(lat, lon)])\n",
    "        gt09s.append(gt09_dict.get((lat, lon), 0))\n",
    "\n",
    "    # Store arrays for this clear_idx in dictionary\n",
    "    results_spatial_qc[clear_idx] = {\n",
    "        'lons': np.array(lons),\n",
    "        'lats': np.array(lats),\n",
    "        'scfs': np.array(scfs),\n",
    "        'counts': np.array(counts),\n",
    "        'gt09': np.array(gt09s)\n",
    "    }        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate metrics for each clear_idx\n",
    "clear_idx_values = sorted(results.keys())\n",
    "total_obs = []\n",
    "total_gt09 = []\n",
    "\n",
    "for idx in clear_idx_values:\n",
    "    total_obs.append(np.sum(results[idx]['counts']))\n",
    "    total_gt09.append(np.sum(results[idx]['gt09']))\n",
    "\n",
    "# Create figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot data\n",
    "line1 = ax1.plot(clear_idx_values, total_gt09, 'b-o', label='Total SCF > 0.9')\n",
    "line2 = ax2.plot(clear_idx_values, total_obs, 'r-s', label='Total Observations')\n",
    "\n",
    "# Customize axes\n",
    "ax1.set_xlabel('Clear Index Threshold')\n",
    "ax1.set_ylabel('Number of SCF > 0.9', color='b')\n",
    "ax2.set_ylabel('Total Observations', color='r')\n",
    "\n",
    "# Add grid aligned with the first y-axis\n",
    "ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "plt.title(f'SCF > 0.9 Counts and Total Observations vs Clear Index Threshold \\n {date.strftime(\"%B %Y\")} over the Southestern US')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for each clear_idx\n",
    "clear_idx_values = sorted(results.keys())\n",
    "total_obs = []\n",
    "total_gt09 = []\n",
    "\n",
    "for idx in clear_idx_values:\n",
    "    total_obs.append(np.sum(results[idx]['counts']))\n",
    "    total_gt09.append(np.sum(results[idx]['gt09']))\n",
    "\n",
    "# Normalize values\n",
    "total_gt09_normalized = [value / max(total_gt09) * 100 for value in total_gt09]\n",
    "total_obs_normalized = [value / max(total_obs) * 100 for value in total_obs]\n",
    "\n",
    "# Create figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot normalized data\n",
    "line1 = ax1.plot(clear_idx_values, total_gt09_normalized, 'b-o', label='Total SCF > 0.9 (Normalized)')\n",
    "line2 = ax2.plot(clear_idx_values, total_obs_normalized, 'r-s', label='Total Observations (Normalized)')\n",
    "\n",
    "# Customize axes\n",
    "ax1.set_xlabel('Clear Index Threshold')\n",
    "ax1.set_ylabel('SCF > 0.9 (% of Max)', color='b')\n",
    "ax2.set_ylabel('Total Observations (% of Max)', color='r')\n",
    "\n",
    "# Add grid aligned with the first y-axis\n",
    "ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "plt.title(f'Normalized SCF > 0.9 Counts and Total Observations vs Clear Index Threshold \\n {date.strftime(\"%B %Y\")} over the Southeastern US')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage over Tibet\n",
    "lon_min = 75.0 #70.0\n",
    "lon_max = 95.0 #105.0\n",
    "lat_min = 27.0\n",
    "lat_max = 39.0\n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "start_doy = 182 # 60\n",
    "end_doy = 213 # 90\n",
    "\n",
    "# Initialize storage for each clear_idx iteration\n",
    "results = {}\n",
    "\n",
    "for clear_idx in range(0, 96, 5):\n",
    "\n",
    "    print(f\"Processing clear index: {clear_idx}\")\n",
    "\n",
    "    scf_dict = {}     # highest SCF per pixel\n",
    "    count_dict = {}   # total observations per pixel\n",
    "    gt09_dict = {}    # count of SCF > 0.9 per pixel\n",
    "\n",
    "    for i in range(start_doy, end_doy):  \n",
    "        fname = f\"MOD10C1.A2005{i:03d}.061.hdf\" \n",
    "        path_fname = os.path.join(path, fname)\n",
    "        date = parse_modis_filename(fname)\n",
    "        \n",
    "        # Read the data\n",
    "        lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max, clear_index=clear_idx)\n",
    "\n",
    "        # Update dictionary with higher values\n",
    "        for lon, lat, scf in zip(lon_out, lat_out, scf_out):\n",
    "            key = (lat, lon)\n",
    "\n",
    "            # Track max SCF per pixel\n",
    "            if key not in scf_dict or scf > scf_dict[key]:\n",
    "                scf_dict[key] = scf\n",
    "\n",
    "            # Count all observations\n",
    "            count_dict[key] = count_dict.get(key, 0) + 1   \n",
    "\n",
    "            # Count SCF > 0.9\n",
    "            if scf > 0.9:\n",
    "                gt09_dict[key] = gt09_dict.get(key, 0) + 1\n",
    "\n",
    "    # Extract to arrays\n",
    "    lats, lons, scfs, counts, gt09s = [], [], [], [], []\n",
    "    for (lat, lon), scf in scf_dict.items():\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "        scfs.append(scf)\n",
    "        counts.append(count_dict[(lat, lon)])\n",
    "        gt09s.append(gt09_dict.get((lat, lon), 0))\n",
    "\n",
    "    # Store arrays for this clear_idx in dictionary\n",
    "    results[clear_idx] = {\n",
    "        'lons': np.array(lons),\n",
    "        'lats': np.array(lats),\n",
    "        'scfs': np.array(scfs),\n",
    "        'counts': np.array(counts),\n",
    "        'gt09': np.array(gt09s)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_idx = 20\n",
    "gt09_array = np.array([results[clear_idx]['gt09'], results[clear_idx]['lons'], results[clear_idx]['lats']]).T \n",
    "\n",
    "\n",
    "# Plot the final dictionary\n",
    "plot_region_scatter(gt09_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='Number',\n",
    "        plot_title=f\"Number of MOD10C1 > 0.9 over Tibetan Plateau: {date.strftime('%B %Y')}\\n  QC_Clear_Index_Min: {clear_idx}\",\n",
    "        point_size=6,\n",
    "        cmin=0,\n",
    "        cmax=8) \n",
    "\n",
    "\n",
    "# Calculate metrics for each clear_idx\n",
    "clear_idx_values = sorted(results.keys())\n",
    "total_obs = []\n",
    "total_gt09 = []\n",
    "\n",
    "for idx in clear_idx_values:\n",
    "    total_obs.append(np.sum(results[idx]['counts']))\n",
    "    total_gt09.append(np.sum(results[idx]['gt09']))\n",
    "\n",
    "# Normalize values\n",
    "total_gt09_normalized = [value / max(total_gt09) * 100 for value in total_gt09]\n",
    "total_obs_normalized = [value / max(total_obs) * 100 for value in total_obs]\n",
    "\n",
    "# Create figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot data\n",
    "line1 = ax1.plot(clear_idx_values, total_gt09, 'b-o', label='Total SCF > 0.9')\n",
    "line2 = ax2.plot(clear_idx_values, total_obs, 'r-s', label='Total Observations')\n",
    "\n",
    "# Customize axes\n",
    "ax1.set_xlabel('Clear Index Threshold')\n",
    "ax1.set_ylabel('Number of SCF > 0.9', color='b')\n",
    "ax2.set_ylabel('Total Observations', color='r')\n",
    "\n",
    "# Add grid aligned with the first y-axis\n",
    "ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "plt.title(f'SCF > 0.9 Counts and Total Observations vs Clear Index Threshold \\n {date.strftime(\"%B %Y\")} over the Tibetan Plateau')\n",
    "plt.show()\n",
    "\n",
    "# Create figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot normalized data\n",
    "line1 = ax1.plot(clear_idx_values, total_gt09_normalized, 'b-o', label='Total SCF > 0.9 (Normalized)')\n",
    "line2 = ax2.plot(clear_idx_values, total_obs_normalized, 'r-s', label='Total Observations (Normalized)')\n",
    "\n",
    "# Customize axes\n",
    "ax1.set_xlabel('Clear Index Threshold')\n",
    "ax1.set_ylabel('Number of SCF > 0.9 (% of Max)', color='b')\n",
    "ax2.set_ylabel('Total Observations (% of Max)', color='r')\n",
    "\n",
    "# Add grid aligned with the first y-axis\n",
    "ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "plt.title(f'Normalized SCF > 0.9 Counts and Total Observations vs Clear Index Threshold \\n {date.strftime(\"%B %Y\")} over the Tibetan Plateau')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage over western Europe\n",
    "lon_min = -5.0\n",
    "lon_max = 15.0\n",
    "lat_min = 43.0\n",
    "lat_max = 55.0\n",
    "\n",
    "start_doy = 182 # 60\n",
    "end_doy = 213 # 90\n",
    "\n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "# Initialize storage for each clear_idx iteration\n",
    "results = {}\n",
    "\n",
    "for clear_idx in range(0, 96, 5):\n",
    "\n",
    "    print(f\"Processing clear index: {clear_idx}\")\n",
    "\n",
    "    scf_dict = {}     # highest SCF per pixel\n",
    "    count_dict = {}   # total observations per pixel\n",
    "    gt09_dict = {}    # count of SCF > 0.9 per pixel\n",
    "\n",
    "    for i in range(start_doy, end_doy):  \n",
    "        fname = f\"MOD10C1.A2005{i:03d}.061.hdf\" \n",
    "        path_fname = os.path.join(path, fname)\n",
    "        date = parse_modis_filename(fname)\n",
    "        \n",
    "        # Read the data\n",
    "        lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max, clear_index=clear_idx)\n",
    "\n",
    "        # Update dictionary with higher values\n",
    "        for lon, lat, scf in zip(lon_out, lat_out, scf_out):\n",
    "            key = (lat, lon)\n",
    "\n",
    "            # Track max SCF per pixel\n",
    "            if key not in scf_dict or scf > scf_dict[key]:\n",
    "                scf_dict[key] = scf\n",
    "\n",
    "            # Count all observations\n",
    "            count_dict[key] = count_dict.get(key, 0) + 1   \n",
    "\n",
    "            # Count SCF > 0.9\n",
    "            if scf > 0.9:\n",
    "                gt09_dict[key] = gt09_dict.get(key, 0) + 1\n",
    "\n",
    "    # Extract to arrays\n",
    "    lats, lons, scfs, counts, gt09s = [], [], [], [], []\n",
    "    for (lat, lon), scf in scf_dict.items():\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "        scfs.append(scf)\n",
    "        counts.append(count_dict[(lat, lon)])\n",
    "        gt09s.append(gt09_dict.get((lat, lon), 0))\n",
    "\n",
    "    # Store arrays for this clear_idx in dictionary\n",
    "    results[clear_idx] = {\n",
    "        'lons': np.array(lons),\n",
    "        'lats': np.array(lats),\n",
    "        'scfs': np.array(scfs),\n",
    "        'counts': np.array(counts),\n",
    "        'gt09': np.array(gt09s)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_idx = 20\n",
    "gt09_array = np.array([results[clear_idx]['gt09'], results[clear_idx]['lons'], results[clear_idx]['lats']]).T \n",
    "\n",
    "\n",
    "# Plot the final dictionary\n",
    "plot_region_scatter(gt09_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='Number',\n",
    "        plot_title=f\"Number of MOD10C1 > 0.9 over Western Europe: {date.strftime('%B %Y')}\\n  QC_Clear_Index_Min: {clear_idx}\",\n",
    "        point_size=6,\n",
    "        cmin=0,\n",
    "        cmax=2) \n",
    "\n",
    "\n",
    "# Calculate metrics for each clear_idx\n",
    "clear_idx_values = sorted(results.keys())\n",
    "total_obs = []\n",
    "total_gt09 = []\n",
    "\n",
    "for idx in clear_idx_values:\n",
    "    total_obs.append(np.sum(results[idx]['counts']))\n",
    "    total_gt09.append(np.sum(results[idx]['gt09']))\n",
    "\n",
    "# Normalize values\n",
    "total_gt09_normalized = [value / max(total_gt09) * 100 for value in total_gt09]\n",
    "total_obs_normalized = [value / max(total_obs) * 100 for value in total_obs]\n",
    "\n",
    "# Create figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot data\n",
    "line1 = ax1.plot(clear_idx_values, total_gt09, 'b-o', label='Total SCF > 0.9')\n",
    "line2 = ax2.plot(clear_idx_values, total_obs, 'r-s', label='Total Observations')\n",
    "\n",
    "# Customize axes\n",
    "ax1.set_xlabel('Clear Index Threshold')\n",
    "ax1.set_ylabel('Number of SCF > 0.9', color='b')\n",
    "ax2.set_ylabel('Total Observations', color='r')\n",
    "\n",
    "# Add grid aligned with the first y-axis\n",
    "ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "plt.title(f'SCF > 0.9 Counts and Total Observations vs Clear Index Threshold \\n {date.strftime(\"%B %Y\")} over the Western Europe')\n",
    "plt.show()\n",
    "\n",
    "# Create figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot normalized data\n",
    "line1 = ax1.plot(clear_idx_values, total_gt09_normalized, 'b-o', label='Total SCF > 0.9 (Normalized)')\n",
    "line2 = ax2.plot(clear_idx_values, total_obs_normalized, 'r-s', label='Total Observations (Normalized)')\n",
    "\n",
    "# Customize axes\n",
    "ax1.set_xlabel('Clear Index Threshold')\n",
    "ax1.set_ylabel('Number of SCF > 0.9 (% of Max)', color='b')\n",
    "ax2.set_ylabel('Total Observations (% of Max)', color='r')\n",
    "\n",
    "# Add grid aligned with the first y-axis\n",
    "ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "plt.title(f'Normalized SCF > 0.9 Counts and Total Observations vs Clear Index Threshold \\n {date.strftime(\"%B %Y\")} over the Western Europe')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage over Southeastern US\n",
    "lon_min = -95.0\n",
    "lon_max = -75.0\n",
    "lat_min = 29.0\n",
    "lat_max = 41.0\n",
    "\n",
    "start_doy = 182 # 60\n",
    "end_doy = 213 # 90\n",
    " \n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "# Initialize storage for each clear_idx iteration\n",
    "results = {}\n",
    "\n",
    "for clear_idx in range(0, 96, 5):\n",
    "\n",
    "    print(f\"Processing clear index: {clear_idx}\")\n",
    "\n",
    "    scf_dict = {}     # highest SCF per pixel\n",
    "    count_dict = {}   # total observations per pixel\n",
    "    gt09_dict = {}    # count of SCF > 0.9 per pixel\n",
    "\n",
    "    for i in range(start_doy, end_doy):  \n",
    "        fname = f\"MOD10C1.A2005{i:03d}.061.hdf\" \n",
    "        path_fname = os.path.join(path, fname)\n",
    "        date = parse_modis_filename(fname)\n",
    "        \n",
    "        # Read the data\n",
    "        lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max, clear_index=clear_idx)\n",
    "\n",
    "        # Update dictionary with higher values\n",
    "        for lon, lat, scf in zip(lon_out, lat_out, scf_out):\n",
    "            key = (lat, lon)\n",
    "\n",
    "            # Track max SCF per pixel\n",
    "            if key not in scf_dict or scf > scf_dict[key]:\n",
    "                scf_dict[key] = scf\n",
    "\n",
    "            # Count all observations\n",
    "            count_dict[key] = count_dict.get(key, 0) + 1   \n",
    "\n",
    "            # Count SCF > 0.9\n",
    "            if scf > 0.9:\n",
    "                gt09_dict[key] = gt09_dict.get(key, 0) + 1\n",
    "\n",
    "    # Extract to arrays\n",
    "    lats, lons, scfs, counts, gt09s = [], [], [], [], []\n",
    "    for (lat, lon), scf in scf_dict.items():\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "        scfs.append(scf)\n",
    "        counts.append(count_dict[(lat, lon)])\n",
    "        gt09s.append(gt09_dict.get((lat, lon), 0))\n",
    "\n",
    "    # Store arrays for this clear_idx in dictionary\n",
    "    results[clear_idx] = {\n",
    "        'lons': np.array(lons),\n",
    "        'lats': np.array(lats),\n",
    "        'scfs': np.array(scfs),\n",
    "        'counts': np.array(counts),\n",
    "        'gt09': np.array(gt09s)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_idx = 90\n",
    "gt09_array = np.array([results[clear_idx]['gt09'], results[clear_idx]['lons'], results[clear_idx]['lats']]).T \n",
    "\n",
    "\n",
    "# Plot the final dictionary\n",
    "plot_region_scatter(gt09_array, \n",
    "        lon_min, lon_max,\n",
    "        lat_min, lat_max,\n",
    "        grid_type='modis',\n",
    "        meanflag=False,\n",
    "        saveflag=False,\n",
    "        units='Number',\n",
    "        plot_title=f\"Number of MOD10C1 > 0.9 over Southeastern US: {date.strftime('%B %Y')}\\n  QC_Clear_Index_Min: {clear_idx}\",\n",
    "        point_size=6,\n",
    "        cmin=0,\n",
    "        cmax=2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Calculate metrics for each clear_idx\n",
    "clear_idx_values = sorted(results.keys())\n",
    "total_obs = []\n",
    "total_gt09 = []\n",
    "\n",
    "for idx in clear_idx_values:\n",
    "    total_obs.append(np.sum(results[idx]['counts']))\n",
    "    total_gt09.append(np.sum(results[idx]['gt09']))\n",
    "\n",
    "# Normalize values\n",
    "total_gt09_normalized = [value / max(total_gt09) * 100 for value in total_gt09]\n",
    "total_obs_normalized = [value / max(total_obs) * 100 for value in total_obs]\n",
    "\n",
    "# Create figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot data\n",
    "line1 = ax1.plot(clear_idx_values, total_gt09, 'b-o', label='Total SCF > 0.9')\n",
    "line2 = ax2.plot(clear_idx_values, total_obs, 'r-s', label='Total Observations')\n",
    "\n",
    "# Customize axes\n",
    "ax1.set_xlabel('Clear Index Threshold')\n",
    "ax1.set_ylabel('Number of SCF > 0.9', color='b')\n",
    "ax2.set_ylabel('Total Observations', color='r')\n",
    "\n",
    "# Add grid aligned with the first y-axis\n",
    "ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "plt.title(f'SCF > 0.9 Counts and Total Observations vs Clear Index Threshold \\n {date.strftime(\"%B %Y\")} over the Southeastern US')\n",
    "plt.show()\n",
    "\n",
    "# Create figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot normalized data\n",
    "line1 = ax1.plot(clear_idx_values, total_gt09_normalized, 'b-o', label='Total SCF > 0.9 (Normalized)')\n",
    "line2 = ax2.plot(clear_idx_values, total_obs_normalized, 'r-s', label='Total Observations (Normalized)')\n",
    "\n",
    "# Customize axes\n",
    "ax1.set_xlabel('Clear Index Threshold')\n",
    "ax1.set_ylabel('Number of SCF > 0.9 (% of Max)', color='b')\n",
    "ax2.set_ylabel('Total Observations (% of Max)', color='r')\n",
    "\n",
    "# Add grid aligned with the first y-axis\n",
    "ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='upper right')\n",
    "\n",
    "plt.title(f'Normalized SCF > 0.9 Counts and Total Observations vs Clear Index Threshold \\n {date.strftime(\"%B %Y\")} over the Southeastern US')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage over CONUS\n",
    "lon_min = -95.0\n",
    "lon_max = -75.0\n",
    "lat_min = 29.0\n",
    "lat_max = 41.0\n",
    "path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/\"\n",
    "\n",
    "start_doy = 182 # 60\n",
    "end_doy = 213 # 90\n",
    "\n",
    "# Initialize storage for each clear_idx iteration\n",
    "results = {}\n",
    "\n",
    "for snow_spatial in [0, 1, 2, 237, 239, 250, 255]:\n",
    "\n",
    "    clear_idx = 20\n",
    "\n",
    "    scf_dict = {}\n",
    "    count_dict = {}\n",
    "    gt09_dict = {}\n",
    "\n",
    "\n",
    "    for i in range(start_doy, end_doy):\n",
    "        fname = f\"MOD10C1.A2005{i:03d}.061.hdf\"\n",
    "        path_fname = os.path.join(path, fname)\n",
    "        date = parse_modis_filename(fname)\n",
    "        \n",
    "        # Read the data\n",
    "        lon_out, lat_out, scf_out = read_modis_scf_hdf(path_fname, lon_min, lon_max, lat_min, lat_max, \n",
    "                                                       clear_index=clear_idx, snow_spatial=snow_spatial)\n",
    "\n",
    "        # Update dictionary with higher values\n",
    "        for lon, lat, scf in zip(lon_out, lat_out, scf_out):\n",
    "            key = (lat, lon)\n",
    "\n",
    "            # Track max SCF per pixel\n",
    "            if key not in scf_dict or scf > scf_dict[key]:\n",
    "                scf_dict[key] = scf\n",
    "\n",
    "            # Count all observations\n",
    "            count_dict[key] = count_dict.get(key, 0) + 1   \n",
    "\n",
    "            # Count SCF > 0.9\n",
    "            if scf > 0.9:\n",
    "                gt09_dict[key] = gt09_dict.get(key, 0) + 1\n",
    "        \n",
    "    # Extract to arrays\n",
    "    lats, lons, scfs, counts, gt09s = [], [], [], [], []\n",
    "    for (lat, lon), scf in scf_dict.items():\n",
    "        lats.append(lat)\n",
    "        lons.append(lon)\n",
    "        scfs.append(scf)\n",
    "        counts.append(count_dict[(lat, lon)])\n",
    "        gt09s.append(gt09_dict.get((lat, lon), 0))\n",
    "\n",
    "    scf_array = np.array([scfs, lons, lats]).T\n",
    "    count_array = np.array([counts, lons, lats]).T\n",
    "    gt09_array = np.array([gt09s, lons, lats]).T \n",
    "   \n",
    "    print(\"Snow_spatial:\", snow_spatial)\n",
    "    print(\"Mean of SCF array:\", np.mean(scf_array[:, 0]))\n",
    "    print(\"Mean of Count array:\", np.mean(count_array[:, 0]))\n",
    "    print(\"Mean of GT09 array:\", np.mean(gt09_array[:, 0]))\n",
    "    print(\"Sum of SCF array:\", np.sum(scf_array[:, 0]))\n",
    "    print(\"Sum of Count array:\", np.sum(count_array[:, 0]))\n",
    "    print(\"Sum of GT09 array:\", np.sum(gt09_array[:, 0]))\n",
    "\n",
    "\n",
    "    # Plot the final dictionary\n",
    "    plot_region_scatter(scf_array, \n",
    "            lon_min, lon_max,\n",
    "            lat_min, lat_max,\n",
    "            grid_type='modis',\n",
    "            meanflag=True,\n",
    "            saveflag=False,\n",
    "            units='SCF',\n",
    "            plot_title=f\"Max MOD10C1 over Southeastern US: {date.strftime('%B %Y')}\\n  QC_Clear_Index_Min: {clear_idx} QC_Snow_Spatial_Max: {snow_spatial}\",\n",
    "            point_size=6,\n",
    "            cmin=0,\n",
    "            cmax=1)    \n",
    "\n",
    "    # Plot the final dictionary\n",
    "    plot_region_scatter(count_array, \n",
    "            lon_min, lon_max,\n",
    "            lat_min, lat_max,\n",
    "            grid_type='modis',\n",
    "            meanflag=True,\n",
    "            saveflag=False,\n",
    "            units='Number',\n",
    "            plot_title=f\"Number of MOD10C1 over Southeastern US: {date.strftime('%B %Y')}\\n  QC_Clear_Index_Min: {clear_idx} QC_Snow_Spatial_Max: {snow_spatial}\",\n",
    "            point_size=6,\n",
    "            cmin=0,\n",
    "            cmax=28)  \n",
    "\n",
    "    # Plot the final dictionary\n",
    "    plot_region_scatter(gt09_array, \n",
    "            lon_min, lon_max,\n",
    "            lat_min, lat_max,\n",
    "            grid_type='modis',\n",
    "            meanflag=True,\n",
    "            saveflag=False,\n",
    "            units='Number',\n",
    "            plot_title=f\"Number of MOD10C1 > 0.9 over Southeastern US: {date.strftime('%B %Y')}\\n  QC_Clear_Index_Min: {clear_idx} QC_Snow_Spatial_Max: {snow_spatial}\",\n",
    "            point_size=6,\n",
    "            cmin=0,\n",
    "            cmax=2) \n",
    "\n",
    "    # Store arrays for this snow_spatial in dictionary\n",
    "    results[snow_spatial] = {\n",
    "        'lons': np.array(lons),\n",
    "        'lats': np.array(lats), \n",
    "        'scfs': np.array(scfs),\n",
    "        'counts': np.array(counts),\n",
    "        'gt09s': np.array(gt09s)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics for each snow_spatial_values\n",
    "snow_spatial_values = sorted(results.keys())\n",
    "total_obs = []\n",
    "total_gt09 = []\n",
    "\n",
    "for idx in snow_spatial_values:\n",
    "    total_obs.append(np.sum(results[idx]['counts']))\n",
    "    total_gt09.append(np.sum(results[idx]['gt09s']))\n",
    "\n",
    "# Normalize values\n",
    "total_gt09_normalized = [value / max(total_gt09) * 100 for value in total_gt09]\n",
    "total_obs_normalized = [value / max(total_obs) * 100 for value in total_obs]\n",
    "\n",
    "# Create figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10,6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Create range for x-axis\n",
    "x_range = np.arange(len(snow_spatial_values))\n",
    "\n",
    "# Plot using x_range but label with snow_spatial_values\n",
    "line1 = ax1.plot(x_range, total_gt09, 'b-o', label='Total SCF > 0.9')\n",
    "line2 = ax2.plot(x_range, total_obs, 'r-s', label='Total Observations')\n",
    "\n",
    "# Set x-ticks to show snow_spatial_values\n",
    "ax1.set_xticks(x_range)\n",
    "ax1.set_xticklabels(snow_spatial_values)\n",
    "\n",
    "# Customize axes\n",
    "ax1.set_xlabel('Snow Spatial Threshold')\n",
    "ax1.set_ylabel('Number of SCF > 0.9', color='b')\n",
    "ax2.set_ylabel('Total Observations', color='r')\n",
    "\n",
    "# Add grid aligned with the first y-axis\n",
    "ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='lower right')\n",
    "\n",
    "plt.title(f'SCF > 0.9 Counts and Total Observations vs Snow Spatial Threshold \\n {date.strftime(\"%B %Y\")} over the Southeastern US')\n",
    "plt.show()\n",
    "\n",
    "# Create figure with two y-axes\n",
    "fig, ax1 = plt.subplots(figsize=(10, 6))\n",
    "ax2 = ax1.twinx()\n",
    "\n",
    "# Plot normalized data\n",
    "line1 = ax1.plot(x_range, total_gt09_normalized, 'b-o', label='Total SCF > 0.9 (Normalized)')\n",
    "line2 = ax2.plot(x_range, total_obs_normalized, 'r-s', label='Total Observations (Normalized)')\n",
    "\n",
    "# Set x-ticks to show snow_spatial_values\n",
    "ax1.set_xticks(x_range)\n",
    "ax1.set_xticklabels(snow_spatial_values)\n",
    "\n",
    "# Customize axes\n",
    "ax1.set_xlabel('Snow Spatial Threshold')\n",
    "ax1.set_ylabel('Number of SCF > 0.9 (% of Max)', color='b')\n",
    "ax2.set_ylabel('Total Observations (% of Max)', color='r')\n",
    "\n",
    "# Add grid aligned with the first y-axis\n",
    "ax1.grid(visible=True, which='both', linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "\n",
    "# Add legend\n",
    "lines = line1 + line2\n",
    "labels = [l.get_label() for l in lines]\n",
    "ax1.legend(lines, labels, loc='lower right')\n",
    "\n",
    "plt.title(f'Normalized SCF > 0.9 Counts and Total Observations vs Snow Spatial Threshold \\n {date.strftime(\"%B %Y\")} over the Southeastern US')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
