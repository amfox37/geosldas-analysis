{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "# Directory containing the .npz files\n",
    "directory_path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg\"\n",
    "\n",
    "# Initialize dictionaries to store time series data\n",
    "time_series_data = {\"time\": []}\n",
    "\n",
    "# Define species names and groups\n",
    "species_names = [\n",
    "    \"blank\", \"SMOS_fit_Tbh_A\", \"SMOS_fit_Tbh_D\", \"SMOS_fit_Tbv_A\", \"SMOS_fit_Tbv_D\",\n",
    "    \"SMAP_L1C_Tbh_A\", \"SMAP_L1C_Tbh_D\", \"SMAP_L1C_Tbv_A\", \"SMAP_L1C_Tbv_D\",\n",
    "    \"ASCAT_META_SM\", \"ASCAT_METB_SM\", \"ASCAT_METC_SM\", \"MYD10C1\", \"MOD10C1\"\n",
    "]\n",
    "\n",
    "species_groups = {\n",
    "    \"SMOS\": [1, 2, 3, 4],\n",
    "    \"SMAP\": [5, 6, 7, 8],\n",
    "    \"ASCAT\": [9, 10, 11],\n",
    "    \"MODIS\": [12, 13]\n",
    "}\n",
    "\n",
    "# Exclude \"blank\" from species names\n",
    "species_time_series = {name: [] for name in species_names if name != \"blank\"}\n",
    "\n",
    "# Initialize cumulative_obs_map outside the loop to ensure it accumulates over iterations\n",
    "cumulative_obs_map = None\n",
    "\n",
    "# Loop through all .npz files in the directory\n",
    "for file_name in sorted(os.listdir(directory_path)):\n",
    "    if file_name.endswith(\".npz\"):\n",
    "        try:\n",
    "            # Parse the time from the file name (e.g., 202303 from LS_DAv8_M36.ens_avg.ldas_ObsFcstAna.summed.202303.npz)\n",
    "            time_str = file_name.split(\".\")[-2]\n",
    "            time = datetime.strptime(time_str, \"%Y%m\")\n",
    "\n",
    "            # Load the .npz file\n",
    "            file_path = os.path.join(directory_path, file_name)\n",
    "            data = np.load(file_path)\n",
    "\n",
    "            # Sum across tiles for each species\n",
    "            species_sum = np.sum(data[\"obs_cnt\"], axis=0)\n",
    "\n",
    "            # Sum data for each group\n",
    "            group_sums = {group: np.sum(species_sum[indices]) for group, indices in species_groups.items()}\n",
    "\n",
    "            # Append the data to the time series for groups\n",
    "            time_series_data[\"time\"].append(time)\n",
    "            for group, total in group_sums.items():\n",
    "                if group not in time_series_data:\n",
    "                    time_series_data[group] = []\n",
    "                time_series_data[group].append(total)\n",
    "\n",
    "            # Append the data to the time series for individual species\n",
    "            for name, total in zip(species_names, species_sum):\n",
    "                if name != \"blank\":\n",
    "                    species_time_series[name].append(total)\n",
    "\n",
    "            # Cumulatively sum for each tile/species to create a map of number of obs per tile\n",
    "            if cumulative_obs_map is None:\n",
    "                cumulative_obs_map = np.zeros_like(data[\"obs_cnt\"])\n",
    "            cumulative_obs_map += data[\"obs_cnt\"]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing file {file_name}: {e}\")\n",
    "\n",
    "# Display the collected time series data for groups\n",
    "print(\"Collected time series data for groups:\")\n",
    "for group, values in time_series_data.items():\n",
    "    print(f\"{group}: {values}\")\n",
    "\n",
    "# Display the collected time series data for individual species\n",
    "print(\"\\nCollected time series data for individual species:\")\n",
    "for species, values in species_time_series.items():\n",
    "    print(f\"{species}: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Exclude the last value in the time series\n",
    "for key in time_series_data.keys():\n",
    "    if isinstance(time_series_data[key], list):\n",
    "        time_series_data[key] = time_series_data[key][:-1]\n",
    "\n",
    "for key in species_time_series.keys():\n",
    "    species_time_series[key] = species_time_series[key][:-1]\n",
    "\n",
    "# Convert time to a sorted list for plotting\n",
    "sorted_indices = sorted(range(len(time_series_data[\"time\"])), key=lambda i: time_series_data[\"time\"][i])\n",
    "sorted_time = [time_series_data[\"time\"][i] for i in sorted_indices]\n",
    "\n",
    "# Plot time series for each group\n",
    "plt.figure(figsize=(10, 6))\n",
    "for group in species_groups.keys():\n",
    "    sorted_values = [time_series_data[group][i] / 1000000 for i in sorted_indices]  # Convert to millions\n",
    "    plt.plot(sorted_time, sorted_values, label=group)\n",
    "\n",
    "    print(f\"Cumulative value for {group}: {(sum(sorted_values) * 1000000) / 112573 }\")\n",
    "\n",
    "# Add labels, legend, and title for groups\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Total Number of Obs per Month (millions)\")\n",
    "plt.title(\"Time Series Plot for Each Group\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"time_series_groups.png\")  # Save the figure\n",
    "plt.show()\n",
    "\n",
    "# Plot time series for individual species\n",
    "plt.figure(figsize=(12, 8))\n",
    "for species in species_time_series.keys():\n",
    "    sorted_values = [species_time_series[species][i] / 1000000 for i in sorted_indices]  # Convert to millions\n",
    "    plt.plot(sorted_time, sorted_values, label=species)\n",
    "\n",
    "# Add labels, legend, and title for individual species\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Total Number of Obs per Month (millions)\")\n",
    "plt.title(\"Time Series Plot for Individual Species\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"time_series_species.png\")  # Save the figure\n",
    "plt.show()\n",
    "\n",
    "# Stacked area plot for groups\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Prepare data for stacking\n",
    "stacked_values = np.array([[time_series_data[group][i] / 1000000 for group in species_groups.keys()] for i in sorted_indices]).T  # Convert to millions\n",
    "labels = list(species_groups.keys())\n",
    "\n",
    "# Plot stacked area chart\n",
    "plt.stackplot(sorted_time, stacked_values, labels=labels, alpha=0.8)\n",
    "\n",
    "# Add labels, legend, and title\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Total Number of Obs per Month (millions)\")\n",
    "plt.title(\"Stacked Area Plot for Groups\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(True)\n",
    "plt.savefig(\"stacked_area_groups.png\")  # Save the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# Initialize dictionaries to store annual means\n",
    "annual_means_groups = defaultdict(list)\n",
    "annual_means_species = defaultdict(list)\n",
    "\n",
    "# Group data by year\n",
    "grouped_by_year = defaultdict(lambda: defaultdict(list))\n",
    "species_grouped_by_year = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "for time, group_values, species_values in zip(time_series_data[\"time\"], \n",
    "                                              zip(*[time_series_data[group] for group in species_groups.keys()]), \n",
    "                                              zip(*[species_time_series[species] for species in species_time_series.keys()])):\n",
    "    year = time.year\n",
    "    for group, value in zip(species_groups.keys(), group_values):\n",
    "        grouped_by_year[year][group].append(value)\n",
    "    for species, value in zip(species_time_series.keys(), species_values):\n",
    "        species_grouped_by_year[year][species].append(value)\n",
    "\n",
    "# Calculate annual means for groups\n",
    "for year, groups in grouped_by_year.items():\n",
    "    for group, values in groups.items():\n",
    "        annual_means_groups[group].append((year, np.mean(values)))\n",
    "\n",
    "# Calculate annual means for individual species\n",
    "for year, species in species_grouped_by_year.items():\n",
    "    for species_name, values in species.items():\n",
    "        annual_means_species[species_name].append((year, np.mean(values)))\n",
    "\n",
    "# Display annual means for groups\n",
    "print(\"Annual means for groups:\")\n",
    "for group, means in annual_means_groups.items():\n",
    "    print(f\"{group}: {[(year, int(mean)) for year, mean in means]}\")\n",
    "\n",
    "# Display annual means for individual species\n",
    "print(\"\\nAnnual means for individual species:\")\n",
    "for species, means in annual_means_species.items():\n",
    "    print(f\"{species}: {[(year, int(mean)) for year, mean in means]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from mapper_functions import plot_global_tight_pcm\n",
    "import numpy as np\n",
    "\n",
    "# Open the dataset for a specific file that contains lat/lon for M36 grid\n",
    "ds_latlon = xr.open_dataset('DAv7_M36.inst3_1d_lndfcstana_Nt.20150901.nc4')\n",
    "\n",
    "# Extract longitude and latitude variables\n",
    "lon = ds_latlon['lon']\n",
    "lat = ds_latlon['lat']\n",
    "\n",
    "# Determine the number of tiles based on the latitude array\n",
    "n_tile = len(lat)\n",
    "\n",
    "# Initialize an observation array with NaN values\n",
    "# The array has dimensions [n_tile, 3], where:\n",
    "# - Column 0 is reserved for future use\n",
    "# - Column 1 stores longitude values\n",
    "# - Column 2 stores latitude values\n",
    "map_array = np.empty([n_tile, 3])\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 1] = lon\n",
    "map_array[:, 2] = lat\n",
    "\n",
    "map_array[:, 0] = np.sum(cumulative_obs_map[1:, :4], axis=1)\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0]) \n",
    "minval = np.nanmin(map_array[:, 0]) \n",
    "plot_global_tight_pcm(map_array,False, True,f'Total SMOS obs (Max: {maxval:.3g} Min: {minval:.3g})','mm', 1, 2000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
