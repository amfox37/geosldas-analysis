{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = '1e_LS_DAv8_M36_debug'\n",
    "\n",
    "start_date = datetime(2002, 10, 1)\n",
    "end_date = datetime(2002, 10, 11)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y/%m/%d')\n",
    "end_date_str = end_date.strftime('%Y/%m/%d')\n",
    "\n",
    "# Define the path directory\n",
    "directory = f'/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/snow_qc_expts/1e_LS_DAv8_M36_0/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/cat/ens0000/Y2002/M10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tile_number = 3438 # 81728 # 77787  # Tile number for which to plot the time series\n",
    "\n",
    "tile_index = tile_number - 1 # Adjust for zero-based indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = os.path.join(directory, '*debug.catch_progn_incr*')\n",
    "\n",
    "files = glob.glob(pattern)\n",
    "\n",
    "# Filter files based on the date range\n",
    "filtered_files = []\n",
    "for file in files:\n",
    "    # Extract the date part from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    print(f'Processing file: {filename}')\n",
    "    parts = filename.split('.')\n",
    "    if len(parts) >= 3:\n",
    "        date_str = parts[-2]  # '20021002'\n",
    "        try:\n",
    "            file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse date from {date_str}\")\n",
    "    else:\n",
    "        print(\"Filename format not recognized\")\n",
    "\n",
    "    # Check if the file date is within the range\n",
    "    if start_date <= file_date < end_date:\n",
    "        filtered_files.append(file)\n",
    "\n",
    "# Load the data \n",
    "ds = xr.open_mfdataset(filtered_files, combine='nested', concat_dim=\"time\")\n",
    "ds = ds.sortby('time_stamp')\n",
    "\n",
    "# Convert DataArray to numpy array, then to strings\n",
    "time_strs = ds['time_stamp'].values.astype(str)\n",
    "\n",
    "# Convert to datetime objects\n",
    "time_objs = [datetime.strptime(ts, \"%Y%m%d_%H%Mz\") for ts in time_strs]\n",
    "\n",
    "print(time_objs[11])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the new pattern for the dataset\n",
    "pattern_debug2 = os.path.join(directory, '*debug2.catch_progn_incr*')\n",
    "\n",
    "# Find files matching the new pattern\n",
    "files_debug2 = glob.glob(pattern_debug2)\n",
    "\n",
    "# Filter files based on the date range\n",
    "filtered_files_debug2 = []\n",
    "for file in files_debug2:\n",
    "    # Extract the date part from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    print(f'Processing file: {filename}')\n",
    "    parts = filename.split('.')\n",
    "    if len(parts) >= 3:\n",
    "        date_str = parts[-2]  # '20021002'\n",
    "        try:\n",
    "            file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse date from {date_str}\")\n",
    "    else:\n",
    "        print(\"Filename format not recognized\")\n",
    "\n",
    "    # Check if the file date is within the range\n",
    "    if start_date <= file_date < end_date:\n",
    "        filtered_files_debug2.append(file)\n",
    "\n",
    "# Load the data\n",
    "ds_debug2 = xr.open_mfdataset(filtered_files_debug2, combine='nested', concat_dim=\"time\")\n",
    "ds_debug2 = ds_debug2.sortby('time_stamp')\n",
    "\n",
    "# Convert DataArray to numpy array, then to strings\n",
    "time_strs_debug2 = ds_debug2['time_stamp'].values.astype(str)\n",
    "\n",
    "# Convert to datetime objects\n",
    "time_objs_debug2 = [datetime.strptime(ts, \"%Y%m%d_%H%Mz\") for ts in time_strs_debug2]\n",
    "\n",
    "print(time_objs_debug2[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Read latitude and longitude for the specified tile_index\n",
    "lat = ds['lat'].sel(tile=tile_index).values\n",
    "lon = ds['lon'].sel(tile=tile_index).values\n",
    "\n",
    "print(f\"Latitude: {lat[0]}, Longitude: {lon[0]}\")\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# Example: lat[0], lon[0] are your coordinates\n",
    "plt.figure(figsize=(8, 4))\n",
    "ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "ax.coastlines()\n",
    "ax.set_global()\n",
    "\n",
    "# Plot the point\n",
    "ax.plot(lon[0], lat[0], marker='o', color='red', markersize=8, transform=ccrs.PlateCarree())\n",
    "ax.set_title(f\"Location: lat={lat[0]}, lon={lon[0]}\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the time series for each variable using .sel\n",
    "var_ts = ds['GHTCNT1_INCR'].sel(tile=tile_index)\n",
    "var_ts_snow = ds['WESNN1_INCR'].sel(tile=tile_index) + ds['WESNN2_INCR'].sel(tile=tile_index) + ds['WESNN3_INCR'].sel(tile=tile_index)\n",
    "var_ts_wilting = ds['TCFWLT_INCR'].sel(tile=tile_index)\n",
    "var_ts2 = ds_debug2['GHTCNT1_INCR'].sel(tile=tile_index)\n",
    "var_ts_snow2 = ds_debug2['WESNN1_INCR'].sel(tile=tile_index) + ds_debug2['WESNN2_INCR'].sel(tile=tile_index) + ds_debug2['WESNN3_INCR'].sel(tile=tile_index)\n",
    "var_ts_wilting2 = ds_debug2['TCFWLT_INCR'].sel(tile=tile_index)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(14, 7), sharex=True)\n",
    "\n",
    "# 1. Soil heat content increment\n",
    "axs[0].vlines(x=time_objs, ymin=0, ymax=var_ts.values, color='tab:blue', alpha=0.7, linewidth=2)\n",
    "axs[0].scatter(time_objs, var_ts.values, color='tab:blue', s=10)\n",
    "axs[0].set_ylabel('GHTCNT1_INCR (J m-2)')\n",
    "axs[0].set_title(f'Ground Head Content (1) Increment for tile {tile_number}')\n",
    "axs[0].grid(True)\n",
    "\n",
    "# 2. Snow mass increment\n",
    "axs[1].vlines(x=time_objs, ymin=0, ymax=var_ts_snow.values, color='tab:blue', label='ght', alpha=0.7, linewidth=2)\n",
    "axs[1].scatter(time_objs, var_ts_snow.values, color='tab:blue', s=10)\n",
    "axs[1].plot(time_objs_debug2, var_ts_snow2.values, color='tab:orange', label='minSWE', linewidth=1.5)\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel('WESN_INCR (kg m-2)')\n",
    "axs[1].set_title(f'Snow Mass Increment for tile {tile_number}')\n",
    "axs[1].grid(True)\n",
    "\n",
    "# 3. Wilting zone temperature increment\n",
    "axs[2].vlines(x=time_objs, ymin=0, ymax=var_ts_wilting.values, color='tab:blue', alpha=0.7, linewidth=2)\n",
    "axs[2].scatter(time_objs, var_ts_wilting.values, color='tab:blue', s=10)\n",
    "axs[2].set_ylabel('TCFWLT_INCR (K)')\n",
    "axs[2].set_title(f'Wilting Zone Temperature Increment for tile {tile_number}')\n",
    "axs[2].set_xlabel('Time')\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = os.path.join(directory, '*debug.inst3_1d_lndfcstana_Nt*')\n",
    "\n",
    "files = glob.glob(pattern)\n",
    "\n",
    "# Filter files based on the date range\n",
    "filtered_files = []\n",
    "for file in files:\n",
    "    # Extract the date part from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    print(f'Processing file: {filename}')\n",
    "    parts = filename.split('.')\n",
    "    if len(parts) >= 3:\n",
    "        date_str = parts[-2]  # '20021002'\n",
    "        try:\n",
    "            file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse date from {date_str}\")\n",
    "    else:\n",
    "        print(\"Filename format not recognized\")\n",
    "\n",
    "    # Check if the file date is within the range\n",
    "    if start_date <= file_date < end_date:\n",
    "        filtered_files.append(file)\n",
    "\n",
    "# Load the data \n",
    "ds = xr.open_mfdataset(filtered_files, combine='nested', concat_dim=\"time\")\n",
    "ds = ds.sortby('time_stamp')\n",
    "\n",
    "# Convert DataArray to numpy array, then to strings\n",
    "time_strs = ds['time_stamp'].values.astype(str)\n",
    "\n",
    "# Convert to datetime objects\n",
    "time_objs = [datetime.strptime(ts, \"%Y%m%d_%H%Mz\") for ts in time_strs]\n",
    "\n",
    "print(time_objs[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = os.path.join(directory, '*OL.inst3_1d_lndfcstana_Nt*')\n",
    "\n",
    "files = glob.glob(pattern)\n",
    "\n",
    "# Filter files based on the date range\n",
    "filtered_files = []\n",
    "for file in files:\n",
    "    # Extract the date part from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    print(f'Processing file: {filename}')\n",
    "    parts = filename.split('.')\n",
    "    if len(parts) >= 3:\n",
    "        date_str = parts[-2]  # '20021002'\n",
    "        try:\n",
    "            file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse date from {date_str}\")\n",
    "    else:\n",
    "        print(\"Filename format not recognized\")\n",
    "\n",
    "    # Check if the file date is within the range\n",
    "    if start_date <= file_date < end_date:\n",
    "        filtered_files.append(file)\n",
    "\n",
    "# Load the data \n",
    "ds_open_loop = xr.open_mfdataset(filtered_files, combine='nested', concat_dim=\"time\")\n",
    "ds_open_loop = ds_open_loop.sortby('time_stamp')\n",
    "\n",
    "# Convert DataArray to numpy array, then to strings\n",
    "time_strs_open_loop = ds_open_loop['time_stamp'].values.astype(str)\n",
    "\n",
    "# Convert to datetime objects\n",
    "time_objs_open_loop = [datetime.strptime(ts, \"%Y%m%d_%H%Mz\") for ts in time_strs_open_loop]\n",
    "\n",
    "print(time_objs_open_loop[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_debug2 = os.path.join(directory, '*debug2.inst3_1d_lndfcstana_Nt*')\n",
    "\n",
    "files_debug2 = glob.glob(pattern_debug2)\n",
    "\n",
    "# Filter files based on the date range\n",
    "filtered_files_debug2 = []\n",
    "for file in files_debug2:\n",
    "    # Extract the date part from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    print(f'Processing file: {filename}')\n",
    "    parts = filename.split('.')\n",
    "    if len(parts) >= 3:\n",
    "        date_str = parts[-2]  # '20021002'\n",
    "        try:\n",
    "            file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse date from {date_str}\")\n",
    "    else:\n",
    "        print(\"Filename format not recognized\")\n",
    "\n",
    "    # Check if the file date is within the range\n",
    "    if start_date <= file_date < end_date:\n",
    "        filtered_files_debug2.append(file)\n",
    "\n",
    "# Load the data\n",
    "ds_debug2 = xr.open_mfdataset(filtered_files_debug2, combine='nested', concat_dim=\"time\")\n",
    "ds_debug2 = ds_debug2.sortby('time_stamp')\n",
    "\n",
    "# Convert DataArray to numpy array, then to strings\n",
    "time_strs_debug2 = ds_debug2['time_stamp'].values.astype(str)\n",
    "\n",
    "# Convert to datetime objects\n",
    "time_objs_debug2 = [datetime.strptime(ts, \"%Y%m%d_%H%Mz\") for ts in time_strs_debug2]\n",
    "\n",
    "print(time_objs_debug2[11])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the time series for the forecast and analysis variables\n",
    "var_ts_soil_temp = ds['TSOIL1_FCST'].sel(tile=tile_index)\n",
    "var_ts_soil_temp_analysis = ds['TSOIL1_ANA'].sel(tile=tile_index)\n",
    "\n",
    "# Create the plot\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "# Plot forecast data\n",
    "ax.plot(time_objs, var_ts_soil_temp.values, label='Forecast', color='tab:blue', alpha=0.7)\n",
    "\n",
    "# Plot analysis data\n",
    "ax.plot(time_objs, var_ts_soil_temp_analysis.values, label='Analysis', color='tab:orange', alpha=0.7)\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_xlabel('Time')\n",
    "ax.set_ylabel('Soil Temperature Layer 1 (K)')\n",
    "ax.set_title(f'Soil Temperature Layer 1 Forecast vs Analysis Time Series for tile {tile_number}')\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare new time and value arrays\n",
    "new_times = []\n",
    "new_values = []\n",
    "\n",
    "for t, fcst, ana in zip(time_objs, var_ts_soil_temp.values, var_ts_soil_temp_analysis.values):\n",
    "    new_times.append(t)\n",
    "    new_values.append(fcst)\n",
    "    # Add analysis value 1 second after forecast\n",
    "    new_times.append(t + timedelta(seconds=1))\n",
    "    new_values.append(ana)\n",
    "\n",
    "# Select the time series for the forecast variable from both datasets\n",
    "var_ts_open_loop_fcst = ds_open_loop['TSOIL1_FCST'].sel(tile=tile_index)\n",
    "var_ts_exp_fcst = ds['TSOIL1_FCST'].sel(tile=tile_index)\n",
    "var_ts_exp2_fcst = ds_debug2['TSOIL1_FCST'].sel(tile=tile_index)\n",
    "\n",
    "\n",
    "fig, axs = plt.subplots(2, 1, figsize=(14, 7), sharex=True)\n",
    "\n",
    "# Subplot 1: Sawtooth Forecast/Analysis\n",
    "axs[0].plot(new_times, new_values, label='Forecast/Analysis Sawtooth', color='tab:purple', marker='o', markersize=2, linestyle='-')\n",
    "axs[0].set_xlabel('Time')\n",
    "axs[0].set_ylabel('Soil Temperature Layer 1 (K)')\n",
    "axs[0].set_title(f'Sawtooth Forecast/Analysis Soil Temperature (1) for tile {tile_number}')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# Subplot 2: Forecasts from three experiments\n",
    "axs[1].plot(time_objs_open_loop, var_ts_open_loop_fcst.values, label='Open Loop', alpha=0.7)\n",
    "axs[1].plot(time_objs_debug2, var_ts_exp2_fcst.values, label='minSWE', alpha=0.7)\n",
    "axs[1].plot(time_objs, var_ts_exp_fcst.values, label='ght', alpha=0.7)\n",
    "axs[1].set_xlabel('Time')\n",
    "axs[1].set_ylabel('Soil Temperature Layer 1 (K)')\n",
    "axs[1].set_title(f'Soil Temperature Layer 1 Forecast for tile {tile_number}')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = os.path.join(directory, '*debug.SMAP_L4_SM_gph*')\n",
    "\n",
    "files = glob.glob(pattern)\n",
    "\n",
    "# Filter files based on the date range\n",
    "filtered_files = []\n",
    "for file in files:\n",
    "    # Extract the date part from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    print(f'Processing file: {filename}')\n",
    "    parts = filename.split('.')\n",
    "    if len(parts) >= 3:\n",
    "        date_str = parts[-2]  # '20021002'\n",
    "        try:\n",
    "            file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse date from {date_str}\")\n",
    "    else:\n",
    "        print(\"Filename format not recognized\")\n",
    "\n",
    "    # Check if the file date is within the range\n",
    "    if start_date <= file_date < end_date:\n",
    "        filtered_files.append(file)\n",
    "\n",
    "# Load the data \n",
    "ds = xr.open_mfdataset(filtered_files, combine='nested', concat_dim=\"time\")\n",
    "ds = ds.sortby('time_stamp')\n",
    "\n",
    "# Convert DataArray to numpy array, then to strings\n",
    "time_strs = ds['time_stamp'].values.astype(str)\n",
    "\n",
    "# Convert to datetime objects\n",
    "time_objs = [datetime.strptime(ts, \"%Y%m%d_%H%Mz\") for ts in time_strs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = os.path.join(directory, '*OL.SMAP_L4_SM_gph*')\n",
    "\n",
    "files = glob.glob(pattern)\n",
    "\n",
    "# Filter files based on the date range\n",
    "filtered_files = []\n",
    "for file in files:\n",
    "    # Extract the date part from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    print(f'Processing file: {filename}')\n",
    "    parts = filename.split('.')\n",
    "    if len(parts) >= 3:\n",
    "        date_str = parts[-2]  # '20021002'\n",
    "        try:\n",
    "            file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse date from {date_str}\")\n",
    "    else:\n",
    "        print(\"Filename format not recognized\")\n",
    "\n",
    "    # Check if the file date is within the range\n",
    "    if start_date <= file_date < end_date:\n",
    "        filtered_files.append(file)\n",
    "\n",
    "# Load the data \n",
    "ds_open_loop = xr.open_mfdataset(filtered_files, combine='nested', concat_dim=\"time\")\n",
    "ds_open_loop = ds_open_loop.sortby('time_stamp')\n",
    "\n",
    "# Convert DataArray to numpy array, then to strings\n",
    "time_strs_open_loop = ds_open_loop['time_stamp'].values.astype(str)\n",
    "\n",
    "# Convert to datetime objects\n",
    "time_objs_open_loop = [datetime.strptime(ts, \"%Y%m%d_%H%Mz\") for ts in time_strs_open_loop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_debug2 = os.path.join(directory, '*debug2.SMAP_L4_SM_gph*')\n",
    "\n",
    "files_debug2 = glob.glob(pattern_debug2)\n",
    "\n",
    "# Filter files based on the date range\n",
    "filtered_files_debug2 = []\n",
    "for file in files_debug2:\n",
    "    # Extract the date part from the filename\n",
    "    filename = os.path.basename(file)\n",
    "    print(f'Processing file: {filename}')\n",
    "    parts = filename.split('.')\n",
    "    if len(parts) >= 3:\n",
    "        date_str = parts[-2]  # '20021002'\n",
    "        try:\n",
    "            file_date = datetime.strptime(date_str, '%Y%m%d')\n",
    "        except ValueError:\n",
    "            print(f\"Could not parse date from {date_str}\")\n",
    "    else:\n",
    "        print(\"Filename format not recognized\")\n",
    "\n",
    "    # Check if the file date is within the range\n",
    "    if start_date <= file_date < end_date:\n",
    "        filtered_files_debug2.append(file)\n",
    "\n",
    "# Load the data\n",
    "ds_debug2 = xr.open_mfdataset(filtered_files_debug2, combine='nested', concat_dim=\"time\")\n",
    "ds_debug2 = ds_debug2.sortby('time_stamp')\n",
    "\n",
    "# Convert DataArray to numpy array, then to strings\n",
    "time_strs_debug2 = ds_debug2['time_stamp'].values.astype(str)\n",
    "\n",
    "# Convert to datetime objects\n",
    "time_objs_debug2 = [datetime.strptime(ts, \"%Y%m%d_%H%Mz\") for ts in time_strs_debug2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_ts_snow_melt_flux = ds['snow_melt_flux'].sel(tile=tile_index) \n",
    "var_ts_snow_melt_flux_open_loop = ds_open_loop['snow_melt_flux'].sel(tile=tile_index) \n",
    "var_ts_snow_melt_flux_debug2 = ds_debug2['snow_melt_flux'].sel(tile=tile_index)\n",
    "var_ts_precipitation = ds['precipitation_total_surface_flux'].sel(tile=tile_index)\n",
    "var_ts_snowfall = ds['snowfall_surface_flux'].sel(tile=tile_index)\n",
    "var_ts_snow_mass = ds['snow_mass'].sel(tile=tile_index)\n",
    "var_ts_snow_mass_open_loop = ds_open_loop['snow_mass'].sel(tile=tile_index)\n",
    "var_ts_snow_mass_debug2 = ds_debug2['snow_mass'].sel(tile=tile_index)\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(14, 7), sharex=True)\n",
    "\n",
    "# --- Subplot 1: Precipitation and Snowfall Surface Flux ---\n",
    "axs[0].plot(time_objs, var_ts_precipitation.values, label='Precipitation Total Surface Flux', color='tab:blue', alpha=0.7)\n",
    "axs[0].plot(time_objs, var_ts_snowfall.values, label='Snowfall Surface Flux', color='tab:orange', alpha=0.7)\n",
    "axs[0].set_ylabel('Flux (kg m-2 s-1)')\n",
    "axs[0].set_title(f'Precipitation and Snowfall Surface Flux for tile {tile_number}')\n",
    "axs[0].legend()\n",
    "axs[0].grid(True)\n",
    "\n",
    "# --- Subplot 2: Snow Mass ---\n",
    "axs[1].plot(time_objs_open_loop, var_ts_snow_mass_open_loop.values, label='Open Loop', alpha=0.7)\n",
    "axs[1].plot(time_objs_debug2, var_ts_snow_mass_debug2.values, label='minSWE', alpha=0.7)\n",
    "axs[1].plot(time_objs, var_ts_snow_mass.values, label='ght', alpha=0.7)\n",
    "axs[1].set_ylabel('Snow Mass (kg m-2)')\n",
    "axs[1].set_title(f'Snow Mass for tile {tile_number}')\n",
    "axs[1].legend()\n",
    "axs[1].grid(True)\n",
    "\n",
    "# --- Subplot 3: Snow Melt Flux ---\n",
    "axs[2].plot(time_objs_open_loop, var_ts_snow_melt_flux_open_loop.values, label='Open Loop', alpha=0.7)\n",
    "axs[2].plot(time_objs_debug2, var_ts_snow_melt_flux_debug2.values, label='minSWE', alpha=0.7)\n",
    "axs[2].plot(time_objs, var_ts_snow_melt_flux.values, label='ght', alpha=0.7)\n",
    "axs[2].set_xlabel('Time')\n",
    "axs[2].set_ylabel('Snow Melt Flux (kg m-2 s-1)')\n",
    "axs[2].set_title(f'Snow Melt Flux for tile {tile_number}')\n",
    "axs[2].legend()\n",
    "axs[2].grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
