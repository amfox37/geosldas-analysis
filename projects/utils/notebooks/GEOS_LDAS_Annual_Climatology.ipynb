{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f9ecaae7",
   "metadata": {},
   "source": [
    "\n",
    "# GEOS-LDAS Land Variables: Annual Means & Monthly Climatologies\n",
    "\n",
    "This notebook reads a collection of **GEOS-LDAS land (`lnd`) NetCDF** files, extracts selected variables, computes **annual means** and **monthly climatologies**, and writes them back out to NetCDF files.\n",
    "\n",
    "**Notes**\n",
    "\n",
    "- The variables are treated as **means over time** (not totals). For fluxes (e.g., `kg m-2 s-1`, `W m-2`), an *annual mean* is computed; if you need *annual totals*, integrate by time instead of a plain mean.\n",
    "- The notebook masks large fill values (e.g., `>= 1e14`) as missing before computing statistics.\n",
    "- Outputs are written as:\n",
    "  - `annual_means.nc`: one file with a `year` dimension\n",
    "  - `monthly_climatology.nc`: one file with a `month` dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fa26bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === User parameters ===\n",
    "\n",
    "# Directory or glob for input LDAS lnd files (edit this)\n",
    "INPUT_GLOB = \"/discover/nobackup/projects/land_da/CYGNSS_Experiments/OLv8_M36_cd/OLv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg/Y????/M??/OLv8_M36_cd.tavg24_1d_lnd*.*\"  # e.g., \"/discover/nobackup/.../lnd/Y*/M*/*.nc4\"\n",
    "\n",
    "# Output folder (created if it doesn't exist)\n",
    "OUT_DIR = \"/discover/nobackup/projects/land_da/CYGNSS_Experiments/OLv8_M36_cd/OLv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg\"\n",
    "\n",
    "# Time subset (inclusive). Set to None to skip filtering.\n",
    "START_DATE = \"2018-08-01\"   # or None\n",
    "END_DATE   = \"2024-06-30\"   # or None\n",
    "\n",
    "# Variables to extract and process\n",
    "VARS = [\n",
    "    \"GRN\", \"LAI\",\n",
    "    \"GWETPROF\", \"GWETROOT\", \"GWETTOP\",\n",
    "    \"PRMC\", \"RZMC\", \"SFMC\",\n",
    "    \"PRECTOTCORRLAND\", \"QINFILLAND\",\n",
    "    \"SHLAND\", \"LHLAND\", \"EVLAND\",\n",
    "]\n",
    "\n",
    "# Chunking for xarray/dask (None = let xarray decide; or provide dict like {\"time\": 64, \"tile\": 4096})\n",
    "CHUNKS = {\"time\": 64, \"tile\": 32768}\n",
    "\n",
    "# Compression settings for NetCDF (set zlib=True for smaller files)\n",
    "ENCODING_COMP = {\"zlib\": True, \"complevel\": 4, \"shuffle\": True}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b913c01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "len(glob(INPUT_GLOB)), INPUT_GLOB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892dab5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "files = sorted(glob(INPUT_GLOB))\n",
    "if not files:\n",
    "    raise FileNotFoundError(f\"No input files found for pattern: {INPUT_GLOB}\")\n",
    "\n",
    "# Open multi-file dataset with only the requested variables (if present)\n",
    "ds = xr.open_mfdataset(\n",
    "    files,\n",
    "    combine=\"by_coords\",\n",
    "    parallel=True,\n",
    "    chunks=CHUNKS,\n",
    "    decode_times=True,\n",
    "    decode_cf=True,\n",
    ")\n",
    "\n",
    "# Keep only the variables of interest that are actually present\n",
    "vars_present = [v for v in VARS if v in ds.data_vars]\n",
    "if not vars_present:\n",
    "    raise ValueError(\"None of the requested variables are present in the input files.\")\n",
    "\n",
    "ds = ds[vars_present]\n",
    "\n",
    "# Optional time subset\n",
    "if START_DATE is not None:\n",
    "    ds = ds.sel(time=slice(START_DATE, None))\n",
    "if END_DATE is not None:\n",
    "    ds = ds.sel(time=slice(None, END_DATE))\n",
    "\n",
    "# Mask ridiculous large fill values manually (in case decode didn't mask all)\n",
    "for v in vars_present:\n",
    "    da = ds[v]\n",
    "    ds[v] = xr.where(np.isfinite(da) & (np.abs(da) < 1e14), da, np.nan)\n",
    "\n",
    "ds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7487e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Annual means (calendar-year means)\n",
    "annual_means = ds.groupby(\"time.year\").mean(\"time\", skipna=True, keep_attrs=True)\n",
    "annual_means = annual_means.rename({\"year\": \"year\"})\n",
    "annual_means.attrs.update(ds.attrs)\n",
    "annual_means\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364c246",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Monthly climatology across all available years\n",
    "monthly_climo = ds.groupby(\"time.month\").mean(\"time\", skipna=True, keep_attrs=True)\n",
    "monthly_climo = monthly_climo.rename({\"month\": \"month\"})\n",
    "monthly_climo.attrs.update(ds.attrs)\n",
    "monthly_climo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23662701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Grand mean & std across years (from annual_means) ===\n",
    "grand_mean = annual_means.mean(dim=\"year\", skipna=True, keep_attrs=True)\n",
    "grand_std  = annual_means.std(dim=\"year\", skipna=True, ddof=1, keep_attrs=True)  # sample std\n",
    "\n",
    "# Combine into one Dataset with clear suffixes\n",
    "gm = xr.Dataset()\n",
    "for v in annual_means.data_vars:\n",
    "    gm[f\"{v}_mean\"] = grand_mean[v]\n",
    "    gm[f\"{v}_std\"]  = grand_std[v]\n",
    "\n",
    "# carry over attributes\n",
    "gm.attrs.update(annual_means.attrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88325343",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_encoding(ds_like):\n",
    "    enc = {}\n",
    "    for v in ds_like.data_vars:\n",
    "        enc[v] = dict(ENCODING_COMP)\n",
    "        enc[v][\"dtype\"] = \"float32\"\n",
    "        enc[v][\"_FillValue\"] = np.float32(1.0e15)\n",
    "    return enc\n",
    "\n",
    "annual_path = os.path.join(OUT_DIR, \"annual_means.nc\")\n",
    "climo_path  = os.path.join(OUT_DIR, \"monthly_climatology.nc\")\n",
    "grand_path = os.path.join(OUT_DIR, \"grand_mean.nc\")\n",
    "\n",
    "annual_means.astype(\"float32\").to_netcdf(\n",
    "    annual_path,\n",
    "    format=\"NETCDF4\",\n",
    "    encoding=build_encoding(annual_means),\n",
    ")\n",
    "monthly_climo.astype(\"float32\").to_netcdf(\n",
    "    climo_path,\n",
    "    format=\"NETCDF4\",\n",
    "    encoding=build_encoding(monthly_climo),\n",
    ")\n",
    "\n",
    "gm.astype(\"float32\").to_netcdf(\n",
    "    grand_path,\n",
    "    format=\"NETCDF4\",\n",
    "    encoding=build_encoding(grand_mean),\n",
    ")\n",
    "annual_path, climo_path, grand_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18bf0f0",
   "metadata": {},
   "source": [
    "\n",
    "## (Optional) Annual totals for flux variables\n",
    "\n",
    "If you need **annual totals** instead of **annual means** for flux variables\n",
    "(e.g., `kg m-2 s-1` or `W m-2`), integrate over time with actual time-step lengths, e.g.:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c34a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Example (commented):\n",
    "# import numpy as np\n",
    "# flux_vars = [\"PRECTOTCORRLAND\", \"QINFILLAND\", \"EVLAND\", \"SHLAND\", \"LHLAND\"]\n",
    "# sec_per_timestep = np.diff(ds.time.values).astype(\"timedelta64[s]\").astype(int)\n",
    "# sec_per_timestep = xr.DataArray(np.append(sec_per_timestep, sec_per_timestep[-1]),\n",
    "#                                 dims=[\"time\"], coords={\"time\": ds.time})\n",
    "# tot = {v: (ds[v]*sec_per_timestep).groupby(\"time.year\").sum(\"time\", skipna=True)\n",
    "#        for v in flux_vars if v in ds}\n",
    "# annual_totals = xr.Dataset(tot)\n",
    "# annual_totals.astype(\"float32\").to_netcdf(os.path.join(OUT_DIR, \"annual_totals_fluxes.nc\"),\n",
    "#                                           format=\"NETCDF4\",\n",
    "#                                           encoding=build_encoding(annual_totals))\n",
    "# annual_totals\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sci]",
   "language": "python",
   "name": "conda-env-sci-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
