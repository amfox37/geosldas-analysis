{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa793ffa",
   "metadata": {},
   "source": [
    "\n",
    "# Aridity Indices from GEOS‑LDAS Daily Output (FAO‑56 Penman–Monteith)\n",
    "\n",
    "This notebook computes annual **UNEP Aridity Index (AI = P / PET)**, **Budyko dryness index (φ = PET / P)**,\n",
    "**Climatic Moisture Index (CMI = (P − PET)/PET)**, and optional **De Martonne** index from\n",
    "GEOS‑LDAS daily tile outputs (tavg24). It:\n",
    "1. Walks a `Y####/M##` directory tree for a specified date range\n",
    "2. Computes **reference PET (ET₀)** via FAO‑56 Penman–Monteith using daily means\n",
    "3. Aggregates to **monthly** and **annual** totals\n",
    "4. Writes results to a single NetCDF file\n",
    "\n",
    "> Variables expected in the daily files: `Tair`, `Qair`, `Wind`, `RefH`, `Psurf`, `SWdown`, `LWdown`, `HLWUP`, `RainfSnowf`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbd7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Parameters (edit these) ===\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Root of your Y####/M## directories:\n",
    "BASE = Path(\"/discover/nobackup/projects/land_da/CYGNSS_Experiments/OLv8_M36_cd/OLv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg\")\n",
    "\n",
    "# Date range\n",
    "START = pd.Timestamp(\"2018-08-01\")\n",
    "END   = pd.Timestamp(\"2024-06-30\")\n",
    "\n",
    "# File match inside each month directory\n",
    "LFS_FILE_GLOB = \"OLv8_M36_cd.tavg24_1d_lfs*.*\"   # broad match to include .nc/.nc4 variants\n",
    "LND_FILE_GLOB = \"OLv8_M36_cd.tavg24_1d_lnd*.*\" # broad match to include .nc/.nc4 variants\n",
    "\n",
    "# Chunking (adjust for your machine/memory)\n",
    "CHUNKS = {\"time\": 64, \"tile\": 10000}\n",
    "\n",
    "# Mask thresholds & constants\n",
    "EPS_MM = 1e-3    # avoid /0 in annual PET (mm)\n",
    "ALPHA_REF = 0.23 # FAO-56 reference albedo (grass)\n",
    "\n",
    "USE_MODEL_NET = True  # if True, use model net radiation; if False, use model shortwave + longwave\n",
    "\n",
    "if USE_MODEL_NET:\n",
    "    OUTFILE = BASE / f\"aridity_indices_model_net_rad_{START:%Y%m%d}_{END:%Y%m%d}.nc4\"\n",
    "else:\n",
    "    OUTFILE = BASE / f\"aridity_indices_{START:%Y%m%d}_{END:%Y%m%d}.nc4\"\n",
    "\n",
    "print(BASE, START, END, OUTFILE, sep=\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc69f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Imports & helpers ===\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import dask\n",
    "\n",
    "DATE_RE = re.compile(r\"\\.(\\d{8})_\")   # captures YYYYMMDD in filename pieces like .20221222_\n",
    "\n",
    "FV = 1e15\n",
    "def clean(ds, name):\n",
    "    \"\"\"Mask out large fill values common in GEOS-LDAS outputs.\"\"\"\n",
    "    v = ds[name]\n",
    "    return v.where(v < FV)\n",
    "\n",
    "def collect_files(base: Path, start: pd.Timestamp, end: pd.Timestamp, file_glob: str):\n",
    "    files = []\n",
    "    for ydir in sorted(base.glob(\"Y*/\")):\n",
    "        for mdir in sorted(ydir.glob(\"M*/\")):\n",
    "            for f in mdir.glob(file_glob):\n",
    "                m = DATE_RE.search(f.name)\n",
    "                if not m:\n",
    "                    continue\n",
    "                dt = pd.to_datetime(m.group(1), format=\"%Y%m%d\")\n",
    "                if start <= dt <= end:\n",
    "                    files.append(str(f))\n",
    "    files.sort()\n",
    "    return files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0025713",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Collect files in the date range ===\n",
    "lfs_files = collect_files(BASE, START, END, LFS_FILE_GLOB)\n",
    "print(f\"Found {len(lfs_files)} daily files between {START.date()} and {END.date()}.\")\n",
    "if len(lfs_files) == 0:\n",
    "    raise SystemExit(\"No files found. Check BASE/START/END/FILE_GLOB.\")\n",
    "lfs_files[:5]\n",
    "\n",
    "lnd_files = collect_files(BASE, START, END, LND_FILE_GLOB)\n",
    "print(f\"Found {len(lnd_files)} daily files between {START.date()} and {END.date()}.\")\n",
    "if len(lnd_files) == 0:\n",
    "    raise SystemExit(\"No files found. Check BASE/START/END/FILE_GLOB.\")\n",
    "lnd_files[:5]\n",
    "if len(lnd_files) != len(lfs_files):\n",
    "    raise SystemExit(\"LFS and LND file counts do not match. Check your FILE_GLOB patterns.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a675d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Open dataset with dask chunking ===\n",
    "ds = xr.open_mfdataset(\n",
    "    lfs_files, combine=\"nested\", parallel=True,concat_dim=\"time\",\n",
    "    decode_times=True, chunks=CHUNKS, engine=\"netcdf4\"\n",
    ")\n",
    "\n",
    "# Quick peek\n",
    "ds\n",
    "\n",
    "ds_lnd = xr.open_mfdataset(\n",
    "    lnd_files, combine=\"nested\", parallel=True,concat_dim=\"time\",\n",
    "    decode_times=True, chunks=CHUNKS, engine=\"netcdf4\"\n",
    ")\n",
    "\n",
    "# Quick peek\n",
    "ds_lnd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852d3afb-2b56-4175-b121-a5a37a182e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab the first filename\n",
    "fname0 = os.path.basename(lfs_files[0])\n",
    "\n",
    "# Regex to capture the 8-digit date before the \"_1200z\"\n",
    "m = re.search(r\"\\.(\\d{8})_1200z\", fname0)\n",
    "if not m:\n",
    "    raise ValueError(f\"No YYYYMMDD date found in {fname0}\")\n",
    "start_str = m.group(1)\n",
    "\n",
    "# Convert to pandas Timestamp / numpy datetime64\n",
    "start_date = pd.to_datetime(start_str, format=\"%Y%m%d\")\n",
    "\n",
    "# Build daily sequence, length = number of files\n",
    "all_dates = start_date + pd.to_timedelta(np.arange(len(lfs_files)), unit=\"D\")\n",
    "\n",
    "# Assign to dataset (as datetime64[ns])\n",
    "ds = ds.assign_coords(time=(\"time\", all_dates.values)).sortby(\"time\")\n",
    "\n",
    "ds_lnd = ds_lnd.assign_coords(time=(\"time\", all_dates.values)).sortby(\"time\")\n",
    "\n",
    "# Verify time coordinate\n",
    "ds.time\n",
    "ds_lnd.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca1495e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Build daily PET (FAO-56 Penman–Monteith) and daily Precip ===\n",
    "\n",
    "# Inputs (daily means)\n",
    "Tair = clean(ds, \"Tair\") - 273.15         # °C\n",
    "qair = clean(ds, \"Qair\")                   # kg/kg\n",
    "wind_z = clean(ds, \"Wind\")                 # m/s at RefH\n",
    "zref = clean(ds, \"RefH\").fillna(2.0)       # m\n",
    "ps_kpa = (clean(ds, \"Psurf\") / 1000.0)     # Pa -> kPa\n",
    "sw_down = clean(ds, \"SWdown\")              # W/m2\n",
    "lw_down = clean(ds, \"LWdown\")              # W/m2\n",
    "lw_up   = clean(ds, \"HLWUP\")               # W/m2\n",
    "P_rate  = clean(ds, \"RainfSnowf\")          # kg m-2 s-1 (== mm s-1)\n",
    "\n",
    "# Inputs from LND file\n",
    "greeness = clean(ds_lnd, \"GRN\")   # unitless [0,1]\n",
    "lai = clean(ds_lnd, \"LAI\")        # m2/m2\n",
    "net_sw = clean(ds_lnd, \"SWLAND\")  # W/m2\n",
    "net_lw = clean(ds_lnd, \"LWLAND\")  # W/m2\n",
    "\n",
    "if USE_MODEL_NET:\n",
    "    # Use model net radiation directly (W/m2)\n",
    "    Rn_W = net_sw + net_lw\n",
    "else:\n",
    "    # Net radiation (MJ m-2 day-1). Assumes LWdown is downward and HLWUP is upward emitted.\n",
    "    Rn_W = (1.0 - ALPHA_REF) * sw_down + lw_down - lw_up\n",
    "    \n",
    "Rn_MJ = (Rn_W * 86400.0) / 1e6\n",
    "\n",
    "# Thermodynamics and VPD\n",
    "es = 0.6108 * np.exp(17.27 * Tair / (Tair + 237.3))      # kPa\n",
    "ea = (qair * ps_kpa) / (0.622 + 0.378 * qair)            # kPa\n",
    "vpd = (es - ea).clip(min=0.0)                            # kPa\n",
    "\n",
    "delta = 4098.0 * es / (Tair + 237.3) ** 2                # kPa / °C\n",
    "gamma = 0.000665 * ps_kpa                                 # kPa / °C\n",
    "\n",
    "# Wind at 2 m (FAO-56)\n",
    "z = xr.where(zref > 0.5, zref, 2.0)\n",
    "u2 = wind_z * (4.87 / np.log(67.8 * z - 5.42))\n",
    "\n",
    "# FAO-56 PM (mm/day), ground heat flux ~ 0 for daily\n",
    "ET0_day = (\n",
    "    0.408 * delta * (Rn_MJ) +\n",
    "    gamma * (900.0 / (Tair + 273.0)) * u2 * vpd\n",
    ") / (delta + gamma * (1.0 + 0.34 * u2))\n",
    "\n",
    "PET_day = ET0_day.clip(min=0.0)            # mm/day\n",
    "P_day   = (P_rate * 86400.0).clip(min=0.0) # mm/day\n",
    "\n",
    "PET_day, P_day\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb72ffed-bdf7-4dbb-a584-6b5570172fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(P_day.dims)\n",
    "print(P_day[\"time\"].dtype, P_day[\"time\"].values[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28824c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Aggregate to monthly and annual totals, then compute indices ===\n",
    "\n",
    "# Monthly totals\n",
    "P_mon   = P_day.resample(time=\"MS\").sum()\n",
    "PET_mon = PET_day.resample(time=\"MS\").sum()\n",
    "\n",
    "# Annual (calendar year) totals\n",
    "P_ann   = P_mon.resample(time=\"YS\").sum()\n",
    "PET_ann = PET_mon.resample(time=\"YS\").sum()\n",
    "\n",
    "# Indices (annual)\n",
    "AI_ann  = (P_ann / PET_ann).where(PET_ann > EPS_MM).rename(\"AI\")\n",
    "PHI_ann = (PET_ann / P_ann).where(P_ann > EPS_MM).rename(\"Budyko_phi\")\n",
    "CMI_ann = ((P_ann - PET_ann) / PET_ann.where(PET_ann > EPS_MM)).rename(\"CMI\")\n",
    "\n",
    "# Climatologies (mean over available years)\n",
    "AI_clim  = AI_ann.mean(\"time\").rename(\"AI_clim\")\n",
    "PHI_clim = PHI_ann.mean(\"time\").rename(\"Budyko_phi_clim\")\n",
    "CMI_clim = CMI_ann.mean(\"time\").rename(\"CMI_clim\")\n",
    "\n",
    "# Optional De Martonne\n",
    "T_ann = (clean(ds, \"Tair\") - 273.15).resample(time=\"YS\").mean()\n",
    "IDM_ann  = (P_ann / (T_ann + 10.0)).rename(\"DeMartonne\")\n",
    "IDM_clim = IDM_ann.mean(\"time\").rename(\"DeMartonne_clim\")\n",
    "\n",
    "# Annual greeness and LAI (preserve annual time dimension)\n",
    "greeness_ann = greeness.resample(time=\"YS\").mean()\n",
    "lai_ann = lai.resample(time=\"YS\").mean()\n",
    "max_lai_ann = lai.resample(time=\"YS\").max()\n",
    "\n",
    "# Climatological mean of annual greeness and LAI (mean over years -> dims: tile)\n",
    "mean_greeness_clim = greeness_ann.mean(dim=\"time\").rename(\"mean_greeness_clim\")\n",
    "mean_lai_clim = lai_ann.mean(dim=\"time\").rename(\"mean_lai_clim\")\n",
    "max_lai_clim = max_lai_ann.mean(dim=\"time\").rename(\"max_lai_clim\")\n",
    "\n",
    "AI_ann, PHI_ann, CMI_ann\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c52543-a2d8-427f-ac67-c7c0eb433f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (after you computed AI_ann, PHI_ann, CMI_ann, IDM_ann, *_clim, P_ann, PET_ann)\n",
    "\n",
    "# persist computed arrays\n",
    "AI_ann, PHI_ann, CMI_ann, IDM_ann, AI_clim, PHI_clim, CMI_clim, IDM_clim, P_ann, PET_ann, mean_greeness_clim, mean_lai_clim, max_lai_clim = \\\n",
    "    dask.persist(AI_ann, PHI_ann, CMI_ann, IDM_ann, AI_clim, PHI_clim, CMI_clim, IDM_clim, P_ann, PET_ann, mean_greeness_clim, mean_lai_clim, max_lai_clim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b754aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Build output dataset and save ===\n",
    "out = xr.Dataset(\n",
    "    data_vars=dict(\n",
    "        AI=AI_ann, Budyko_phi=PHI_ann, CMI=CMI_ann,\n",
    "        DeMartonne=IDM_ann,\n",
    "        AI_clim=AI_clim, Budyko_phi_clim=PHI_clim, CMI_clim=CMI_clim,\n",
    "        DeMartonne_clim=IDM_clim,\n",
    "        P_annual=P_ann.rename(\"P_annual\"),\n",
    "        PET_annual=PET_ann.rename(\"PET_annual\"),\n",
    "        mean_greeness_clim=mean_greeness_clim,\n",
    "        mean_lai_clim=mean_lai_clim,\n",
    "        max_lai_clim=max_lai_clim\n",
    "    ),\n",
    "    coords=dict(\n",
    "        time=AI_ann.time,\n",
    "        tile=ds[\"tile\"] if \"tile\" in ds.coords else np.arange(ds.dims[\"tile\"]),\n",
    "        lat=ds[\"lat\"], lon=ds[\"lon\"]\n",
    "    ),\n",
    "    attrs=dict(\n",
    "        description=\"Aridity indices from GEOS-LDAS daily tile output using FAO-56 Penman–Monteith\",\n",
    "        period_start=str(START.date()), period_end=str(END.date()),\n",
    "        albedo_reference=float(ALPHA_REF), pet_method=\"FAO-56 Penman–Monteith\",\n",
    "        precip_var=\"RainfSnowf\", note=\"Annual sums/means over resampled calendar years.\"\n",
    "    )\n",
    ").assign_coords(year=(\"time\", AI_ann[\"time.year\"].values))\n",
    "\n",
    "encoding = {v: {\"zlib\": True, \"complevel\": 3} for v in out.data_vars}\n",
    "out.to_netcdf(OUTFILE, encoding=encoding)\n",
    "print(\"Wrote:\", OUTFILE)\n",
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e6611",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# === Quick checks (optional) ===\n",
    "\n",
    "# 1) Global mean AI by year (excludes tiles with NaNs)\n",
    "ai_mean = out[\"AI\"].mean(dim=\"tile\", skipna=True)\n",
    "phi_mean = out[\"Budyko_phi\"].mean(dim=\"tile\", skipna=True)\n",
    "cmi_mean = out[\"CMI\"].mean(dim=\"tile\", skipna=True)\n",
    "display(ai_mean.to_dataframe(name=\"AI_mean\").head())\n",
    "display(phi_mean.to_dataframe(name=\"phi_mean\").head())\n",
    "display(cmi_mean.to_dataframe(name=\"CMI_mean\").head())\n",
    "\n",
    "# 2) Count valid tiles per year\n",
    "valid_tiles = out[\"AI\"].notnull().sum(dim=\"tile\")\n",
    "display(valid_tiles.to_dataframe(name=\"valid_tiles\").head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f194ee3-c2a1-4b59-b587-498e6f0fc183",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diag]",
   "language": "python",
   "name": "conda-env-.conda-diag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
