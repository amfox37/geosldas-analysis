{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xarray as xr\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mapper_functions import plot_global_tight_pcm\n",
    "from my_functions import read_obsfcstana_extend_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read /Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2020/M01/LS_OLv8_M36.ens_avg.ldas_ObsFcstAna.20200102_0300z.bin\n",
    "\n",
    "path = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_OLv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2020/M01'\n",
    "file_name_start = 'LS_OLv8_M36.ens_avg.ldas_ObsFcstAna.2020012'\n",
    "printflag = True\n",
    "\n",
    "date_time, obs_species, obs_tilenum, obs_lon, obs_lat, obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar = read_obsfcstana_extend_datetime(path, file_name_start, printflag)\n",
    "o_date_time = np.array(date_time)\n",
    "o_obs_species = np.array(obs_species)\n",
    "o_obs_tilenum = np.array(obs_tilenum)\n",
    "o_obs_lon = np.array(obs_lon)\n",
    "o_obs_lat = np.array(obs_lat)\n",
    "o_obs_obs = np.array(obs_obs)\n",
    "o_obs_fcst = np.array(obs_fcst)\n",
    "o_obs_ana = np.array(obs_ana)\n",
    "\n",
    "missing_val = -9999.0\n",
    "o_obs_obs[o_obs_obs == missing_val] = np.nan\n",
    "o_obs_fcst[o_obs_fcst == missing_val] = np.nan\n",
    "o_obs_ana[o_obs_ana == missing_val] = np.nan\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/LS_DAv8_M36/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg/Y2020/M01'\n",
    "file_name_start = 'LS_DAv8_M36.ens_avg.ldas_ObsFcstAna.2020012'\n",
    "printflag = True\n",
    "\n",
    "date_time, obs_species, obs_tilenum, obs_lon, obs_lat, obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar = read_obsfcstana_extend_datetime(path, file_name_start, printflag)\n",
    "d_date_time = np.array(date_time)\n",
    "d_obs_species = np.array(obs_species)\n",
    "d_obs_tilenum = np.array(obs_tilenum)\n",
    "d_obs_lon = np.array(obs_lon)\n",
    "d_obs_lat = np.array(obs_lat)\n",
    "d_obs_obs = np.array(obs_obs)\n",
    "d_obs_fcst = np.array(obs_fcst)\n",
    "d_obs_ana = np.array(obs_ana)\n",
    "\n",
    "missing_val = -9999.0\n",
    "d_obs_obs[d_obs_obs == missing_val] = np.nan\n",
    "d_obs_fcst[d_obs_fcst == missing_val] = np.nan\n",
    "d_obs_ana[d_obs_ana == missing_val] = np.nan\n",
    "\n",
    "print(d_date_time[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming o_date_time and d_date_time are dictionaries with arrays for each component of the date and time\n",
    "\n",
    "def parse_date_time(date_time):\n",
    "    return [\n",
    "        f\"{dt['year'][0]:04d}-{dt['month'][0]:02d}-{dt['day'][0]:02d} {dt['hour'][0]:02d}:{dt['min'][0]:02d}:{dt['sec'][0]:02d}\"\n",
    "        for dt in date_time\n",
    "    ]\n",
    "\n",
    "# Parse date_time\n",
    "o_date_time_parsed = parse_date_time(o_date_time)\n",
    "d_date_time_parsed = parse_date_time(d_date_time)\n",
    "\n",
    "# Create DataFrames\n",
    "o_df = pd.DataFrame({\n",
    "    'date_time': o_date_time_parsed,\n",
    "    'species': o_obs_species,\n",
    "    'tilenum': o_obs_tilenum,\n",
    "    'lon': o_obs_lon,\n",
    "    'lat': o_obs_lat\n",
    "})\n",
    "\n",
    "d_df = pd.DataFrame({\n",
    "    'date_time': d_date_time_parsed,\n",
    "    'species': d_obs_species,\n",
    "    'tilenum': d_obs_tilenum,\n",
    "    'lon': d_obs_lon,\n",
    "    'lat': d_obs_lat\n",
    "})\n",
    "\n",
    "# Merge DataFrames on all columns\n",
    "merged_df = pd.merge(o_df.reset_index(), d_df.reset_index(), on=['date_time', 'species', 'tilenum', 'lon', 'lat'], suffixes=('_o', '_d'))\n",
    "\n",
    "# Extract indices\n",
    "o_indices = merged_df['index_o'].values\n",
    "d_indices = merged_df['index_d'].values\n",
    "\n",
    "# Convert to numpy arrays\n",
    "o_indices = np.array(o_indices)\n",
    "d_indices = np.array(d_indices)\n",
    "\n",
    "# Apply the indices to the data arrays\n",
    "o_obs_obs = o_obs_obs[o_indices]\n",
    "o_obs_species = o_obs_species[o_indices]\n",
    "o_obs_fcst = o_obs_fcst[o_indices]\n",
    "o_obs_ana = o_obs_ana[o_indices]\n",
    "\n",
    "d_obs_obs = d_obs_obs[d_indices]\n",
    "d_obs_species = d_obs_species[d_indices]\n",
    "d_obs_fcst = d_obs_fcst[d_indices]\n",
    "d_obs_ana = d_obs_ana[d_indices]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 5\n",
    "\n",
    "num_obs = len(o_obs_obs[o_obs_species ==i])\n",
    "print('Number of OL observations: ', num_obs)\n",
    "\n",
    "num_obs = len(d_obs_obs[d_obs_species ==i])\n",
    "print('Number of DA observations: ', num_obs)\n",
    "\n",
    "o_omf = o_obs_fcst[o_obs_species == i] - o_obs_obs[o_obs_species == i]\n",
    "d_omf = d_obs_fcst[d_obs_species == i] - d_obs_obs[d_obs_species == i]\n",
    "b_omf = o_obs_fcst[o_obs_species == i] - d_obs_obs[d_obs_species == i]\n",
    "\n",
    "o_oma = o_obs_ana[o_obs_species == i] - o_obs_obs[o_obs_species == i]\n",
    "d_oma = d_obs_ana[d_obs_species == i] - d_obs_obs[d_obs_species == i]\n",
    "b_oma = o_obs_ana[o_obs_species == i] - d_obs_obs[d_obs_species == i]\n",
    "\n",
    "o_inc = o_obs_ana[o_obs_species == i] - o_obs_fcst[o_obs_species == i]\n",
    "d_inc = d_obs_ana[d_obs_species == i] - d_obs_fcst[d_obs_species == i]\n",
    "\n",
    "# Plot the OMF and OMA\n",
    "plt.figure()\n",
    "plt.plot(o_omf, 'ro')\n",
    "plt.plot(d_omf, 'bo')\n",
    "plt.plot(b_omf, 'g+')\n",
    "plt.legend(['OL', 'DA', 'Bias corrected OL'])\n",
    "plt.title('OMF')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(o_oma, 'ro')\n",
    "plt.plot(d_oma, 'bo')\n",
    "plt.plot(b_oma, 'g+')\n",
    "plt.legend(['OL', 'DA', 'Bias corrected OL'])\n",
    "plt.title('OMA')\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(o_inc, 'ro')\n",
    "plt.plot(d_inc, 'bo')\n",
    "plt.legend(['OL', 'DA'])\n",
    "plt.title('Increment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, 14):\n",
    "    o_omf = o_obs_fcst[o_obs_species == i] - o_obs_obs[o_obs_species == i]\n",
    "    d_omf = d_obs_fcst[d_obs_species == i] - d_obs_obs[d_obs_species == i]\n",
    "    b_omf = o_obs_fcst[o_obs_species == i] - d_obs_obs[d_obs_species == i]\n",
    "\n",
    "    o_oma = o_obs_ana[o_obs_species == i] - o_obs_obs[o_obs_species == i]\n",
    "    d_oma = d_obs_ana[d_obs_species == i] - d_obs_obs[d_obs_species == i]\n",
    "\n",
    "    o_inc = o_obs_ana[o_obs_species == i] - o_obs_fcst[o_obs_species == i]\n",
    "    d_inc = d_obs_ana[d_obs_species == i] - d_obs_fcst[d_obs_species == i]\n",
    "\n",
    "    print('i = ', i) \n",
    "\n",
    "    if np.max(np.abs(o_obs_fcst[o_obs_species == i])) > 1000:\n",
    "        print('OL OMF has a large value:', np.max(np.abs(o_obs_fcst[o_obs_species == i])))\n",
    "    if np.max(np.abs(d_obs_fcst[d_obs_species == i])) > 1000:\n",
    "        print('DA OMF has a large value:', np.max(np.abs(d_obs_fcst[d_obs_species == i])))\n",
    "    if np.max(np.abs(o_obs_ana[o_obs_species == i])) > 1000:\n",
    "        print('OL OMA has a large value:', np.max(np.abs(o_obs_ana[o_obs_species == i])))\n",
    "    if np.max(np.abs(d_obs_ana[d_obs_species == i])) > 1000:\n",
    "        print('DA OMA has a large value:', np.max(np.abs(d_obs_ana[d_obs_species == i])))\n",
    "\n",
    "    print('OL OMF mean: ', np.nanmean(o_omf), ' OL OMF std: ', np.nanstd(o_omf))\n",
    "    print('DA OMF mean: ', np.nanmean(d_omf), ' DA OMF std: ', np.nanstd(d_omf))\n",
    "    print('BI OMF mean: ', np.nanmean(b_omf), ' BI OMF std: ', np.nanstd(b_omf))\n",
    "    print('OL OMA mean: ', np.nanmean(o_oma), ' OL OMA std: ', np.nanstd(o_oma), 'Max abs OMA: ', np.nanmax(np.abs(o_oma)))\n",
    "    print('DA OMA mean: ', np.nanmean(d_oma), ' DA OMA std: ', np.nanstd(d_oma), 'Max abs OMA: ', np.nanmax(np.abs(d_oma)))\n",
    "    print('OL Increment mean: ', np.nanmean(o_inc), ' OL Increment std: ', np.nanstd(o_inc))\n",
    "    print('DA Increment mean: ', np.nanmean(d_inc), ' DA Increment std: ', np.nanstd(d_inc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "expt1_name = 'LS_OLv8_M36'\n",
    "expt2_name = 'LS_DAv8_M36'\n",
    "\n",
    "start_date = datetime(2020, 1, 1)\n",
    "end_date = datetime(2020, 2, 1)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y%m%d')\n",
    "end_date_str = end_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the daily statistics in observation space\n",
    "\n",
    "# Define the print flag\n",
    "printflag = False\n",
    "\n",
    "# Initialize lists to store the mean values for each variable and the dates\n",
    "dates_list = []\n",
    "\n",
    "# Initialize daily mean lists for observation space\n",
    "daily_o_omf_mean = [] \n",
    "daily_d_omf_mean = []\n",
    "daily_b_omf_mean = []\n",
    "daily_o_oma_mean = []\n",
    "daily_d_oma_mean = []\n",
    "daily_o_inc_mean = []\n",
    "daily_d_inc_mean = []\n",
    "\n",
    "\n",
    "# Define the start and end dates\n",
    "# start_date = datetime.strptime('20150401', '%Y%m%d')\n",
    "# end_date = datetime.strptime('20210331', '%Y%m%d')\n",
    "\n",
    "# Loop over the dates\n",
    "current_date = start_date\n",
    "while current_date <= end_date:\n",
    "\n",
    "    print('current_date = ', current_date)\n",
    "\n",
    "    # Define the file name for the current date\n",
    "\n",
    "    # Define the path directory\n",
    "    path_dir = f'/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/{expt1_name}/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg'\n",
    "\n",
    "    # Define the common file name start\n",
    "    file_name_start = f'{expt1_name}.ens_avg.ldas_ObsFcstAna.'\n",
    "\n",
    "    file_name = file_name_start + current_date.strftime('%Y%m%d')\n",
    "    #if file_name[-4:] == '0105':\n",
    "    #    print('file_name = ', file_name)\n",
    "    \n",
    "    # Call the read_obsfcstana function for the current file\n",
    "    date_time, obs_species, obs_tilenum, obs_lon, obs_lat, obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar = read_obsfcstana_extend_datetime(path_dir, file_name, printflag)\n",
    "\n",
    "    # Convert the lists to numpy arrays\n",
    "    o_date_time = np.array(date_time)\n",
    "    o_obs_species = np.array(obs_species)\n",
    "    o_obs_tilenum = np.array(obs_tilenum)\n",
    "    o_obs_lon = np.array(obs_lon)\n",
    "    o_obs_lat = np.array(obs_lat)\n",
    "    o_obs_obs = np.array(obs_obs)\n",
    "    o_obs_fcst = np.array(obs_fcst)\n",
    "    o_obs_ana = np.array(obs_ana)\n",
    "\n",
    "    missing_val = -9999.0\n",
    "    o_obs_obs[o_obs_obs == missing_val] = np.nan\n",
    "    o_obs_fcst[o_obs_fcst == missing_val] = np.nan\n",
    "    o_obs_ana[o_obs_ana == missing_val] = np.nan\n",
    "\n",
    "\n",
    "    # Call the read_obsfcstana function for the expt2 file\n",
    "    path_dir = f'/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/{expt2_name}/output/SMAP_EASEv2_M36_GLOBAL/ana/ens_avg'\n",
    "\n",
    "    file_name_start = f'{expt2_name}.ens_avg.ldas_ObsFcstAna.'\n",
    "    file_name = file_name_start + current_date.strftime('%Y%m%d')\n",
    "\n",
    "    date_time, obs_species, obs_tilenum, obs_lon, obs_lat, obs_obs, obs_obsvar, obs_fcst, obs_fcstvar, obs_ana, obs_anavar = read_obsfcstana_extend_datetime(path_dir, file_name, printflag)\n",
    "\n",
    "    # Convert the lists to numpy arrays\n",
    "    d_date_time = np.array(date_time)\n",
    "    d_obs_species = np.array(obs_species)\n",
    "    d_obs_tilenum = np.array(obs_tilenum)\n",
    "    d_obs_lon = np.array(obs_lon)\n",
    "    d_obs_lat = np.array(obs_lat)\n",
    "    d_obs_obs = np.array(obs_obs)\n",
    "    d_obs_fcst = np.array(obs_fcst)\n",
    "    d_obs_ana = np.array(obs_ana)\n",
    "\n",
    "    missing_val = -9999.0\n",
    "    d_obs_obs[d_obs_obs == missing_val] = np.nan\n",
    "    d_obs_fcst[d_obs_fcst == missing_val] = np.nan\n",
    "    d_obs_ana[d_obs_ana == missing_val] = np.nan\n",
    "\n",
    "\n",
    "    def parse_date_time(date_time):\n",
    "        return [\n",
    "            f\"{dt['year'][0]:04d}-{dt['month'][0]:02d}-{dt['day'][0]:02d} {dt['hour'][0]:02d}:{dt['min'][0]:02d}:{dt['sec'][0]:02d}\"\n",
    "            for dt in date_time\n",
    "        ]\n",
    "\n",
    "    # Parse date_time\n",
    "    o_date_time_parsed = parse_date_time(o_date_time)\n",
    "    d_date_time_parsed = parse_date_time(d_date_time)\n",
    "\n",
    "    # Create DataFrames\n",
    "    o_df = pd.DataFrame({\n",
    "        'date_time': o_date_time_parsed,\n",
    "        'species': o_obs_species,\n",
    "        'tilenum': o_obs_tilenum,\n",
    "        'lon': o_obs_lon,\n",
    "        'lat': o_obs_lat\n",
    "    })\n",
    "\n",
    "    d_df = pd.DataFrame({\n",
    "        'date_time': d_date_time_parsed,\n",
    "        'species': d_obs_species,\n",
    "        'tilenum': d_obs_tilenum,\n",
    "        'lon': d_obs_lon,\n",
    "        'lat': d_obs_lat\n",
    "    })\n",
    "\n",
    "    # Merge DataFrames on all columns\n",
    "    merged_df = pd.merge(o_df.reset_index(), d_df.reset_index(), on=['date_time', 'species', 'tilenum', 'lon', 'lat'], suffixes=('_o', '_d'))\n",
    "\n",
    "    # Extract indices\n",
    "    o_indices = merged_df['index_o'].values\n",
    "    d_indices = merged_df['index_d'].values\n",
    "\n",
    "    # Convert to numpy arrays\n",
    "    o_indices = np.array(o_indices)\n",
    "    d_indices = np.array(d_indices)\n",
    "\n",
    "    # Apply the indices to the data arrays\n",
    "    o_obs_obs = o_obs_obs[o_indices]\n",
    "    o_obs_species = o_obs_species[o_indices]\n",
    "    o_obs_fcst = o_obs_fcst[o_indices]\n",
    "    o_obs_ana = o_obs_ana[o_indices]\n",
    "\n",
    "    d_obs_obs = d_obs_obs[d_indices]\n",
    "    d_obs_species = d_obs_species[d_indices]\n",
    "    d_obs_fcst = d_obs_fcst[d_indices]\n",
    "    d_obs_ana = d_obs_ana[d_indices]\n",
    "\n",
    "    # Calculate the daily statistics in observation space\n",
    "    for i in range(1, 14):\n",
    "        o_omf = o_obs_fcst[o_obs_species == i] - o_obs_obs[o_obs_species == i]\n",
    "        d_omf = d_obs_fcst[d_obs_species == i] - d_obs_obs[d_obs_species == i]\n",
    "        b_omf = o_obs_fcst[o_obs_species == i] - d_obs_obs[d_obs_species == i]\n",
    "\n",
    "        o_oma = o_obs_ana[o_obs_species == i] - o_obs_obs[o_obs_species == i]\n",
    "        d_oma = d_obs_ana[d_obs_species == i] - d_obs_obs[d_obs_species == i]\n",
    "\n",
    "        o_inc = o_obs_ana[o_obs_species == i] - o_obs_fcst[o_obs_species == i]\n",
    "        d_inc = d_obs_ana[d_obs_species == i] - d_obs_fcst[d_obs_species == i]\n",
    "\n",
    "        # Append the daily mean values to the daily mean lists\n",
    "        daily_o_omf_mean.append(np.nanmean(o_omf))\n",
    "        daily_d_omf_mean.append(np.nanmean(d_omf))\n",
    "        daily_b_omf_mean.append(np.nanmean(b_omf))\n",
    "        daily_o_oma_mean.append(np.nanmean(o_oma))\n",
    "        daily_d_oma_mean.append(np.nanmean(d_oma))\n",
    "        daily_o_inc_mean.append(np.nanmean(o_inc))\n",
    "        daily_d_inc_mean.append(np.nanmean(d_inc))\n",
    "\n",
    "    # Append the current date to the dates list\n",
    "    dates_list.append(current_date.strftime('%Y%m%d'))\n",
    "\n",
    "    # Increment the current date by one day\n",
    "    current_date += timedelta(days=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Length of daily_o_omf_mean: ', len(daily_o_omf_mean))\n",
    "\n",
    "species_names = ['SMOS_fit_Tbh_A', 'SMOS_fit_Tbh_D', 'SMOS_fit_Tbv_A', 'SMOS_fit_Tbv_D', 'SMAP_L1C_Tbh_A', \n",
    "                 'SMAP_L1C_Tbh_D', 'SMAP_L1C_Tbv_A', 'SMAP_L1C_Tbv_D', 'ASCAT_META_SM', 'ASCAT_METB_SM', \n",
    "                 'ASCAT_METC_SM', 'MYD10C1', 'MOD10C1']\n",
    "\n",
    "# Make daily time series plots of the mean OMF, OMA, and increments\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "daily_o_omf_mean = np.array(daily_o_omf_mean)\n",
    "daily_d_omf_mean = np.array(daily_d_omf_mean)\n",
    "daily_b_omf_mean = np.array(daily_b_omf_mean)\n",
    "daily_o_oma_mean = np.array(daily_o_oma_mean)\n",
    "daily_d_oma_mean = np.array(daily_d_oma_mean)\n",
    "daily_o_inc_mean = np.array(daily_o_inc_mean)\n",
    "daily_d_inc_mean = np.array(daily_d_inc_mean)\n",
    "\n",
    "# Convert the dates list to a numpy array\n",
    "dates_list = np.array(dates_list)\n",
    "\n",
    "# Plot the daily time series of the mean OMF, OMA, and increments for each species\n",
    "\n",
    "for i in range(1, 14):\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(dates_list, daily_d_omf_mean[i-1::13])\n",
    "    plt.plot(dates_list, daily_b_omf_mean[i-1::13])\n",
    "    plt.plot(dates_list, daily_d_oma_mean[i-1::13])\n",
    "    # Black dashed line at 0\n",
    "    plt.axhline(y=0, color='k', linestyle='--')\n",
    "    plt.legend(['DA OmF', 'bcOL OmF', 'DA OmA'])\n",
    "    # xtick labels only on every 7th day\n",
    "    plt.xticks(dates_list[::5], rotation=45)\n",
    "    # Put species names in the title\n",
    "    plt.title(f'{species_names[i-1]}')\n",
    "    # Save the figure\n",
    "    plt.savefig(f'/Users/amfox/Desktop/GEOSldas_diagnostics/figures/daily_time_series_{species_names[i-1]}.png')\n",
    "\n",
    "for i in range(1, 14):\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.plot(dates_list, daily_o_omf_mean[i-1::13])\n",
    "    plt.plot(dates_list, daily_b_omf_mean[i-1::13])\n",
    "    # Black dashed line at 0\n",
    "    plt.axhline(y=0, color='k', linestyle='--')\n",
    "    plt.legend(['OL OmF', 'bcOL OmF'])\n",
    "    # xtick labels only on every 7th day\n",
    "    plt.xticks(dates_list[::5], rotation=45)\n",
    "    # Put species names in the title\n",
    "    plt.title(f'{species_names[i-1]}')\n",
    "    # Save the figure\n",
    "    plt.savefig(f'/Users/amfox/Desktop/GEOSldas_diagnostics/figures/daily_time_series_OL_{species_names[i-1]}.png')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
