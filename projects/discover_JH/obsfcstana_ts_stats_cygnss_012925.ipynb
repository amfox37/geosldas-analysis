{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54fe27b-0c64-45d8-aa97-ab32db88b10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from mapper_functions import plot_global_tight_pcm, plot_global_tight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2252ee9a-3ac2-4723-bc9c-6ef8e0922e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt_name = 'long_run_cygd_M36'\n",
    "\n",
    "start_date = datetime(2018, 8, 1)\n",
    "end_date = datetime(2019, 8, 1)\n",
    "\n",
    "start_date_str = start_date.strftime('%Y%m%d')\n",
    "end_date_str = end_date.strftime('%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adbc728-ae57-401d-9794-4538488447c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the path to the netCDF file\n",
    "file_path = f'/discover/nobackup/amfox/Experiments/CYGNSS_development/{expt_name}/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg/Y2018/M08/{expt_name}.tavg24_1d_lnd_Nt.20180801_1200z.nc4'\n",
    "\n",
    "# Open the netCDF file\n",
    "dataset = xr.open_dataset(file_path)\n",
    "\n",
    "# Extract the lon and lat variables\n",
    "lon = dataset['lon']\n",
    "lat = dataset['lat']\n",
    "\n",
    "# Print the dimensions of the variables\n",
    "print(f\"Dimensions of lon: {lon.shape}\")\n",
    "print(f\"Dimensions of lat: {lat.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513aeb91-2265-408c-a5ea-e52cefa83c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open each of the saved files\n",
    "\n",
    "#data_2015 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2015.npz', allow_pickle=True)\n",
    "#data_2016 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2016.npz', allow_pickle=True)\n",
    "#data_2017 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2017.npz', allow_pickle=True)\n",
    "#data_2018 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2018.npz', allow_pickle=True)\n",
    "#data_2019 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2019.npz', allow_pickle=True)\n",
    "#data_2020 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2020.npz', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a04fe4-3702-4da2-ab6e-8b826a541c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and combine the data from each of the files\n",
    "#date_time = np.concatenate((data_2015['date_time'], data_2016['date_time'], data_2017['date_time'], data_2018['date_time'], data_2019['date_time'], data_2020['date_time']))\n",
    "#obs_species = np.concatenate((data_2015['obs_species'], data_2016['obs_species'], data_2017['obs_species'], data_2018['obs_species'], data_2019['obs_species'], data_2020['obs_species']))\n",
    "#obs_tilenum = np.concatenate((data_2015['obs_tilenum'], data_2016['obs_tilenum'], data_2017['obs_tilenum'], data_2018['obs_tilenum'], data_2019['obs_tilenum'], data_2020['obs_tilenum']))\n",
    "#obs_lon = np.concatenate((data_2015['obs_lon'], data_2016['obs_lon'], data_2017['obs_lon'], data_2018['obs_lon'], data_2019['obs_lon'], data_2020['obs_lon']))\n",
    "#obs_lat = np.concatenate((data_2015['obs_lat'], data_2016['obs_lat'], data_2017['obs_lat'], data_2018['obs_lat'], data_2019['obs_lat'], data_2020['obs_lat']))\n",
    "#obs_obs = np.concatenate((data_2015['obs_obs'], data_2016['obs_obs'], data_2017['obs_obs'], data_2018['obs_obs'], data_2019['obs_obs'], data_2020['obs_obs']))\n",
    "#obs_fcst = np.concatenate((data_2015['obs_fcst'], data_2016['obs_fcst'], data_2017['obs_fcst'], data_2018['obs_fcst'], data_2019['obs_fcst'], data_2020['obs_fcst']))\n",
    "#obs_ana = np.concatenate((data_2015['obs_ana'], data_2016['obs_ana'], data_2017['obs_ana'], data_2018['obs_ana'], data_2019['obs_ana'], data_2020['obs_ana']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2af0db-bec8-4b4b-94aa-8e32e6669e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2016 = np.load(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_extend_datetime_2018.npz', allow_pickle=True)\n",
    "\n",
    "## Extract and combine the data from each of the files\n",
    "date_time =   ((data_2016['date_time']))\n",
    "obs_species = ((data_2016['obs_species']))\n",
    "obs_tilenum = ((data_2016['obs_tilenum']))\n",
    "obs_lon =     ((data_2016['obs_lon']))\n",
    "obs_lat =     ((data_2016['obs_lat']))\n",
    "obs_obs =     ((data_2016['obs_obs']))\n",
    "obs_fcst =    ((data_2016['obs_fcst']))\n",
    "obs_ana =     ((data_2016['obs_ana']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dcbaf13-abe8-4c22-9371-1f4ece9d1860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate obs minus fcst\n",
    "obs_minus_fcst = []\n",
    "obs_minus_ana = []\n",
    "for i in range(len(obs_obs)):\n",
    "    obs_minus_fcst_chunk = obs_obs[i] - obs_fcst[i]\n",
    "    obs_minus_fcst.append(obs_minus_fcst_chunk)\n",
    "    obs_minus_ana_chunk = obs_obs[i] - obs_ana[i]\n",
    "    obs_minus_ana.append(obs_minus_ana_chunk)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973b55d0-ec23-4a42-9661-ea49dc2739d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to numpy arrays\n",
    "obs_minus_fcst = np.array(obs_minus_fcst)\n",
    "obs_minus_ana = np.array(obs_minus_ana)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c08734-e507-4a4c-a815-4bc811886d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unique tilenum values\n",
    "unique_tilenum = np.unique(obs_tilenum)\n",
    "\n",
    "# Find the number of unique tilenum values\n",
    "num_unique_tilenum = len(unique_tilenum)\n",
    "\n",
    "# Print the number of unique tilenum values\n",
    "print(f\"Number of unique tilenum values: {num_unique_tilenum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074bab8c-7585-4ee8-a365-8061c2959e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the arrays based on obs_tilenum\n",
    "sort_indices = np.argsort(obs_tilenum)\n",
    "sorted_obs_tilenum = obs_tilenum[sort_indices]\n",
    "sorted_obs_species = obs_species[sort_indices]\n",
    "sorted_obs_obs = obs_obs[sort_indices]\n",
    "sorted_obs_fcst = obs_fcst[sort_indices]\n",
    "sorted_obs_ana = obs_ana[sort_indices]\n",
    "sorted_obs_minus_fcst = obs_minus_fcst[sort_indices]\n",
    "sorted_obs_minus_ana = obs_minus_ana[sort_indices]\n",
    "sorted_date_time = date_time[sort_indices]\n",
    "\n",
    "# Find the unique tilenum values and their counts\n",
    "unique_tilenum, counts = np.unique(sorted_obs_tilenum, return_counts=True)\n",
    "\n",
    "# Calculate the indices where the groups should be split\n",
    "split_indices = np.cumsum(counts)[:-1]\n",
    "\n",
    "# Split the sorted arrays based on the split indices\n",
    "obs_species_grouped = np.split(sorted_obs_species, split_indices)\n",
    "obs_obs_grouped = np.split(sorted_obs_obs, split_indices)\n",
    "obs_fcst_grouped = np.split(sorted_obs_fcst, split_indices)\n",
    "obs_ana_grouped = np.split(sorted_obs_ana, split_indices)\n",
    "obs_minus_fcst_grouped = np.split(sorted_obs_minus_fcst, split_indices)\n",
    "obs_minus_ana_grouped = np.split(sorted_obs_minus_ana, split_indices)\n",
    "date_time_grouped = np.split(sorted_date_time, split_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a082d1ef-770b-46fe-bb62-997bb9fcd11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the length of obs_obs_grouped\n",
    "print(f\"Length of obs_obs_grouped: {len(obs_obs_grouped)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248f2f7f-d522-4e68-98e3-bc422bdbe4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you have a single sensor experiment\n",
    "\n",
    "# Find the number of observations for each tilenum\n",
    "num_obs = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    num_obs.append(len(obs_obs_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_obs for each tilenum\n",
    "mean_obs_obs = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_obs.append(np.mean(obs_obs_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_fcst for each tilenum\n",
    "mean_obs_fcst = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_fcst.append(np.mean(obs_fcst_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_ana for each tilenum\n",
    "mean_obs_ana = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_ana.append(np.mean(obs_ana_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_minus_fcst for each tilenum\n",
    "mean_obs_minus_fcst = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_minus_fcst.append(np.mean(obs_minus_fcst_grouped[i]))\n",
    "\n",
    "# Calculate the mean obs_minus_ana for each tilenum\n",
    "mean_obs_minus_ana = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    mean_obs_minus_ana.append(np.mean(obs_minus_ana_grouped[i]))\n",
    "\n",
    "# Calculate the standard deviation of obs_minus_fcst for each tilenum\n",
    "std_obs_minus_fcst = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_minus_fcst.append(np.std(obs_minus_fcst_grouped[i]))\n",
    "\n",
    "# Calculate the standard deviation of obs_minus_ana for each tilenum\n",
    "std_obs_minus_ana = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    std_obs_minus_ana.append(np.std(obs_minus_ana_grouped[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2807e7-7158-4d55-82ce-36b738d5874f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign lon and lat to each tilenum\n",
    "lon_tilenum = []\n",
    "lat_tilenum = []\n",
    "for i in range(num_unique_tilenum):\n",
    "    lon_tilenum.append(lon[int(unique_tilenum[i])])\n",
    "    lat_tilenum.append(lat[int(unique_tilenum[i])])\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "lon_tilenum = np.array(lon_tilenum)\n",
    "lat_tilenum = np.array(lat_tilenum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bd059d-c542-42c8-ac1e-72003ea4ecea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell if you have a single sensor experiment\n",
    "# Save all of the calculated values to a file\n",
    "np.savez(f'{expt_name}_{start_date_str}_{end_date_str}_obsfcstana_stats.npz', \n",
    "         unique_tilenum=unique_tilenum, \n",
    "         num_obs=num_obs, \n",
    "         mean_obs_obs=mean_obs_obs, \n",
    "         mean_obs_fcst=mean_obs_fcst, \n",
    "         mean_obs_ana=mean_obs_ana, \n",
    "         mean_obs_minus_fcst=mean_obs_minus_fcst, \n",
    "         mean_obs_minus_ana=mean_obs_minus_ana, \n",
    "         std_obs_minus_fcst=std_obs_minus_fcst, \n",
    "         std_obs_minus_ana=std_obs_minus_ana, \n",
    "         lon_tilenum=lon_tilenum, \n",
    "         lat_tilenum=lat_tilenum )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaab4cd-2ad8-479b-8be1-b3055888b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_array = num_obs\n",
    "test_array = np.array(test_array)\n",
    "#test_array[test_array < 1.] = np.nan\n",
    "    \n",
    "obarray = np.empty([num_unique_tilenum, 3])\n",
    "obarray[:, 1] = lon_tilenum\n",
    "obarray[:, 2] = lat_tilenum\n",
    "obarray[:, 0] = test_array\n",
    "   \n",
    "#plot_global_tight_pcm(obarray,False, True,'Number of Obs Assimilated','Total',0,300)\n",
    "\n",
    "maxval = np.nanmax(obarray[:, 0])\n",
    "minval = np.nanmin(obarray[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(obarray, False, True, f'Number of Obs Assimilated\\n (Min: {minval:.3g} Max: {maxval:.3g})', 'Total', 0, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001ed649-64e9-4e08-a94a-b57155a14c50",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:.conda-diag]",
   "language": "python",
   "name": "conda-env-.conda-diag-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}