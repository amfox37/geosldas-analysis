{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from helper.read_GEOSldas import read_tilecoord, read_obs_param\n",
    "from helper.util import make_folder, array2grid\n",
    "from helper.plot import plotMap\n",
    "from helper.smapeasev2 import smapeasev2_ind2latlon\n",
    "\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import sys \n",
    "import io\n",
    "\n",
    "#sys.stdout = io.TextIOWrapper(open(sys.stdout.fileno(), 'wb', 0), write_through=True)\n",
    "#sys.stderr = io.TextIOWrapper(open(sys.stderr.fileno(), 'wb', 0), write_through=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expdir = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/'\n",
    "expid = 'LS_DAv8_M36'\n",
    "domain = 'SMAP_EASEv2_M36_GLOBAL'\n",
    "\n",
    "start_time = datetime(2000,6,1)\n",
    "end_time = datetime(2024,4,1)\n",
    "\n",
    "start_date_str = start_time.strftime('%Y/%m/%d')\n",
    "end_date_str = end_time.strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expdir = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_Aus/'\n",
    "expid = 'DAv8_M36_Aus'\n",
    "domain = 'SMAP_EASEv2_M36_GLOBAL'\n",
    "\n",
    "start_time = datetime(2018,8,1)\n",
    "end_time = datetime(2024,7,1)\n",
    "\n",
    "start_date_str = start_time.strftime('%Y/%m/%d')\n",
    "end_date_str = end_time.strftime('%Y/%m/%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a minimum threshold for the temporal data points to ensure statistical reliability\n",
    "# of the computed metrics. \n",
    "Nmin = 20\n",
    "\n",
    "# Base directory for storing monthly files\n",
    "# This can be the same as the experiment directory (expdir) or a different location\n",
    "out_path_mo = expdir+expid+'/output/'+domain+'/ana/ens_avg/'\n",
    "\n",
    "# Directory for diagnostic plots\n",
    "out_path = expdir+expid+'/output/'+domain+'/figures/'\n",
    "make_folder(out_path)\n",
    "\n",
    "# Variable list for computing sum and sum of squared\n",
    "var_list = ['obs_obs', 'obs_obsvar','obs_fcst','obs_fcstvar','obs_ana','obs_anavar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tilecoord and obsparam for tile and obs species information\n",
    "ftc = os.path.join(expdir, expid, 'output', domain, 'rc_out', f'{expid}.ldas_tilecoord.bin')\n",
    "tc = read_tilecoord(ftc)\n",
    "n_tile = tc['N_tile']\n",
    "\n",
    "# Construct the file path dynamically using start_time\n",
    "fop = os.path.join(\n",
    "    expdir, expid, 'output', domain, 'rc_out',\n",
    "    'Y' + start_time.strftime('%Y'),\n",
    "    'M' + start_time.strftime('%m'),\n",
    "    f\"{expid}.ldas_obsparam.{start_time.strftime('%Y%m%d')}_0000z.txt\"\n",
    ")\n",
    "obs_param = read_obs_param(fop)\n",
    "n_spec = len(obs_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = {\n",
    "    \"SMOS\": [0, 1, 2, 3],\n",
    "    \"SMAP\": [4, 5, 6, 7],\n",
    "    \"ASCAT\": [8, 9, 10],\n",
    "    \"MODIS\": [11, 12]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = {\n",
    "    \"SMOS\": [0, 1, 2, 3],\n",
    "    \"SMAP\": [4, 5, 6, 7],\n",
    "    \"ASCAT\": [8, 9, 10],\n",
    "    \"CYGNSS\": [11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the lists of monthly data from the file\n",
    "\n",
    "with open(out_path + f'monthly_OmF_data_{expid}_{start_time.strftime(\"%Y%m%d\")}_{end_time.strftime(\"%Y%m%d\")}.pkl', 'rb') as f:\n",
    "    monthly_data = pickle.load(f)\n",
    "\n",
    "# Extract the data from the loaded dictionary\n",
    "N_data_group_all_months = monthly_data['N_data_group_all_months']\n",
    "OmF_mean_all_months = monthly_data['OmF_mean_all_months']\n",
    "OmF_stdv_all_months = monthly_data['OmF_stdv_all_months']\n",
    "monthly_timestamps = monthly_data['monthly_timestamps']\n",
    "\n",
    "# Load the group_metrics dictionary from the file\n",
    "with open(out_path + f'group_metrics_{expid}_{start_time.strftime(\"%Y%m%d\")}_{end_time.strftime(\"%Y%m%d\")}.pkl', 'rb') as f:\n",
    "    loaded_group_metrics = pickle.load(f)\n",
    "\n",
    "print(\"loaded_group_metrics keys:\", loaded_group_metrics.keys())    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot N_data_group for each species group\n",
    "plt.figure(figsize=(10, 6))\n",
    "for group, values in N_data_group_all_months.items():\n",
    "    values_in_millions = [v / 1e6 for v in values]  # Convert to millions\n",
    "    plt.plot(monthly_timestamps, values_in_millions, label=group)\n",
    "    print(f\"{group} N_data (in millions): {values_in_millions}\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('N_data (Millions)')\n",
    "plt.title('Total N_data by Species Group (in Millions)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(out_path + 'N_data_group.png')  # Save the plot for all groups\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "\n",
    "# Plot OmF_mean for each species group\n",
    "for group, values in OmF_mean_all_months.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, values, label=f'{group} OmF Mean', color='blue')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Mean')\n",
    "    plt.title(f'OmF Mean for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(out_path + f'OmF_Mean_{group}.png')  # Save the plot for each group\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Plot OmF_stdv for each species group\n",
    "for group, values in OmF_stdv_all_months.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, values, label=f'{group} OmF Stdv', color='orange')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Standard Deviation')\n",
    "    plt.title(f'OmF Standard Deviation for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(out_path + f'OmF_Stdv_{group}.png')  # Save the plot for each group\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(monthly_timestamps))\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(monthly_timestamps, label='Monthly Timestamps')\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.xlabel('Index')\n",
    "plt.ylabel('Timestamps')\n",
    "plt.title('Monthly Timestamps Plot')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaded_group_metrics = group_metrics\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['SMOS']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['SMOS']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['SMOS']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['SMOS']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['SMOS']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[k]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 5000] # np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' SMOS Tb Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-10, 10]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' SMOS Tb O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMOS Tb O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMOS Tb normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))\n",
    "    \n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])            \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_SMOS_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['SMAP']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['SMAP']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['SMAP']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['SMAP']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['SMAP']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[k]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 7000] #np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' SMAP Tb Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-10, 10]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' SMAP Tb O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMAP Tb O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMAP Tb normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))            \n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])            \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_SMAP_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['ASCAT']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['ASCAT']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['ASCAT']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['ASCAT']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['ASCAT']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[m3/m3]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 12000] #np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' ASCAT SM Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-0.05, 0.05]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' ASCAT SM O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 0.1]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' ASCAT SM O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' ASCAt SM normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))                \n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])            \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_ASCAT_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['MODIS']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['MODIS']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['MODIS']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['MODIS']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['MODIS']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[frac.]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 20000] #np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' SCF Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-1, 1]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' SCF O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 0.5]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SCF O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SCF normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])    \n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))                  \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_SCF_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['CYGNSS']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['CYGNSS']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['CYGNSS']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['CYGNSS']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['CYGNSS']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[frac.]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 3000] #np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' CYGNSS Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-0.25, 0.25]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' CYGNSS O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 0.1]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' CYGNSS O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' CYGNSS normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])    \n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))                  \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_SCF_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the lists of monthly data from the file\n",
    "expdir ='/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_Aus/' \n",
    "expid = 'DAv8_M36_Aus'\n",
    "out_path = expdir+expid+'/output/'+domain+'/figures/'\n",
    "\n",
    "with open(out_path + f'monthly_OmF_data_{expid}_{start_time.strftime(\"%Y%m%d\")}_{end_time.strftime(\"%Y%m%d\")}.pkl', 'rb') as f:\n",
    "    monthly_data_da = pickle.load(f)\n",
    "\n",
    "with open(out_path + f'group_metrics_{expid}_{start_time.strftime(\"%Y%m%d\")}_{end_time.strftime(\"%Y%m%d\")}.pkl', 'rb') as f:\n",
    "    group_metrics_da = pickle.load(f)   \n",
    "\n",
    "monthly_timestamps_da = monthly_data_da['monthly_timestamps']    \n",
    "\n",
    "expdir ='/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_Aus/' \n",
    "expid = 'OLv8_M36_Aus'\n",
    "out_path = expdir+expid+'/output/'+domain+'/figures/'\n",
    "# Load the lists of monthly data from the file\n",
    "with open(out_path + f'monthly_OmF_data_{expid}_{start_time.strftime(\"%Y%m%d\")}_{end_time.strftime(\"%Y%m%d\")}.pkl', 'rb') as f:\n",
    "    monthly_data_ol = pickle.load(f)\n",
    "\n",
    "with open(out_path + f'group_metrics_{expid}_{start_time.strftime(\"%Y%m%d\")}_{end_time.strftime(\"%Y%m%d\")}.pkl', 'rb') as f:\n",
    "    group_metrics_ol = pickle.load(f)\n",
    "\n",
    "monthly_timestamps_ol = monthly_data_ol['monthly_timestamps']    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot OmF_stdv for each species group in monthly_data_da\n",
    "plt.figure(figsize=(10, 6))\n",
    "for group, values in monthly_data_ol['OmF_stdv_all_months'].items():\n",
    "    mean_value = np.nanmean([v for v in values if v != 0])\n",
    "    plt.plot(monthly_timestamps_da, values, label=f'{group} (mean={mean_value:.3f})')\n",
    "    print(f\"{group} OmF StdDev: {values}\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('OmF Standard Deviation')\n",
    "plt.title('OmF Standard Deviation for Each Species Group')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_species_data(monthly_data, species_groups):\n",
    "    # Initialize grouped data dictionaries\n",
    "    N_data_grouped = {group: [] for group in species_groups.keys()}\n",
    "    OmF_mean_grouped = {group: [] for group in species_groups.keys()}\n",
    "    OmF_stdv_grouped = {group: [] for group in species_groups.keys()}\n",
    "    \n",
    "    # For each month\n",
    "    for month_idx in range(len(monthly_data['monthly_timestamps'])):\n",
    "        # Process each group\n",
    "        for group_name, species_indices in species_groups.items():\n",
    "            # Sum N_data across species in group\n",
    "            N_data_sum = sum(monthly_data['N_data_group_all_months'][species][month_idx] \n",
    "                           for species in species_indices)\n",
    "            \n",
    "            # Calculate weighted means for OmF metrics\n",
    "            OmF_mean_weights = [monthly_data['N_data_group_all_months'][species][month_idx] \n",
    "                              for species in species_indices]\n",
    "            OmF_mean_values = [monthly_data['OmF_mean_all_months'][species][month_idx] \n",
    "                             for species in species_indices]\n",
    "            OmF_stdv_values = [monthly_data['OmF_stdv_all_months'][species][month_idx] \n",
    "                             for species in species_indices]\n",
    "            \n",
    "            # Calculate weighted means, handling zero weights\n",
    "            if sum(OmF_mean_weights) > 0:\n",
    "                weighted_OmF_mean = np.average(OmF_mean_values, weights=OmF_mean_weights)\n",
    "                weighted_OmF_stdv = np.average(OmF_stdv_values, weights=OmF_mean_weights)\n",
    "            else:\n",
    "                weighted_OmF_mean = np.nan\n",
    "                weighted_OmF_stdv = np.nan\n",
    "            \n",
    "            # Store results\n",
    "            N_data_grouped[group_name].append(N_data_sum)\n",
    "            OmF_mean_grouped[group_name].append(weighted_OmF_mean)\n",
    "            OmF_stdv_grouped[group_name].append(weighted_OmF_stdv)\n",
    "    \n",
    "    return {\n",
    "        'N_data_group_all_months': N_data_grouped,\n",
    "        'OmF_mean_all_months': OmF_mean_grouped,\n",
    "        'OmF_stdv_all_months': OmF_stdv_grouped,\n",
    "        'monthly_timestamps': monthly_data['monthly_timestamps']\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "grouped_data_da = group_species_data(monthly_data_da, species_groups)\n",
    "grouped_data_ol = group_species_data(monthly_data_ol, species_groups)\n",
    "\n",
    "# Now you can use the grouped data with your existing plotting code\n",
    "N_data_group_all_months_da = grouped_data_da['N_data_group_all_months']\n",
    "N_data_group_all_months_ol = grouped_data_ol['N_data_group_all_months']\n",
    "OmF_mean_all_months_da = grouped_data_da['OmF_mean_all_months']\n",
    "OmF_mean_all_months_ol = grouped_data_ol['OmF_mean_all_months']\n",
    "OmF_stdv_all_months_da = grouped_data_da['OmF_stdv_all_months']\n",
    "OmF_stdv_all_months_ol = grouped_data_ol['OmF_stdv_all_months']\n",
    "monthly_timestamps_da = grouped_data_da['monthly_timestamps']\n",
    "monthly_timestamps_ol = grouped_data_ol['monthly_timestamps']\n",
    "\n",
    "# Replace 0 with NaN in the data\n",
    "for group, values in OmF_mean_all_months_da.items():\n",
    "    OmF_mean_all_months_da[group] = [np.nan if v == 0 else v for v in values]\n",
    "\n",
    "for group, values in OmF_stdv_all_months_da.items():\n",
    "    OmF_stdv_all_months_da[group] = [np.nan if v == 0 else v for v in values]\n",
    "\n",
    "for group, values in OmF_mean_all_months_ol.items():\n",
    "    OmF_mean_all_months_ol[group] = [np.nan if v == 0 else v for v in values]\n",
    "\n",
    "for group, values in OmF_stdv_all_months_ol.items():\n",
    "    OmF_stdv_all_months_ol[group] = [np.nan if v == 0 else v for v in values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot N_data_group for each species group for both DA and OL experiments on the same plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "for group, values in N_data_group_all_months_da.items():\n",
    "    values_in_millions = [v / 1e6 for v in values]  # Convert to millions\n",
    "    plt.plot(monthly_timestamps_da, values_in_millions, label=f'{group} DA')\n",
    "    print(f\"{group} DA N_data (in millions): {values_in_millions}\")\n",
    "for group, values in N_data_group_all_months_ol.items():\n",
    "    values_in_millions = [v / 1e6 for v in values]  # Convert to millions\n",
    "    plt.plot(monthly_timestamps_ol, values_in_millions, label=f'{group} OL', linestyle='--')\n",
    "    print(f\"{group} OL N_data (in millions): {values_in_millions}\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('N_data (Millions)')\n",
    "plt.title('Total N_data by Species Group (in Millions) for DA and OL')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.savefig(out_path + 'N_data_group_OLS_OL.png')  # Save the plot for all groups\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot OmF_mean for each species group for both DA and OL experiments on the same plot\n",
    "for group, values in OmF_mean_all_months_da.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    mean_da = np.nanmean(values)\n",
    "    mean_ol = np.nanmean(OmF_mean_all_months_ol[group])\n",
    "    plt.plot(monthly_timestamps_da, values, label=f'{group} DA (mean={mean_da:.3f})')\n",
    "    print(f\"{group} DA OmF Mean: {values}, Mean: {mean_da:.3f}\")\n",
    "    plt.plot(monthly_timestamps_ol, OmF_mean_all_months_ol[group], label=f'{group} OL (mean={mean_ol:.3f})', linestyle='--')\n",
    "    print(f\"{group} OL OmF Mean: {OmF_mean_all_months_ol[group]}, Mean: {mean_ol:.3f}\")\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Mean')\n",
    "    plt.title(f'OmF Mean for {group} (DA vs OL)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(out_path + f'OmF_Mean_{group}_OLS_OL.png')  # Save the plot for each group\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Plot OmF_stdv for each species group for both DA and OL experiments on the same plot\n",
    "for group, values in OmF_stdv_all_months_da.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    mean_da = np.nanmean(values)\n",
    "    mean_ol = np.nanmean(OmF_stdv_all_months_ol[group])\n",
    "    plt.plot(monthly_timestamps_da, values, label=f'{group} DA (mean={mean_da:.3f})')\n",
    "    print(f\"{group} DA OmF Stdv: {values}, Mean: {mean_da:.3f}\")\n",
    "    plt.plot(monthly_timestamps_ol, OmF_stdv_all_months_ol[group], label=f'{group} OL (mean={mean_ol:.3f})', linestyle='--')\n",
    "    print(f\"{group} OL OmF Stdv: {OmF_stdv_all_months_ol[group]}, Mean: {mean_ol:.3f}\")\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Standard Deviation')\n",
    "    plt.title(f'OmF Standard Deviation for {group} (DA vs OL)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(out_path + f'OmF_Stdv_{group}_OLS_OL.png')  # Save the plot for each group\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Plot N_data_group for each species group for both DA and OL experiments on separate plots\n",
    "for group, values in N_data_group_all_months_da.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    values_in_millions_da = [v / 1e6 for v in values]  # Convert to millions\n",
    "    values_in_millions_ol = [v / 1e6 for v in N_data_group_all_months_ol[group]]  # Convert to millions\n",
    "    mean_da = np.nanmean(values_in_millions_da)\n",
    "    mean_ol = np.nanmean(values_in_millions_ol)\n",
    "    plt.plot(monthly_timestamps_da, values_in_millions_da, label=f'{group} DA (mean={mean_da:.3f})')\n",
    "    print(f\"{group} DA N_data (in millions): {values_in_millions_da}, Mean: {mean_da:.3f}\")\n",
    "    plt.plot(monthly_timestamps_ol, values_in_millions_ol, label=f'{group} OL (mean={mean_ol:.3f})', linestyle='--')\n",
    "    print(f\"{group} OL N_data (in millions): {values_in_millions_ol}, Mean: {mean_ol:.3f}\")\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('N_data (Millions)')\n",
    "    plt.title(f'Total N_data for {group} (DA vs OL)')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.savefig(out_path + f'N_data_{group}_OLS_OL.png')  # Save the plot for each group\n",
    "    plt.show()\n",
    "    plt.close()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../Jupyter')\n",
    "from mapper_functions import plot_global_tight_pcm, plot_aus_tight_pcm\n",
    "\n",
    "lat = tc['com_lat']\n",
    "lon = tc['com_lon']\n",
    "\n",
    "# Determine the number of tiles based on the latitude array\n",
    "n_tile = len(lat)\n",
    "\n",
    "# Initialize an observation array with NaN values\n",
    "# The array has dimensions [n_tile, 3], where:\n",
    "# - Column 0 is reserved for future use\n",
    "# - Column 1 stores longitude values\n",
    "# - Column 2 stores latitude values\n",
    "map_array = np.empty([n_tile, 3])\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 1] = lon\n",
    "map_array[:, 2] = lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_id = 'SMOS'\n",
    "\n",
    "# Avoid division by zero by replacing zeros in the denominator with np.nan\n",
    "denominator = np.array(group_metrics_ol[group_id]['OmF_stdv'])\n",
    "denominator[denominator == 0] = np.nan\n",
    "\n",
    "# Compute the percentage difference safely\n",
    "map_array[:, 0] = ((np.array(group_metrics_da[group_id]['OmF_stdv']) - denominator) / denominator) * 100\n",
    "\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(map_array, True, True, f'DA-OL relative delta StdDev of OmF:\\n {group_id} Tb (Max: {maxval:.3g} Min: {minval:.3g})', '%', -60, 60)\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'DA-OL relative delta StdDev of OmF:\\n {group_id} Tb (Max: {maxval:.3g} Min: {minval:.3g})', '%', -60, 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "group_id = 'SMAP'\n",
    "\n",
    "# Avoid division by zero by replacing zeros in the denominator with np.nan\n",
    "denominator = np.array(group_metrics_ol[group_id]['OmF_stdv'])\n",
    "denominator[denominator == 0] = np.nan\n",
    "\n",
    "# Compute the percentage difference safely\n",
    "map_array[:, 0] = ((np.array(group_metrics_da[group_id]['OmF_stdv']) - denominator) / denominator) * 100\n",
    "\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(map_array, True, True, f'DA-OL relative delta StdDev of OmF:\\n {group_id} Tb (Max: {maxval:.3g} Min: {minval:.3g})', '%', -60, 60)\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'DA-OL relative delta StdDev of OmF:\\n {group_id} Tb (Max: {maxval:.3g} Min: {minval:.3g})', '%', -60, 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = 'ASCAT'\n",
    "\n",
    "# Avoid division by zero by replacing zeros in the denominator with np.nan\n",
    "denominator = np.array(group_metrics_ol[group_id]['OmF_stdv'])\n",
    "denominator[denominator == 0] = np.nan\n",
    "\n",
    "# Compute the percentage difference safely\n",
    "map_array[:, 0] = ((np.array(group_metrics_da[group_id]['OmF_stdv']) - denominator) / denominator) * 100\n",
    "\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(map_array, True, True, f'DA-OL relative delta StdDev of OmF:\\n {group_id} SM (Max: {maxval:.3g} Min: {minval:.3g})', '%', -60, 60)\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'DA-OL relative delta StdDev of OmF:\\n {group_id} SM (Max: {maxval:.3g} Min: {minval:.3g})', '%', -60, 60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = 'CYGNSS'\n",
    "\n",
    "# Avoid division by zero by replacing zeros in the denominator with np.nan\n",
    "denominator = np.array(group_metrics_ol[group_id]['OmF_stdv'])\n",
    "denominator[denominator == 0] = np.nan\n",
    "\n",
    "# Compute the percentage difference safely\n",
    "map_array[:, 0] = ((np.array(group_metrics_da[group_id]['OmF_stdv']) - denominator) / denominator) * 100\n",
    "\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_global_tight_pcm(map_array, True, True, f'DA-OL relative delta StdDev of OmF:\\n {group_id} SM (Max: {maxval:.3g} Min: {minval:.3g})', '%', -60, 60)\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'DA-OL relative delta StdDev of OmF:\\n {group_id} SM (Max: {maxval:.3g} Min: {minval:.3g})', '%', -60, 60)\n",
    "\n",
    "mask = np.array(group_metrics_ol['SMAP']['OmF_stdv'])\n",
    "mask = np.where(~np.isnan(mask), 1, np.nan)\n",
    "\n",
    "map_array[:, 0] = map_array[:, 0]* mask\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'DA-OL relative delta StdDev of OmF:\\n {group_id} SM (SMAP \"mask\") (Max: {maxval:.3g} Min: {minval:.3g})', '%', -60, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_id = 'CYGNSS'\n",
    "\n",
    "denominator = np.array(group_metrics_ol[group_id]['Nobs_data'])\n",
    "denominator[denominator == 0] = np.nan\n",
    "\n",
    "map_array[:, 0] = denominator\n",
    "\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'Number of observations:\\n {group_id} SM (Max: {maxval:.3g} Min: {minval:.3g})', '-', 0, 3000)\n",
    "\n",
    "denominator = np.array(group_metrics_ol[group_id]['OmF_mean'])\n",
    "denominator[denominator == 0] = np.nan\n",
    "\n",
    "map_array[:, 0] = denominator\n",
    "\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'OL OmF Mean:\\n {group_id} SM (Max: {maxval:.3g} Min: {minval:.3g})', 'm続/m続', -0.3, 0.3)\n",
    "\n",
    "denominator = np.array(group_metrics_da[group_id]['OmF_mean'])\n",
    "denominator[denominator == 0] = np.nan\n",
    "\n",
    "map_array[:, 0] = denominator\n",
    "\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'DA OmF Mean:\\n {group_id} SM (Max: {maxval:.3g} Min: {minval:.3g})', 'm続/m続', -0.3, 0.3)\n",
    "\n",
    "denominator = np.array(group_metrics_ol[group_id]['OmF_stdv'])\n",
    "denominator[denominator == 0] = np.nan\n",
    "\n",
    "map_array[:, 0] = denominator\n",
    "\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'OL OmF StDv:\\n {group_id} SM (Max: {maxval:.3g} Min: {minval:.3g})', 'm続/m続', 0, 0.1)\n",
    "\n",
    "denominator = np.array(group_metrics_da[group_id]['OmF_stdv'])\n",
    "denominator[denominator == 0] = np.nan\n",
    "\n",
    "map_array[:, 0] = denominator\n",
    "\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'DA OmF StDv:\\n {group_id} SM (Max: {maxval:.3g} Min: {minval:.3g})', 'm続/m続', 0., 0.1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "denominator = np.array(group_metrics_ol[group_id]['OmF_stdv'])\n",
    "denominator[denominator == 0] = np.nan\n",
    "\n",
    "map_array[:, 0] = (np.array(group_metrics_da[group_id]['OmF_stdv']) - denominator) / denominator\n",
    "\n",
    "# Calculate max and min values, ignoring NaNs\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "plot_aus_tight_pcm(map_array, True, True, f'(DA - OL OmF StDv)/OL:\\n {group_id} SM (Max: {maxval:.3g} Min: {minval:.3g})', '-', -1, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
