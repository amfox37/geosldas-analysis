{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper.read_GEOSldas import read_tilecoord, read_obs_param\n",
    "from helper.util import make_folder, array2grid\n",
    "from helper.plot import plotMap\n",
    "from helper.smapeasev2 import smapeasev2_ind2latlon\n",
    "from helper.compute_monthly_stats import compute_monthly_stats\n",
    "from helper.write_nc4 import write_sums_nc4\n",
    "\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import sys \n",
    "import io\n",
    "\n",
    "#sys.stdout = io.TextIOWrapper(open(sys.stdout.fileno(), 'wb', 0), write_through=True)\n",
    "#sys.stderr = io.TextIOWrapper(open(sys.stderr.fileno(), 'wb', 0), write_through=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expdir = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_Aus/'\n",
    "expid = 'DAv8_M36_Aus'\n",
    "domain = 'SMAP_EASEv2_M36_GLOBAL'\n",
    "\n",
    "start_time = datetime(2018,8,1)\n",
    "end_time = datetime(2018,10,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a minimum threshold for the temporal data points to ensure statistical reliability\n",
    "# of the computed metrics. \n",
    "Nmin = 5 #20\n",
    "\n",
    "# Base directory for storing monthly files\n",
    "# This can be the same as the experiment directory (expdir) or a different location\n",
    "out_path_mo = expdir+expid+'/output/'+domain+'/ana/ens_avg/'\n",
    "\n",
    "# Directory for diagnostic plots\n",
    "out_path = expdir+expid+'/output/'+domain+'/figures/'\n",
    "make_folder(out_path)\n",
    "\n",
    "# Variable list for computing sum and sum of squared\n",
    "var_list = ['obs_obs', 'obs_obsvar','obs_fcst','obs_fcstvar','obs_ana','obs_anavar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tilecoord and obsparam for tile and obs species information\n",
    "ftc = os.path.join(expdir, expid, 'output', domain, 'rc_out', f'{expid}.ldas_tilecoord.bin')\n",
    "tc = read_tilecoord(ftc)\n",
    "n_tile = tc['N_tile']\n",
    "\n",
    "# Construct the file path dynamically using start_time\n",
    "fop = os.path.join(\n",
    "    expdir, expid, 'output', domain, 'rc_out',\n",
    "    'Y' + start_time.strftime('%Y'),\n",
    "    'M' + start_time.strftime('%m'),\n",
    "    f\"{expid}.ldas_obsparam.{start_time.strftime('%Y%m%d')}_0000z.txt\"\n",
    ")\n",
    "obs_param = read_obs_param(fop)\n",
    "n_spec = len(obs_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize statistical metrics \n",
    "data_sum = {}\n",
    "data2_sum = {}\n",
    "N_data = np.zeros((n_tile, n_spec))\n",
    "oxf_sum = np.zeros((n_tile, n_spec))\n",
    "oxa_sum = np.zeros((n_tile, n_spec))\n",
    "fxa_sum = np.zeros((n_tile, n_spec))\n",
    "\n",
    "for var in var_list:\n",
    "    data_sum[var] = np.zeros((n_tile, n_spec))\n",
    "    data2_sum[var] = np.zeros((n_tile, n_spec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time loop: processing data at monthly time step\n",
    "date_time = start_time\n",
    "while date_time < end_time:\n",
    "    # File to store monthly statistics    \n",
    "    fout_path = out_path_mo + '/Y'+ date_time.strftime('%Y') + '/M' + date_time.strftime('%m') + '/'\n",
    "    make_folder(fout_path)\n",
    "    \n",
    "    fout = fout_path + expid+'.ens_avg.ldas_ObsFcstAna.' + date_time.strftime('%Y%m') +'_stats.nc4'\n",
    "\n",
    "    # Read monthly data if file exists, otherwise compute monthly statistics first   \n",
    "    if os.path.isfile(fout):\n",
    "        print('read sums from  monthly file: '+fout)\n",
    "        mdata_sum = {}\n",
    "        mdata2_sum = {}\n",
    "        with Dataset(fout,'r') as nc:\n",
    "            mN_data = nc.variables['N_data'][:]\n",
    "            moxf_sum = nc.variables['obsxfcst_sum'][:]\n",
    "            moxa_sum = nc.variables['obsxana_sum'][:]\n",
    "            mfxa_sum = nc.variables['fcstxana_sum'][:]\n",
    "            for var in var_list:\n",
    "                mdata_sum[var] = nc.variables[var+'_sum'][:]\n",
    "                mdata2_sum[var] = nc.variables[var+'2_sum'][:]\n",
    "    else:\n",
    "        print('compute monthly sums for '+date_time.strftime('%Y%m'))\n",
    "        mN_data, mdata_sum, mdata2_sum, moxf_sum, moxa_sum, mfxa_sum = \\\n",
    "                 compute_monthly_stats(expdir,expid,domain,date_time,tc,obs_param,var_list)\n",
    "        print('save to monthly file: '+fout)\n",
    "        write_sums_nc4(fout, mN_data,mdata_sum, mdata2_sum, moxf_sum, moxa_sum, mfxa_sum, obs_param)\n",
    "\n",
    "    # Aggregate monthly data\n",
    "    N_data += mN_data\n",
    "    oxf_sum += moxf_sum\n",
    "    oxa_sum += moxa_sum\n",
    "    fxa_sum += mfxa_sum\n",
    "   \n",
    "    for var in var_list:\n",
    "        data_sum[var] += mdata_sum[var] \n",
    "        data2_sum[var] += mdata2_sum[var]  \n",
    "        \n",
    "    date_time =date_time + relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time loop: processing data at monthly time step for OPENLOOP experiment\n",
    "\n",
    "from helper.compute_monthly_stats_OL import compute_monthly_stats_OL\n",
    "\n",
    "da_expdir='/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/'\n",
    "da_expid='LS_DAv8_M36'\n",
    "    \n",
    "date_time = start_time\n",
    "while date_time < end_time:\n",
    "    # File to store monthly statistics    \n",
    "    fout_path = out_path_mo + '/Y'+ date_time.strftime('%Y') + '/M' + date_time.strftime('%m') + '/'\n",
    "    make_folder(fout_path)\n",
    "    \n",
    "    fout = fout_path + expid+'.ens_avg.ldas_ObsFcstAna.' + date_time.strftime('%Y%m') +'_stats_CROSSMASKED.nc4'\n",
    "\n",
    "    # Read monthly data if file exists, otherwise compute monthly statistics first   \n",
    "    if os.path.isfile(fout):\n",
    "        print('read sums from  monthly file: '+fout)\n",
    "        mdata_sum = {}\n",
    "        mdata2_sum = {}\n",
    "        with Dataset(fout,'r') as nc:\n",
    "            mN_data = nc.variables['N_data'][:]\n",
    "            moxf_sum = nc.variables['obsxfcst_sum'][:]\n",
    "            moxa_sum = nc.variables['obsxana_sum'][:]\n",
    "            mfxa_sum = nc.variables['fcstxana_sum'][:]\n",
    "            for var in var_list:\n",
    "                mdata_sum[var] = nc.variables[var+'_sum'][:]\n",
    "                mdata2_sum[var] = nc.variables[var+'2_sum'][:]\n",
    "    else:\n",
    "        print('compute monthly sums for '+date_time.strftime('%Y%m'))\n",
    "        mN_data, mdata_sum, mdata2_sum, moxf_sum, moxa_sum, mfxa_sum = \\\n",
    "             compute_monthly_stats_OL(expdir,\n",
    "                  expid,\n",
    "                  domain,\n",
    "                  date_time,\n",
    "                  tc,\n",
    "                  obs_param,\n",
    "                  var_list,\n",
    "                  da_expdir,\n",
    "                  da_expid)\n",
    "        print('save to monthly file: '+fout)\n",
    "        write_sums_nc4(fout, mN_data,mdata_sum, mdata2_sum, moxf_sum, moxa_sum, mfxa_sum, obs_param)\n",
    "\n",
    "    # Aggregate monthly data\n",
    "    N_data += mN_data\n",
    "    oxf_sum += moxf_sum\n",
    "    oxa_sum += moxa_sum\n",
    "    fxa_sum += mfxa_sum\n",
    "   \n",
    "    for var in var_list:\n",
    "        data_sum[var] += mdata_sum[var] \n",
    "        data2_sum[var] += mdata2_sum[var]  \n",
    "        \n",
    "    date_time =date_time + relativedelta(months=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = {\n",
    "    \"SMOS\": [0, 1, 2, 3],\n",
    "    \"SMAP\": [4, 5, 6, 7],\n",
    "    \"ASCAT\": [8, 9, 10],\n",
    "    \"MODIS\": [11, 12]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = {\n",
    "    \"SMOS\": [0, 1, 2, 3],\n",
    "    \"SMAP\": [4, 5, 6, 7],\n",
    "    \"ASCAT\": [8, 9, 10],\n",
    "    \"CYGNSS\": [11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage for time series data\n",
    "N_data_group_all_months = {group: [] for group in species_groups}\n",
    "OmF_mean_all_months = {group: [] for group in species_groups}\n",
    "OmF_stdv_all_months = {group: [] for group in species_groups}\n",
    "monthly_timestamps = []  # To store the timestamps for each month\n",
    "\n",
    "# Time loop: processing data at monthly time step\n",
    "date_time = start_time\n",
    "while date_time < end_time:\n",
    "    # File to store monthly statistics    \n",
    "    fout_path = out_path_mo + '/Y' + date_time.strftime('%Y') + '/M' + date_time.strftime('%m') + '/'\n",
    "    make_folder(fout_path)\n",
    "    \n",
    "    fout = fout_path + expid + '.ens_avg.ldas_ObsFcstAna.' + date_time.strftime('%Y%m') + '_stats.nc4'\n",
    "\n",
    "    # Read monthly data if file exists\n",
    "    if os.path.isfile(fout):\n",
    "        print('Reading sums from monthly file: ' + fout)\n",
    "        with Dataset(fout, 'r') as nc:\n",
    "            mN_data = nc.variables['N_data'][:]  # Shape: (tiles, species)\n",
    "            moxf_sum = nc.variables['obsxfcst_sum'][:]  # Shape: (tiles, species)\n",
    "            mdata_sum = {var: nc.variables[var + '_sum'][:] for var in var_list}\n",
    "            mdata2_sum = {var: nc.variables[var + '2_sum'][:] for var in var_list}\n",
    "    else:\n",
    "        print('Cannot find monthly file: ' + fout)\n",
    "        date_time += relativedelta(months=1)\n",
    "        continue\n",
    "\n",
    "    # Compute metrics for each species group\n",
    "    for group, indices in species_groups.items():\n",
    "        # Sum across tiles for the species in this group\n",
    "        N_data_group = np.sum(mN_data[:, indices], axis=1)  # Total count for the group\n",
    "        OmF_sum_group = np.sum(moxf_sum[:, indices], axis=1)  # Total OmF sum for the group\n",
    "\n",
    "        # Convert N_data_group to float to allow NaN values\n",
    "        N_data_group = N_data_group.astype(float)\n",
    "\n",
    "        # Filter out invalid data\n",
    "        N_data_group[N_data_group == 0] = np.nan\n",
    "\n",
    "        # Compute group-level means and variances\n",
    "        data_mean = {var: np.sum(mdata_sum[var][:, indices], axis=1) / N_data_group for var in var_list}\n",
    "        data2_mean = {var: np.sum(mdata2_sum[var][:, indices], axis=1) / N_data_group for var in var_list}\n",
    "        data_var = {var: data2_mean[var] - data_mean[var]**2 for var in var_list}\n",
    "\n",
    "        # Compute OmF_mean and OmF_stdv\n",
    "        OmF_mean = data_mean['obs_obs'] - data_mean['obs_fcst']\n",
    "        OmF_stdv = np.sqrt(\n",
    "            data_var['obs_obs'] + data_var['obs_fcst'] -\n",
    "            2 * (OmF_sum_group / N_data_group - data_mean['obs_obs'] * data_mean['obs_fcst'])\n",
    "        )\n",
    "\n",
    "        # Ensure arrays are writable\n",
    "        OmF_mean = np.copy(OmF_mean)\n",
    "        OmF_stdv = np.copy(OmF_stdv)\n",
    "\n",
    "        # Aggregate results to single values\n",
    "        N_data_group_total = np.nansum(N_data_group)  # Total N_data for the group\n",
    "        OmF_mean_avg = np.nanmean(OmF_mean)  # Mean OmF for the group\n",
    "        OmF_stdv_avg = np.nanmean(OmF_stdv)  # Stdv OmF for the group\n",
    "\n",
    "        # Store the results for the current month\n",
    "        N_data_group_all_months[group].append(N_data_group_total)\n",
    "        OmF_mean_all_months[group].append(OmF_mean_avg)\n",
    "        OmF_stdv_all_months[group].append(OmF_stdv_avg)\n",
    "\n",
    "    # Store the current timestamp for the month\n",
    "    monthly_timestamps.append(date_time)\n",
    "\n",
    "    # Increment to the next month\n",
    "    date_time += relativedelta(months=1)\n",
    "\n",
    "# Plot N_data_group for each species group\n",
    "plt.figure(figsize=(10, 6))\n",
    "for group, values in N_data_group_all_months.items():\n",
    "    values_in_millions = [v / 1e6 for v in values]  # Convert to millions\n",
    "    plt.plot(monthly_timestamps, values_in_millions, label=group)\n",
    "    print(f\"{group} N_data (in millions): {values_in_millions}\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('N_data (Millions)')\n",
    "plt.title('Total N_data by Species Group (in Millions)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot OmF_mean for each species group\n",
    "for group, values in OmF_mean_all_months.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, values, label=f'{group} OmF Mean', color='blue')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Mean')\n",
    "    plt.title(f'OmF Mean for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.savefig(out_path + f'OmF_Mean_{group}.png')  # Save the plot for each group\n",
    "    plt.close()\n",
    "\n",
    "# Plot OmF_stdv for each species group\n",
    "for group, values in OmF_stdv_all_months.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, values, label=f'{group} OmF Stdv', color='orange')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Standard Deviation')\n",
    "    plt.title(f'OmF Standard Deviation for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.savefig(out_path + f'OmF_Stdv_{group}.png')  # Save the plot for each group\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    OmF_stdv_all_months_OL = {group: values.copy() for group, values in OmF_stdv_all_months.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage for time series data\n",
    "N_data_group_all_months = {group: [] for group in species_groups}\n",
    "OmF_mean_all_months = {group: [] for group in species_groups}\n",
    "OmF_stdv_all_months = {group: [] for group in species_groups}\n",
    "monthly_timestamps = []  # To store the timestamps for each month\n",
    "\n",
    "# Time loop: processing data at monthly time step\n",
    "date_time = start_time\n",
    "while date_time < end_time:\n",
    "    # File to store monthly statistics    \n",
    "    fout_path = out_path_mo + '/Y' + date_time.strftime('%Y') + '/M' + date_time.strftime('%m') + '/'\n",
    "    make_folder(fout_path)\n",
    "    \n",
    "    fout = fout_path + expid + '.ens_avg.ldas_ObsFcstAna.' + date_time.strftime('%Y%m') + '_stats_CROSSMASKED.nc4'\n",
    "\n",
    "    # Read monthly data if file exists\n",
    "    if os.path.isfile(fout):\n",
    "        print('Reading sums from monthly file: ' + fout)\n",
    "        with Dataset(fout, 'r') as nc:\n",
    "            mN_data = nc.variables['N_data'][:]  # Shape: (tiles, species)\n",
    "            moxf_sum = nc.variables['obsxfcst_sum'][:]  # Shape: (tiles, species)\n",
    "            mdata_sum = {var: nc.variables[var + '_sum'][:] for var in var_list}\n",
    "            mdata2_sum = {var: nc.variables[var + '2_sum'][:] for var in var_list}\n",
    "    else:\n",
    "        print('Cannot find monthly file: ' + fout)\n",
    "        date_time += relativedelta(months=1)\n",
    "        continue\n",
    "\n",
    "    # Compute metrics for each species group\n",
    "    for group, indices in species_groups.items():\n",
    "        # Sum across tiles for the species in this group\n",
    "        N_data_group = np.sum(mN_data[:, indices], axis=1)  # Total count for the group\n",
    "        OmF_sum_group = np.sum(moxf_sum[:, indices], axis=1)  # Total OmF sum for the group\n",
    "\n",
    "        # Convert N_data_group to float to allow NaN values\n",
    "        N_data_group = N_data_group.astype(float)\n",
    "\n",
    "        # Filter out invalid data\n",
    "        N_data_group[N_data_group == 0] = np.nan\n",
    "\n",
    "        # Compute group-level means and variances\n",
    "        data_mean = {var: np.sum(mdata_sum[var][:, indices], axis=1) / N_data_group for var in var_list}\n",
    "        data2_mean = {var: np.sum(mdata2_sum[var][:, indices], axis=1) / N_data_group for var in var_list}\n",
    "        data_var = {var: data2_mean[var] - data_mean[var]**2 for var in var_list}\n",
    "\n",
    "        # Compute OmF_mean and OmF_stdv\n",
    "        OmF_mean = data_mean['obs_obs'] - data_mean['obs_fcst']\n",
    "        OmF_stdv = np.sqrt(\n",
    "            data_var['obs_obs'] + data_var['obs_fcst'] -\n",
    "            2 * (OmF_sum_group / N_data_group - data_mean['obs_obs'] * data_mean['obs_fcst'])\n",
    "        )\n",
    "\n",
    "        # Ensure arrays are writable\n",
    "        OmF_mean = np.copy(OmF_mean)\n",
    "        OmF_stdv = np.copy(OmF_stdv)\n",
    "\n",
    "        # Aggregate results to single values\n",
    "        N_data_group_total = np.nansum(N_data_group)  # Total N_data for the group\n",
    "        OmF_mean_avg = np.nanmean(OmF_mean)  # Mean OmF for the group\n",
    "        OmF_stdv_avg = np.nanmean(OmF_stdv)  # Stdv OmF for the group\n",
    "\n",
    "        # Store the results for the current month\n",
    "        N_data_group_all_months[group].append(N_data_group_total)\n",
    "        OmF_mean_all_months[group].append(OmF_mean_avg)\n",
    "        OmF_stdv_all_months[group].append(OmF_stdv_avg)\n",
    "\n",
    "    # Store the current timestamp for the month\n",
    "    monthly_timestamps.append(date_time)\n",
    "\n",
    "    # Increment to the next month\n",
    "    date_time += relativedelta(months=1)\n",
    "\n",
    "# Plot N_data_group for each species group\n",
    "plt.figure(figsize=(10, 6))\n",
    "for group, values in N_data_group_all_months.items():\n",
    "    values_in_millions = [v / 1e6 for v in values]  # Convert to millions\n",
    "    plt.plot(monthly_timestamps, values_in_millions, label=group)\n",
    "    print(f\"{group} N_data (in millions): {values_in_millions}\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('N_data (Millions)')\n",
    "plt.title('Total N_data by Species Group (in Millions)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot OmF_mean for each species group\n",
    "for group, values in OmF_mean_all_months.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, values, label=f'{group} OmF Mean', color='blue')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Mean')\n",
    "    plt.title(f'OmF Mean for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.savefig(out_path + f'OmF_Mean_{group}.png')  # Save the plot for each group\n",
    "    plt.close()\n",
    "\n",
    "# Plot OmF_stdv for each species group\n",
    "for group, values in OmF_stdv_all_months.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, values, label=f'{group} OmF Stdv', color='orange')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Standard Deviation')\n",
    "    plt.title(f'OmF Standard Deviation for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.savefig(out_path + f'OmF_Stdv_{group}.png')  # Save the plot for each group\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "    OmF_stdv_all_months_CM = {group: values.copy() for group, values in OmF_stdv_all_months.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expid='LS_DAv8_M36'\n",
    "\n",
    "out_path_mo = expdir+expid+'/output/'+domain+'/ana/ens_avg/'\n",
    "\n",
    "# Initialize storage for time series data\n",
    "N_data_group_all_months = {group: [] for group in species_groups}\n",
    "OmF_mean_all_months = {group: [] for group in species_groups}\n",
    "OmF_stdv_all_months = {group: [] for group in species_groups}\n",
    "monthly_timestamps = []  # To store the timestamps for each month\n",
    "\n",
    "# Time loop: processing data at monthly time step\n",
    "date_time = start_time\n",
    "while date_time < end_time:\n",
    "    # File to store monthly statistics    \n",
    "    fout_path = out_path_mo + '/Y' + date_time.strftime('%Y') + '/M' + date_time.strftime('%m') + '/'\n",
    "    make_folder(fout_path)\n",
    "    \n",
    "    fout = fout_path + expid + '.ens_avg.ldas_ObsFcstAna.' + date_time.strftime('%Y%m') + '_stats.nc4'\n",
    "\n",
    "    # Read monthly data if file exists\n",
    "    if os.path.isfile(fout):\n",
    "        print('Reading sums from monthly file: ' + fout)\n",
    "        with Dataset(fout, 'r') as nc:\n",
    "            mN_data = nc.variables['N_data'][:]  # Shape: (tiles, species)\n",
    "            moxf_sum = nc.variables['obsxfcst_sum'][:]  # Shape: (tiles, species)\n",
    "            mdata_sum = {var: nc.variables[var + '_sum'][:] for var in var_list}\n",
    "            mdata2_sum = {var: nc.variables[var + '2_sum'][:] for var in var_list}\n",
    "    else:\n",
    "        print('Cannot find monthly file: ' + fout)\n",
    "        date_time += relativedelta(months=1)\n",
    "        continue\n",
    "\n",
    "    # Compute metrics for each species group\n",
    "    for group, indices in species_groups.items():\n",
    "        # Sum across tiles for the species in this group\n",
    "        N_data_group = np.sum(mN_data[:, indices], axis=1)  # Total count for the group\n",
    "        OmF_sum_group = np.sum(moxf_sum[:, indices], axis=1)  # Total OmF sum for the group\n",
    "\n",
    "        # Convert N_data_group to float to allow NaN values\n",
    "        N_data_group = N_data_group.astype(float)\n",
    "\n",
    "        # Filter out invalid data\n",
    "        N_data_group[N_data_group == 0] = np.nan\n",
    "\n",
    "        # Compute group-level means and variances\n",
    "        data_mean = {var: np.sum(mdata_sum[var][:, indices], axis=1) / N_data_group for var in var_list}\n",
    "        data2_mean = {var: np.sum(mdata2_sum[var][:, indices], axis=1) / N_data_group for var in var_list}\n",
    "        data_var = {var: data2_mean[var] - data_mean[var]**2 for var in var_list}\n",
    "\n",
    "        # Compute OmF_mean and OmF_stdv\n",
    "        OmF_mean = data_mean['obs_obs'] - data_mean['obs_fcst']\n",
    "        OmF_stdv = np.sqrt(\n",
    "            data_var['obs_obs'] + data_var['obs_fcst'] -\n",
    "            2 * (OmF_sum_group / N_data_group - data_mean['obs_obs'] * data_mean['obs_fcst'])\n",
    "        )\n",
    "\n",
    "        # Ensure arrays are writable\n",
    "        OmF_mean = np.copy(OmF_mean)\n",
    "        OmF_stdv = np.copy(OmF_stdv)\n",
    "\n",
    "        # Aggregate results to single values\n",
    "        N_data_group_total = np.nansum(N_data_group)  # Total N_data for the group\n",
    "        OmF_mean_avg = np.nanmean(OmF_mean)  # Mean OmF for the group\n",
    "        OmF_stdv_avg = np.nanmean(OmF_stdv)  # Stdv OmF for the group\n",
    "\n",
    "        # Store the results for the current month\n",
    "        N_data_group_all_months[group].append(N_data_group_total)\n",
    "        OmF_mean_all_months[group].append(OmF_mean_avg)\n",
    "        OmF_stdv_all_months[group].append(OmF_stdv_avg)\n",
    "\n",
    "    # Store the current timestamp for the month\n",
    "    monthly_timestamps.append(date_time)\n",
    "\n",
    "    # Increment to the next month\n",
    "    date_time += relativedelta(months=1)\n",
    "\n",
    "# Plot N_data_group for each species group\n",
    "plt.figure(figsize=(10, 6))\n",
    "for group, values in N_data_group_all_months.items():\n",
    "    values_in_millions = [v / 1e6 for v in values]  # Convert to millions\n",
    "    plt.plot(monthly_timestamps, values_in_millions, label=group)\n",
    "    print(f\"{group} N_data (in millions): {values_in_millions}\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('N_data (Millions)')\n",
    "plt.title('Total N_data by Species Group (in Millions)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot OmF_mean for each species group\n",
    "for group, values in OmF_mean_all_months.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, values, label=f'{group} OmF Mean', color='blue')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Mean')\n",
    "    plt.title(f'OmF Mean for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.savefig(out_path + f'OmF_Mean_{group}.png')  # Save the plot for each group\n",
    "    plt.close()\n",
    "\n",
    "# Plot OmF_stdv for each species group\n",
    "for group, values in OmF_stdv_all_months.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, values, label=f'{group} OmF Stdv', color='orange')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Standard Deviation')\n",
    "    plt.title(f'OmF Standard Deviation for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.savefig(out_path + f'OmF_Stdv_{group}.png')  # Save the plot for each group\n",
    "    plt.close()\n",
    "\n",
    "    OmF_stdv_all_months_DA = {group: values.copy() for group, values in OmF_stdv_all_months.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot OmF_stdv for each species group\n",
    "for group, values in OmF_stdv_all_months.items():\n",
    "    # Plot three lines per group\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, OmF_stdv_all_months_OL[group], label=f'{group} OL', color='blue')\n",
    "    plt.plot(monthly_timestamps, OmF_stdv_all_months_CM[group], label=f'{group} CM', color='green')\n",
    "    plt.plot(monthly_timestamps, OmF_stdv_all_months_DA[group], label=f'{group} DA', color='red')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Standard Deviation')\n",
    "    plt.title(f'OmF Standard Deviation Comparison for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.savefig(out_path + f'OmF_Stdv_Comparison_{group}.png')  # Save the plot for each group\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the final statistics\n",
    "# This section calculate the final statistical metrics based on the accumulated data.\n",
    "data_mean ={}\n",
    "data2_mean = {}\n",
    "data_var = {}\n",
    "\n",
    "# First, compute the metrics of individual variables  \n",
    "for var in var_list:\n",
    "    data_sum[var][N_data == 0] = np.nan\n",
    "    data2_sum[var][N_data == 0] = np.nan\n",
    "    \n",
    "    data_mean[var]  = data_sum[var] / N_data\n",
    "    data2_mean[var] = data2_sum[var] /N_data\n",
    "    # var(x) = E[x2] - (E[x])^2\n",
    "    data_var[var] = data2_mean[var] - data_mean[var]**2\n",
    "    \n",
    "oxf_sum[N_data == 0] = np.nan\n",
    "oxa_sum[N_data == 0] = np.nan\n",
    "fxa_sum[N_data == 0] = np.nan\n",
    "# E[xy]\n",
    "oxf_mean = oxf_sum / N_data\n",
    "oxa_mean = oxa_sum / N_data\n",
    "fxa_mean = fxa_sum / N_data\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed \n",
    "# mean(x-y) = E[x] - E[y]   \n",
    "OmF_mean = data_mean['obs_obs'] - data_mean['obs_fcst']\n",
    "OmA_mean = data_mean['obs_obs'] - data_mean['obs_ana']\n",
    "# var(x-y) = var(x) + var(y) - 2cov(x,y)\n",
    "# cov(x,y) = E[xy] - E[x]E[y]\n",
    "OmF_stdv  = np.sqrt(data_var['obs_obs'] + data_var['obs_fcst'] - \\\n",
    "                       2 * (oxf_mean - data_mean['obs_obs']*data_mean['obs_fcst']))\n",
    "                    \n",
    "OmA_stdv  = np.sqrt(data_var['obs_obs'] + data_var['obs_ana'] - \\\n",
    "                       2 * (oxa_mean - data_mean['obs_obs']*data_mean['obs_ana']))\n",
    "\n",
    "OmF_norm_mean = OmF_mean / np.sqrt(data_mean['obs_obsvar'] + data_mean['obs_fcstvar']) \n",
    "OmF_norm_stdv = np.sqrt(OmF_stdv**2 / (data_mean['obs_obsvar'] + data_mean['obs_fcstvar']) )\n",
    "    \n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[N_data < Nmin] = np.nan\n",
    "OmF_stdv[N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[N_data < Nmin] = np.nan\n",
    "OmA_stdv[N_data < Nmin] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = {\n",
    "    \"SMOS\": [0, 1, 2, 3],\n",
    "    \"SMAP\": [4, 5, 6, 7],\n",
    "    \"ASCAT\": [8, 9, 10],\n",
    "    \"MODIS\": [11, 12]\n",
    "}\n",
    "\n",
    "group_metrics = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['Nobs_data'] = group_N_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_sum['obs_obs'].shape)\n",
    "\n",
    "print('size N_data:', N_data.shape)\n",
    "\n",
    "print('size OmF_mean:', OmF_mean.shape)\n",
    "\n",
    "print(group_N_data.shape)\n",
    "\n",
    "print('Max of group_N_data:', np.nanmax(group_N_data))\n",
    "print('Min of group_N_data:', np.nanmin(group_N_data))\n",
    "print('Mean of group_N_data:', np.nanmean(group_N_data))\n",
    "\n",
    "print(species_indices)\n",
    "\n",
    "print('Max of N_data[:, species_indices]:', np.nanmax(N_data[:, species_indices]))\n",
    "print('Min of N_data[:, species_indices]:', np.nanmin(N_data[:, species_indices]))\n",
    "print('Mean of N_data[:, species_indices]:', np.nanmean(N_data[:, species_indices]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Debugging: Check out_path\n",
    "print(\"out_path:\", out_path)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# Debugging: Check group_metrics before saving\n",
    "print(\"group_metrics:\", group_metrics)\n",
    "\n",
    "# Save the group_metrics dictionary to a file\n",
    "with open(out_path + 'group_metrics.pkl', 'wb') as f:\n",
    "    pickle.dump(group_metrics, f)\n",
    "\n",
    "# Debugging: Check if the file was saved\n",
    "print(\"File exists:\", os.path.exists(out_path + 'group_metrics.pkl'))\n",
    "\n",
    "# Load the group_metrics dictionary from the file\n",
    "with open(out_path + 'group_metrics.pkl', 'rb') as f:\n",
    "    loaded_group_metrics = pickle.load(f)\n",
    "\n",
    "# Debugging: Check the loaded dictionary\n",
    "print(\"loaded_group_metrics:\", loaded_group_metrics)\n",
    "print(\"loaded_group_metrics keys:\", loaded_group_metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Plotting\n",
    "expdir = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/'\n",
    "expid = 'LS_DAv8_M36'\n",
    "domain = 'SMAP_EASEv2_M36_GLOBAL'\n",
    "outpath = \"./\"\n",
    "\n",
    "start_time = datetime(2000,6,1)\n",
    "end_time = datetime(2024,4,1)\n",
    "\n",
    "# Load the group_metrics dictionary from the file\n",
    "with open('group_metrics.pkl', 'rb') as f:\n",
    "   loaded_group_metrics = pickle.load(f)\n",
    "\n",
    "# Load the group_metrics dictionary from the file\n",
    "#with open(out_path + 'group_metrics.pkl', 'rb') as f:\n",
    "#    loaded_group_metrics = pickle.load(f)    \n",
    "\n",
    "print(\"loaded_group_metrics keys:\", loaded_group_metrics.keys())\n",
    "\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['SMOS']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['SMOS']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['SMOS']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['SMOS']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['SMOS']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[k]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 5000] # np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' SMOS Tb Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-10, 10]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' SMOS Tb O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMOS Tb O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMOS Tb normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))\n",
    "    \n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])            \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['SMAP']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['SMAP']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['SMAP']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['SMAP']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['SMAP']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[k]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 7000] #np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' SMAP Tb Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-10, 10]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' SMAP Tb O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMAP Tb O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMAP Tb normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))            \n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])            \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['ASCAT']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['ASCAT']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['ASCAT']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['ASCAT']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['ASCAT']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[m3/m3]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 12000] #np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' ASCAT SM Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-0.05, 0.05]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' ASCAT SM O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 0.1]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' ASCAT SM O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' ASCAt SM normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))                \n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])            \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['MODIS']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['MODIS']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['MODIS']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['MODIS']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['MODIS']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[frac.]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 20000] #np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' SCF Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-1, 1]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' SCF O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 0.5]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SCF O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SCF normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])    \n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))                  \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
