{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "from helper.read_GEOSldas import read_tilecoord, read_obs_param\n",
    "from helper.util import make_folder, array2grid\n",
    "from helper.plot import plotMap\n",
    "from helper.smapeasev2 import smapeasev2_ind2latlon\n",
    "\n",
    "import warnings; warnings.filterwarnings(\"ignore\")\n",
    "import sys \n",
    "import io\n",
    "\n",
    "#sys.stdout = io.TextIOWrapper(open(sys.stdout.fileno(), 'wb', 0), write_through=True)\n",
    "#sys.stderr = io.TextIOWrapper(open(sys.stderr.fileno(), 'wb', 0), write_through=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expdir = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/'\n",
    "expid = 'LS_DAv8_M36'\n",
    "domain = 'SMAP_EASEv2_M36_GLOBAL'\n",
    "\n",
    "start_time = datetime(2020,1,1)\n",
    "end_time = datetime(2021,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a minimum threshold for the temporal data points to ensure statistical reliability\n",
    "# of the computed metrics. \n",
    "Nmin = 20\n",
    "\n",
    "# Base directory for storing monthly files\n",
    "# This can be the same as the experiment directory (expdir) or a different location\n",
    "out_path_mo = expdir+expid+'/output/'+domain+'/ana/ens_avg/'\n",
    "\n",
    "# Directory for diagnostic plots\n",
    "out_path = expdir+expid+'/output/'+domain+'/figures/'\n",
    "make_folder(out_path)\n",
    "\n",
    "# Variable list for computing sum and sum of squared\n",
    "var_list = ['obs_obs', 'obs_obsvar','obs_fcst','obs_fcstvar','obs_ana','obs_anavar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tilecoord and obsparam for tile and obs species information\n",
    "ftc = os.path.join(expdir, expid, 'output', domain, 'rc_out', f'{expid}.ldas_tilecoord.bin')\n",
    "tc = read_tilecoord(ftc)\n",
    "n_tile = tc['N_tile']\n",
    "\n",
    "# Construct the file path dynamically using start_time\n",
    "fop = os.path.join(\n",
    "    expdir, expid, 'output', domain, 'rc_out',\n",
    "    'Y' + start_time.strftime('%Y'),\n",
    "    'M' + start_time.strftime('%m'),\n",
    "    f\"{expid}.ldas_obsparam.{start_time.strftime('%Y%m%d')}_0000z.txt\"\n",
    ")\n",
    "obs_param = read_obs_param(fop)\n",
    "n_spec = len(obs_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = {\n",
    "    \"SMOS\": [0, 1, 2, 3],\n",
    "    \"SMAP\": [4, 5, 6, 7],\n",
    "    \"ASCAT\": [8, 9, 10],\n",
    "    \"MODIS\": [11, 12]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initialize statistical metrics \n",
    "data_sum = {}\n",
    "data2_sum = {}\n",
    "N_data = np.zeros((n_tile, n_spec))\n",
    "oxf_sum = np.zeros((n_tile, n_spec))\n",
    "oxa_sum = np.zeros((n_tile, n_spec))\n",
    "fxa_sum = np.zeros((n_tile, n_spec))\n",
    "\n",
    "for var in var_list:\n",
    "    data_sum[var] = np.zeros((n_tile, n_spec))\n",
    "    data2_sum[var] = np.zeros((n_tile, n_spec))   \n",
    "\n",
    "# Initialize storage for time series data for each species\n",
    "N_data_all_months = {species: [] for species in range(13)}  # For 13 species (0-12)\n",
    "OmF_mean_all_months = {species: [] for species in range(13)}  # For 13 species (0-12)\n",
    "OmF_stdv_all_months = {species: [] for species in range(13)}\n",
    "OmA_mean_all_months = {species: [] for species in range(13)}\n",
    "OmA_stdv_all_months = {species: [] for species in range(13)}\n",
    "OmF_norm_mean_all_months = {species: [] for species in range(13)}\n",
    "OmF_norm_stdv_all_months = {species: [] for species in range(13)}\n",
    "monthly_timestamps = []  # To store the timestamps for each month\n",
    "\n",
    "# Time loop: processing data at monthly time step\n",
    "date_time = start_time\n",
    "while date_time < end_time:\n",
    "    # File to store monthly statistics    \n",
    "    fout_path = out_path_mo + '/Y' + date_time.strftime('%Y') + '/M' + date_time.strftime('%m') + '/'\n",
    "    make_folder(fout_path)\n",
    "    \n",
    "    fout = fout_path + expid + '.ens_avg.ldas_ObsFcstAna.' + date_time.strftime('%Y%m') + '_stats.nc4'\n",
    "\n",
    "    # Read monthly data if file exists\n",
    "    if os.path.isfile(fout):\n",
    "        print('Reading sums from monthly file: ' + fout)\n",
    "        with Dataset(fout, 'r') as nc:\n",
    "            mN_data = nc.variables['N_data'][:]  # Shape: (tiles, species)\n",
    "            moxf_sum = nc.variables['obsxfcst_sum'][:]  # Shape: (tiles, species)\n",
    "            moxa_sum = nc.variables['obsxana_sum'][:]\n",
    "            mfxa_sum = nc.variables['fcstxana_sum'][:]\n",
    "            mdata_sum = {var: nc.variables[var + '_sum'][:] for var in var_list}\n",
    "            mdata2_sum = {var: nc.variables[var + '2_sum'][:] for var in var_list}\n",
    "    else:\n",
    "        print('Cannot find monthly file: ' + fout)\n",
    "        date_time += relativedelta(months=1)\n",
    "        continue\n",
    "\n",
    "    # Aggregate monthly data\n",
    "    N_data += mN_data\n",
    "    oxf_sum += moxf_sum\n",
    "    oxa_sum += moxa_sum\n",
    "    fxa_sum += mfxa_sum\n",
    "   \n",
    "    for var in var_list:\n",
    "        data_sum[var] += mdata_sum[var] \n",
    "        data2_sum[var] += mdata2_sum[var]       \n",
    "    \n",
    "    # Convert mN_data to float to allow NaN values\n",
    "    mN_data = mN_data.astype(float)\n",
    "    \n",
    "    # Initialize dictionaries for monthly stats\n",
    "    mdata_mean = {}\n",
    "    mdata2_mean = {}\n",
    "    mdata_var = {}\n",
    "    \n",
    "    # First, compute the metrics of individual variables  \n",
    "    for var in var_list:\n",
    "        # Create copies to make arrays writable\n",
    "        mdata_sum_copy = np.copy(mdata_sum[var])\n",
    "        mdata2_sum_copy = np.copy(mdata2_sum[var])\n",
    "        \n",
    "        # Filter out zeros\n",
    "        mdata_sum_copy[mN_data == 0] = np.nan\n",
    "        mdata2_sum_copy[mN_data == 0] = np.nan\n",
    "        \n",
    "        # Compute means and variances\n",
    "        mdata_mean[var] = mdata_sum_copy / mN_data\n",
    "        mdata2_mean[var] = mdata2_sum_copy / mN_data\n",
    "        # var(x) = E[x2] - (E[x])^2\n",
    "        mdata_var[var] = mdata2_mean[var] - mdata_mean[var]**2\n",
    "    \n",
    "    # Create copies of sum arrays\n",
    "    moxf_sum_copy = np.copy(moxf_sum)\n",
    "    moxa_sum_copy = np.copy(moxa_sum)\n",
    "    mfxa_sum_copy = np.copy(mfxa_sum)\n",
    "    \n",
    "    # Filter out zeros\n",
    "    moxf_sum_copy[mN_data == 0] = np.nan\n",
    "    moxa_sum_copy[mN_data == 0] = np.nan\n",
    "    mfxa_sum_copy[mN_data == 0] = np.nan\n",
    "    \n",
    "    # E[xy]\n",
    "    moxf_mean = moxf_sum_copy / mN_data\n",
    "    moxa_mean = moxa_sum_copy / mN_data\n",
    "    mfxa_mean = mfxa_sum_copy / mN_data\n",
    "    \n",
    "    # Then compute metrics of O-F, O-A, etc. based on above computed \n",
    "    # mean(x-y) = E[x] - E[y]   \n",
    "    mOmF_mean = mdata_mean['obs_obs'] - mdata_mean['obs_fcst']\n",
    "    mOmA_mean = mdata_mean['obs_obs'] - mdata_mean['obs_ana']\n",
    "    \n",
    "    # var(x-y) = var(x) + var(y) - 2cov(x,y)\n",
    "    # cov(x,y) = E[xy] - E[x]E[y]\n",
    "    mOmF_stdv = np.sqrt(mdata_var['obs_obs'] + mdata_var['obs_fcst'] - \n",
    "                        2 * (moxf_mean - mdata_mean['obs_obs'] * mdata_mean['obs_fcst']))\n",
    "                        \n",
    "    mOmA_stdv = np.sqrt(mdata_var['obs_obs'] + mdata_var['obs_ana'] - \n",
    "                        2 * (moxa_mean - mdata_mean['obs_obs'] * mdata_mean['obs_ana']))\n",
    "    \n",
    "    mOmF_norm_mean = mOmF_mean / np.sqrt(mdata_mean['obs_obsvar'] + mdata_mean['obs_fcstvar'])\n",
    "    mOmF_norm_stdv = np.sqrt(mOmF_stdv**2 / (mdata_mean['obs_obsvar'] + mdata_mean['obs_fcstvar']))\n",
    "    \n",
    "    # Create writable copies before species loop\n",
    "    mOmF_mean_copy = np.copy(mOmF_mean)\n",
    "    mOmF_stdv_copy = np.copy(mOmF_stdv)\n",
    "    mOmA_mean_copy = np.copy(mOmA_mean)\n",
    "    mOmA_stdv_copy = np.copy(mOmA_stdv)\n",
    "    mOmF_norm_mean_copy = np.copy(mOmF_norm_mean)\n",
    "    mOmF_norm_stdv_copy = np.copy(mOmF_norm_stdv)\n",
    "\n",
    "# Store metrics for each species separately\n",
    "for species in range(13):\n",
    "    # Get observation counts per tile for this species\n",
    "    tile_counts = mN_data[:, species]\n",
    "    \n",
    "    # Calculate total N_data for this species (sum across all tiles)\n",
    "    N_data_total = np.nansum(tile_counts)\n",
    "    \n",
    "    # Only use tiles with observations for weighted averages\n",
    "    valid_tiles = tile_counts > 0\n",
    "    \n",
    "    # Compute weighted averages across tiles if we have valid data\n",
    "    if np.any(valid_tiles):\n",
    "        weights = tile_counts[valid_tiles]\n",
    "        OmF_mean_avg = np.average(mOmF_mean_copy[valid_tiles, species], weights=weights)\n",
    "        OmF_stdv_avg = np.average(mOmF_stdv_copy[valid_tiles, species], weights=weights)\n",
    "        OmA_mean_avg = np.average(mOmA_mean_copy[valid_tiles, species], weights=weights)\n",
    "        OmA_stdv_avg = np.average(mOmA_stdv_copy[valid_tiles, species], weights=weights)\n",
    "        OmF_norm_mean_avg = np.average(mOmF_norm_mean_copy[valid_tiles, species], weights=weights)\n",
    "        OmF_norm_stdv_avg = np.average(mOmF_norm_stdv_copy[valid_tiles, species], weights=weights)\n",
    "    else:\n",
    "        # No valid data for this species\n",
    "        OmF_mean_avg = np.nan\n",
    "        OmF_stdv_avg = np.nan\n",
    "        OmA_mean_avg = np.nan\n",
    "        OmA_stdv_avg = np.nan\n",
    "        OmF_norm_mean_avg = np.nan\n",
    "        OmF_norm_stdv_avg = np.nan\n",
    "        \n",
    "        # Store the results for the current month for this species\n",
    "        N_data_all_months[species].append(N_data_total)\n",
    "        OmF_mean_all_months[species].append(OmF_mean_avg)\n",
    "        OmF_stdv_all_months[species].append(OmF_stdv_avg)\n",
    "        OmA_mean_all_months[species].append(OmA_mean_avg)\n",
    "        OmA_stdv_all_months[species].append(OmA_stdv_avg)\n",
    "        OmF_norm_mean_all_months[species].append(OmF_norm_mean_avg)\n",
    "        OmF_norm_stdv_all_months[species].append(OmF_norm_stdv_avg)\n",
    "    \n",
    "    # Store the current timestamp for the month\n",
    "    monthly_timestamps.append(date_time)\n",
    "    \n",
    "    # Increment to the next month\n",
    "    date_time += relativedelta(months=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for species in range(13):\n",
    "    print(f\"{species_names[species]}: {np.nanmean(OmF_stdv_all_months[species])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the lists of monthly data to a file\n",
    "with open(out_path + f'monthly_OmF_data_{expid}_{start_time.strftime(\"%Y%m%d\")}_{end_time.strftime(\"%Y%m%d\")}.pkl', 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'N_data_group_all_months': N_data_all_months,\n",
    "        'OmF_mean_all_months': OmF_mean_all_months,\n",
    "        'OmF_stdv_all_months': OmF_stdv_all_months,\n",
    "        'monthly_timestamps': monthly_timestamps\n",
    "    }, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the final statistics\n",
    "# This section calculate the final statistical metrics based on the accumulated data.\n",
    "data_mean ={}\n",
    "data2_mean = {}\n",
    "data_var = {}\n",
    "\n",
    "# First, compute the metrics of individual variables  \n",
    "for var in var_list:\n",
    "    data_sum[var][N_data == 0] = np.nan\n",
    "    data2_sum[var][N_data == 0] = np.nan\n",
    "    \n",
    "    data_mean[var]  = data_sum[var] / N_data\n",
    "    data2_mean[var] = data2_sum[var] /N_data\n",
    "    # var(x) = E[x2] - (E[x])^2\n",
    "    data_var[var] = data2_mean[var] - data_mean[var]**2\n",
    "    \n",
    "oxf_sum[N_data == 0] = np.nan\n",
    "oxa_sum[N_data == 0] = np.nan\n",
    "fxa_sum[N_data == 0] = np.nan\n",
    "# E[xy]\n",
    "oxf_mean = oxf_sum / N_data\n",
    "oxa_mean = oxa_sum / N_data\n",
    "fxa_mean = fxa_sum / N_data\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed \n",
    "# mean(x-y) = E[x] - E[y]   \n",
    "OmF_mean = data_mean['obs_obs'] - data_mean['obs_fcst']\n",
    "OmA_mean = data_mean['obs_obs'] - data_mean['obs_ana']\n",
    "# var(x-y) = var(x) + var(y) - 2cov(x,y)\n",
    "# cov(x,y) = E[xy] - E[x]E[y]\n",
    "OmF_stdv  = np.sqrt(data_var['obs_obs'] + data_var['obs_fcst'] - \\\n",
    "                       2 * (oxf_mean - data_mean['obs_obs']*data_mean['obs_fcst']))\n",
    "                    \n",
    "OmA_stdv  = np.sqrt(data_var['obs_obs'] + data_var['obs_ana'] - \\\n",
    "                       2 * (oxa_mean - data_mean['obs_obs']*data_mean['obs_ana']))\n",
    "\n",
    "OmF_norm_mean = OmF_mean / np.sqrt(data_mean['obs_obsvar'] + data_mean['obs_fcstvar']) \n",
    "OmF_norm_stdv = np.sqrt(OmF_stdv**2 / (data_mean['obs_obsvar'] + data_mean['obs_fcstvar']) )\n",
    "    \n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[N_data < Nmin] = np.nan\n",
    "OmF_stdv[N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[N_data < Nmin] = np.nan\n",
    "OmA_stdv[N_data < Nmin] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_metrics = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics[group]['Nobs_data'] = group_N_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "# Debugging: Check out_path\n",
    "print(\"out_path:\", out_path)\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(out_path, exist_ok=True)\n",
    "\n",
    "# Debugging: Check group_metrics before saving\n",
    "print(\"group_metrics:\", group_metrics)\n",
    "\n",
    "# Save the group_metrics dictionary to a file\n",
    "with open(out_path + f'group_metrics_{expid}_{start_time.strftime(\"%Y%m%d\")}_{end_time.strftime(\"%Y%m%d\")}.pkl', 'wb') as f:\n",
    "    pickle.dump(group_metrics, f)\n",
    "\n",
    "# Debugging: Check if the file was saved\n",
    "print(\"File exists:\", os.path.exists(out_path + 'group_metrics.pkl'))\n",
    "\n",
    "# Load the group_metrics dictionary from the file\n",
    "with open(out_path + f'group_metrics_{expid}_{start_time.strftime(\"%Y%m%d\")}_{end_time.strftime(\"%Y%m%d\")}.pkl', 'rb') as f:\n",
    "    loaded_group_metrics = pickle.load(f)\n",
    "\n",
    "# Debugging: Check the loaded dictionary\n",
    "print(\"loaded_group_metrics:\", loaded_group_metrics)\n",
    "print(\"loaded_group_metrics keys:\", loaded_group_metrics.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Plotting\n",
    "expdir = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/land_sweeper/'\n",
    "expid = 'LS_DAv8_M36'\n",
    "domain = 'SMAP_EASEv2_M36_GLOBAL'\n",
    "outpath = \"./\"\n",
    "\n",
    "start_time = datetime(2000,6,1)\n",
    "end_time = datetime(2024,4,1)\n",
    "\n",
    "# Load the group_metrics dictionary from the file\n",
    "with open('group_metrics.pkl', 'rb') as f:\n",
    "   loaded_group_metrics = pickle.load(f)\n",
    "\n",
    "# Load the group_metrics dictionary from the file\n",
    "#with open(out_path + 'group_metrics.pkl', 'rb') as f:\n",
    "#    loaded_group_metrics = pickle.load(f)    \n",
    "\n",
    "print(\"loaded_group_metrics keys:\", loaded_group_metrics.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot N_data_group for each species group\n",
    "plt.figure(figsize=(10, 6))\n",
    "for group, values in N_data_group_all_months.items():\n",
    "    values_in_millions = [v / 1e6 for v in values]  # Convert to millions\n",
    "    plt.plot(monthly_timestamps, values_in_millions, label=group)\n",
    "    print(f\"{group} N_data (in millions): {values_in_millions}\")\n",
    "plt.gcf().autofmt_xdate()\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('N_data (Millions)')\n",
    "plt.title('Total N_data by Species Group (in Millions)')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Plot OmF_mean for each species group\n",
    "for group, values in OmF_mean_all_months.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, values, label=f'{group} OmF Mean', color='blue')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Mean')\n",
    "    plt.title(f'OmF Mean for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.savefig(out_path + f'OmF_Mean_{group}.png')  # Save the plot for each group\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# Plot OmF_stdv for each species group\n",
    "for group, values in OmF_stdv_all_months.items():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(monthly_timestamps, values, label=f'{group} OmF Stdv', color='orange')\n",
    "    plt.gcf().autofmt_xdate()\n",
    "    plt.xlabel('Month')\n",
    "    plt.ylabel('OmF Standard Deviation')\n",
    "    plt.title(f'OmF Standard Deviation for {group}')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "    plt.savefig(out_path + f'OmF_Stdv_{group}.png')  # Save the plot for each group\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_group_metrics = group_metrics\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['SMOS']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['SMOS']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['SMOS']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['SMOS']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['SMOS']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[k]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 5000] # np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' SMOS Tb Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-10, 10]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' SMOS Tb O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMOS Tb O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMOS Tb normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))\n",
    "    \n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])            \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['SMAP']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['SMAP']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['SMAP']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['SMAP']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['SMAP']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[k]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 7000] #np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' SMAP Tb Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-10, 10]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' SMAP Tb O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMAP Tb O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SMAP Tb normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))            \n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])            \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['ASCAT']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['ASCAT']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['ASCAT']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['ASCAT']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['ASCAT']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[m3/m3]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 12000] #np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' ASCAT SM Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-0.05, 0.05]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' ASCAT SM O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 0.1]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' ASCAT SM O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' ASCAt SM normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))                \n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])            \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "fig, axes = plt.subplots(2,2, figsize=(18,10))\n",
    "plt.rcParams.update({'font.size':14})\n",
    "\n",
    "Nobs_data = loaded_group_metrics['MODIS']['Nobs_data']\n",
    "OmF_mean = loaded_group_metrics['MODIS']['OmF_mean']\n",
    "OmF_stdv = loaded_group_metrics['MODIS']['OmF_stdv']\n",
    "OmF_norm_mean = loaded_group_metrics['MODIS']['OmF_norm_mean']\n",
    "OmF_norm_stdv = loaded_group_metrics['MODIS']['OmF_norm_stdv']\n",
    "\n",
    "for i in np.arange(2):\n",
    "    for j in np.arange(2):\n",
    "        units = '[frac.]'\n",
    "        if i == 0 and j == 0:\n",
    "            tile_data = Nobs_data\n",
    "            # crange is [cmin, cmax]\n",
    "            crange =[0, 20000] #np.ceil((end_time-start_time).days/150)*300]\n",
    "            colormap = plt.get_cmap('jet',20)\n",
    "            title_txt = expid + ' SCF Nobs '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "            units = '[-]'\n",
    "        if i == 0 and j ==1:\n",
    "            tile_data = OmF_mean\n",
    "            crange =[-1, 1]\n",
    "            colormap = plt.get_cmap('bwr', 15) \n",
    "            title_txt = expid + ' SCF O-F mean '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 0:\n",
    "            tile_data = OmF_stdv\n",
    "            crange =[0, 0.5]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SCF O-F stdv '+ start_time.strftime('%Y%m')+'_'+end_time.strftime('%Y%m')\n",
    "        if i == 1 and j == 1:\n",
    "            tile_data = OmF_norm_stdv\n",
    "            crange =[0, 15]\n",
    "            colormap = plt.get_cmap ('jet',15)\n",
    "            title_txt = expid + ' SCF normalized O-F stdv '+ start_time.strftime('%Y%m%d')+'_'+end_time.strftime('%Y%m%d')\n",
    "\n",
    "        colormap.set_bad(color='0.9') # light grey, 0-black, 1-white\n",
    "\n",
    "        # Regrid 1d tile_data to 2d grid_data for map plots\n",
    "        if '_M09_' in domain: # special case  \n",
    "            grid_data_M09 = np.zeros((1624, 3856)) + np.nan  \n",
    "            grid_data_M09[tc['j_indg'],tc['i_indg']] = tile_data\n",
    "            \n",
    "            # Reshape the data into 4x4 blocks\n",
    "            reshaped = grid_data_M09.reshape(1624//4, 4, 3856//4, 4)\n",
    "\n",
    "            # Combine each 4x4 M09 block into a M36 grid\n",
    "            if i==0 and j==0:\n",
    "                grid_data = np.sum(reshaped,axis=(1, 3)) \n",
    "            else:\n",
    "                grid_data = np.nanmean(reshaped,axis=(1, 3))\n",
    "                \n",
    "            lat_M36, lon_M36 = smapeasev2_ind2latlon(np.arange(406), np.arange(964),'M36')\n",
    "            lon_2d,lat_2d = np.meshgrid(lon_M36,lat_M36)\n",
    "        else:\n",
    "            grid_data, uy,ux = array2grid(tile_data, lat = tc['com_lat'], lon = tc['com_lon'])\n",
    "            lon_2d,lat_2d = np.meshgrid(ux, uy)\n",
    "            \n",
    "        if 'normalized' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs(nstdv-1))=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data-1.)))+' '+units\n",
    "        elif 'mean' in title_txt:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.3f, avg(abs)=%.3f\" % (np.nanmean(grid_data), np.nanmean(np.abs(grid_data)))+' '+units\n",
    "        else:\n",
    "            title_txt = title_txt + '\\n' + \"avg=%.2f\" % (np.nanmean(grid_data)) +' '+units                \n",
    "\n",
    "        if 'normalized' in title_txt:\n",
    "            grid_data = np.log10(grid_data)\n",
    "            crange = [-0.6, 0.45]\n",
    "            \n",
    "        mm, cs = plotMap(grid_data, ax =axes[i,j], lat=lat_2d, lon=lon_2d, cRange=crange, \\\n",
    "                    title=title_txt, cmap=colormap, bounding=[-60, 80, -180,180])    \n",
    "\n",
    "        # Print the mean, min and max values of the grid data\n",
    "        print('Mean of grid_data:', np.nanmean(grid_data))\n",
    "        print('Min of grid_data:', np.nanmin(grid_data))\n",
    "        print('Max of grid_data:', np.nanmax(grid_data))                  \n",
    "\n",
    "plt.tight_layout()\n",
    "# Save figure to file\n",
    "fig.savefig(out_path+'Map_OmF_'+expid+'_'+start_time.strftime('%Y%m')+'_'+\\\n",
    "                    end_time.strftime('%Y%m')+'.png')\n",
    "plt.show()\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
