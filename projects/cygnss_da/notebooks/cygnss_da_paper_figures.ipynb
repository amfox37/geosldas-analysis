{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba4f8aca",
   "metadata": {},
   "source": [
    "# Paper figures\n",
    "Multi-panel labeled figures combined from CYGNSS notebooks; single-panel/plot_region outputs removed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0762ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import sys\n",
    "\n",
    "# Ensure repo utils are on path and import region bounds/helpers\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / '.git').exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "here = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()\n",
    "repo_root = find_repo_root(here)\n",
    "sys.path.append(str(repo_root / 'common' / 'python' / 'plotting'))\n",
    "from geospatial_plotting import REGION_BOUNDS, load_ease_grid, build_ease_grid_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3451dab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SAVE_DIR' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 251\u001b[0m\n\u001b[1;32m    245\u001b[0m             Ns_raw[key][ni, :, ei] \u001b[38;5;241m=\u001b[39m n\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# FIGURE 1: RAW MEANS (overlay)\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[1;32m    250\u001b[0m plot_overlay(means_raw, cis_raw, Ns_raw, panel_info_means,\n\u001b[0;32m--> 251\u001b[0m              Path(\u001b[43mSAVE_DIR\u001b[49m)\u001b[38;5;241m/\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfigure_1\u001b[39m\u001b[38;5;124m\"\u001b[39m, title_suffix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;66;03m# FIGURE 2: Δ FROM CONTROL (overlay, paired per-site t CIs)\u001b[39;00m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;66;03m# ===============================\u001b[39;00m\n\u001b[1;32m    256\u001b[0m \u001b[38;5;66;03m# Build Δ vs CNTL for each network/experiment using site-paired differences.\u001b[39;00m\n\u001b[1;32m    257\u001b[0m delta_means \u001b[38;5;241m=\u001b[39m {m: np\u001b[38;5;241m.\u001b[39mfull_like(means_raw[m], np\u001b[38;5;241m.\u001b[39mnan) \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m metrics}  \u001b[38;5;66;03m# NaN instead of zeros\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SAVE_DIR' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from scipy.stats import t\n",
    "from pathlib import Path\n",
    "\n",
    "# ===============================\n",
    "# CONFIG\n",
    "# ===============================\n",
    "\n",
    "DATA_DIR = Path(\"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data\")\n",
    "\n",
    "BASE_DIR = Path(DATA_DIR, \"CYGNSS_Experiments/Evaluation/InSitu/output\")\n",
    "\n",
    "# Experiments (order -> x-axis)\n",
    "# experiment_names = [\"OLv8_M36_cd\", \"DAv8_M36_cd\", \"DAv8_M36_cd_ssa\", \"DAv8_M36_cd_all\"]\n",
    "# expt_labels = [\"CNTL\", \"CYG_DA\", \"SSA_DA\", \"ALL_DA\"]\n",
    "\n",
    "experiment_names = [\"OLv8_M36_cd\", \"DAv8_M36_cd\", \"DAv8_M36_cd_ssa_fixed\", \"DAv8_M36_cd_all_fixed\"]\n",
    "expt_labels = [\"CNTL\", \"CYG_DA\", \"SSA_DA\", \"ALL_DA\"] \n",
    "\n",
    "# Networks to combine: (insitu_tag_in_filename, label)\n",
    "networks = [\n",
    "    (\"_SCAN_SM_1d_c1234smv_6yr\", \"SCAN\"),\n",
    "    (\"_USCRN_SM_1d_c1234smv_6yr\", \"USCRN\"),\n",
    "    (\"_CalVal_M33_SM_1d__6yr\", \"SMAP Core\"),\n",
    "]\n",
    "\n",
    "# Plot look\n",
    "dot_size = 100\n",
    "capsize = 2\n",
    "\n",
    "# Okabe–Ito palette (3 distinct)\n",
    "palette = {\"SCAN\": \"#0072B2\", \"USCRN\": \"#E69F00\", \"SMAP Core\": \"#009E73\"}\n",
    "markers = {\"SCAN\": \"o\", \"USCRN\": \"s\", \"SMAP Core\": \"^\"}\n",
    "\n",
    "# Panels and y-lims for raw means\n",
    "panel_info_means = [\n",
    "    (\"R\",      r\"$R$ (-)\",                (0.50, 0.90)),\n",
    "    (\"anomR\",  r\"anomR (-)\",              (0.50, 0.90)),\n",
    "    (\"ubRMSE\", r\"ubRMSD ($m^3\\,m^{-3}$)\", (0.015, 0.060)),\n",
    "]\n",
    "\n",
    "# Panels and y-lims for deltas (tweak if needed)\n",
    "panel_info_delta = [\n",
    "    (\"R\",      r\"Δ$R$ (EXP − CNTL)\",                      (-0.02, 0.16)),\n",
    "    (\"anomR\",  r\"ΔanomR (EXP − CNTL)\",                    (-0.02, 0.16)),\n",
    "    (\"ubRMSE\", r\"ΔubRMSD (CNTL − EXP) $m^3\\,m^{-3}$\",     (-0.004, 0.010)),\n",
    "]\n",
    "\n",
    "# ===============================\n",
    "# HELPERS\n",
    "# ===============================\n",
    "def reduce_metric_means_ci(arr, lo, up):\n",
    "    \"\"\"\n",
    "    Compute mean across sites and CI magnitudes as in your original script:\n",
    "    CI_magnitudes ≈ mean(LO or UP)/sqrt(N_nonNaN).\n",
    "    Returns:\n",
    "      mean: (depth,)\n",
    "      ci_mag: (2, depth)  (lower, upper) magnitudes (non-negative)\n",
    "      n: (depth,) integer counts of non-NaN sites\n",
    "    \"\"\"\n",
    "    mean = np.nanmean(arr, axis=0)                  # (depth,)\n",
    "    n = np.sum(~np.isnan(arr), axis=0)              # (depth,)\n",
    "    denom = np.sqrt(np.maximum(n, 1))\n",
    "    ci_lo = np.nanmean(lo, axis=0) / denom\n",
    "    ci_up = np.nanmean(up, axis=0) / denom\n",
    "    ci_mag = np.vstack([np.abs(ci_lo), np.abs(ci_up)])\n",
    "    return mean, ci_mag, n\n",
    "\n",
    "def paired_delta_stats(arr_cntl, arr_exp, up_is_better=True, alpha=0.05):\n",
    "    \"\"\"\n",
    "    Paired per-site differences and t-intervals (statistically correct).\n",
    "    arr_cntl, arr_exp: (sites, depth)\n",
    "    up_is_better=True -> Δ = EXP - CNTL; False -> Δ = CNTL - EXP (e.g., ubRMSE)\n",
    "    Returns:\n",
    "      mean_delta: (depth,)\n",
    "      ci_half:   (depth,) symmetric t CI half-width (magnitude)\n",
    "      n_eff:     (depth,) paired counts\n",
    "    \"\"\"\n",
    "    sign = +1 if up_is_better else -1\n",
    "    D = sign * (arr_exp - arr_cntl)                 # (sites, depth)\n",
    "    # mask to paired non-NaN per depth\n",
    "    mask = (~np.isnan(arr_cntl)) & (~np.isnan(arr_exp))\n",
    "    depth = arr_cntl.shape[1]\n",
    "    mean_delta = np.full(depth, np.nan)\n",
    "    ci_half = np.full(depth, 0.0)\n",
    "    n_eff = np.zeros(depth, dtype=int)\n",
    "\n",
    "    for d in range(depth):\n",
    "        m = mask[:, d]\n",
    "        if not np.any(m):\n",
    "            continue\n",
    "        di = D[m, d]\n",
    "        n = di.size\n",
    "        n_eff[d] = n\n",
    "        dbar = np.nanmean(di)\n",
    "        sd = np.nanstd(di, ddof=1) if n > 1 else 0.0\n",
    "        se = sd / np.sqrt(max(n, 1))\n",
    "        k = t.ppf(1 - alpha/2, df=max(n-1, 1))\n",
    "        mean_delta[d] = dbar\n",
    "        ci_half[d] = k * se\n",
    "    return mean_delta, ci_half, n_eff\n",
    "\n",
    "def plot_overlay(\n",
    "    means_dict, cis_dict, Ns_dict, panel_info, outfile,\n",
    "    title_suffix=\"\", expt_idx=None, x_tick_labels=None\n",
    "):\n",
    "    \"\"\"\n",
    "    means_dict[m]: [net, depth, expt]\n",
    "    cis_dict[m]:   [net, 2(lo,up), depth, expt]  (magnitudes)\n",
    "    Ns_dict[m]:    [net, depth, expt]\n",
    "    expt_idx:      list/array of experiment indices to plot (default: all)\n",
    "    x_tick_labels: labels matching expt_idx (default: expt_labels[expt_idx])\n",
    "    \"\"\"\n",
    "    num_networks = len(networks)\n",
    "    all_idx = np.arange(len(expt_labels))\n",
    "    if expt_idx is None:\n",
    "        expt_idx = all_idx\n",
    "    expt_idx = np.asarray(expt_idx)\n",
    "    if x_tick_labels is None:\n",
    "        x_tick_labels = [expt_labels[i] for i in expt_idx]\n",
    "\n",
    "    fig = plt.figure(figsize=(12.5, 7.8), constrained_layout=True)\n",
    "    mosaic = [\n",
    "        [\"legend\", \"legend\", \"legend\"],\n",
    "        [\"s0\", \"s1\", \"s2\"],\n",
    "        [\"r0\", \"r1\", \"r2\"],\n",
    "    ]\n",
    "    axs = fig.subplot_mosaic(\n",
    "            mosaic,\n",
    "            gridspec_kw={\"height_ratios\": [0.14, 1.0, 1.0]}\n",
    "            )\n",
    "    \n",
    "    # Add panel labels\n",
    "    labels = [\"(a)\", \"(b)\", \"(c)\", \"(d)\", \"(e)\", \"(f)\"]\n",
    "    label_keys = [\"s0\", \"s1\", \"s2\", \"r0\", \"r1\", \"r2\"]\n",
    "    for lab, key in zip(labels, label_keys):\n",
    "        axs[key].text(0.02, 0.97, lab, transform=axs[key].transAxes, va=\"top\", ha=\"left\")\n",
    "    ax_leg = axs[\"legend\"]; ax_leg.axis(\"off\")\n",
    "\n",
    "    x = np.arange(len(expt_idx))\n",
    "    offsets = np.linspace(-0.18, 0.18, num_networks)\n",
    "\n",
    "    for col, (metric_key, ylab, ylim) in enumerate(panel_info):\n",
    "        for depth in [0, 1]:\n",
    "            ax = axs[(\"s\" if depth == 0 else \"r\") + str(col)]\n",
    "            ax.grid(axis=\"y\", color=\"lightgrey\", zorder=0)\n",
    "            ax.axhline(y=0, color='black', linestyle='--', linewidth=0.8, alpha=0.7, zorder=1)\n",
    "            ax.set_axisbelow(True)\n",
    "\n",
    "            for ni, (_, nlabel) in enumerate(networks):\n",
    "                y  = means_dict[metric_key][ni, depth, expt_idx]\n",
    "                xpos = x + offsets[ni]\n",
    "\n",
    "                ci = np.asarray(cis_dict[metric_key][ni, :, depth, expt_idx], dtype=float)\n",
    "                if ci.ndim == 0:                    # scalar -> (2,1)\n",
    "                    val = float(ci)\n",
    "                    ci = np.array([[val], [val]])\n",
    "                elif ci.ndim == 1:                  # (N,) -> (2,N) symmetric\n",
    "                    ci = np.vstack([ci, ci])\n",
    "                elif ci.ndim == 2 and ci.shape[0] != 2:  # (N,2) -> (2,N)\n",
    "                    ci = ci.T\n",
    "\n",
    "                ax.scatter(xpos, y, s=dot_size, marker=markers[nlabel],\n",
    "                           color=palette[nlabel], edgecolor=\"none\", zorder=3,\n",
    "                           label=nlabel if (depth==0 and col==0) else None)\n",
    "                ax.errorbar(xpos, y, yerr=ci, fmt=\"none\", ecolor=\"gray\",\n",
    "                            elinewidth=0.5, capsize=capsize, zorder=2)\n",
    "\n",
    "            ax.set_ylim(*ylim)\n",
    "            if depth == 1:\n",
    "                ax.set_xticks(x, x_tick_labels)\n",
    "            else:\n",
    "                ax.set_xticks(x, [\"\"] * len(x_tick_labels))\n",
    "\n",
    "            layer = \"Surface\" if depth == 0 else \"Rootzone\"\n",
    "            ax.set_ylabel(f\"{layer} {ylab}\")\n",
    "\n",
    "            # Title: ONLY n per network (from CNTL)\n",
    "            ntext = \" | \".join(\n",
    "                f\"{networks[ni][1]} n={int(Ns_dict[metric_key][ni, depth, 0])}\"\n",
    "                for ni in range(num_networks)\n",
    "            )\n",
    "            ax.set_title(ntext)\n",
    "\n",
    "    # Legend centered in slim band\n",
    "    handles, labels = axs[\"s0\"].get_legend_handles_labels()\n",
    "    if handles:\n",
    "        ax_leg.legend(handles, labels, loc=\"center\", ncols=len(labels), frameon=False,\n",
    "                      handletextpad=0.6, borderaxespad=0.0)\n",
    "\n",
    "    save_fig(fig, name=Path(outfile).stem if outfile else None)\n",
    "    #plt.close(fig)\n",
    "\n",
    "\n",
    "\n",
    "# ===============================\n",
    "# LOAD ALL FILES ONCE; BUILD STATS\n",
    "# ===============================\n",
    "metrics = [\"R\", \"anomR\", \"ubRMSE\"]\n",
    "num_expts = len(experiment_names)\n",
    "num_networks = len(networks)\n",
    "\n",
    "# Store per-network, per-experiment, per-metric arrays for paired Δ (site x depth)\n",
    "store_R     = [[None]*num_expts for _ in range(num_networks)]\n",
    "store_anomR = [[None]*num_expts for _ in range(num_networks)]\n",
    "store_ub    = [[None]*num_expts for _ in range(num_networks)]\n",
    "\n",
    "# Containers for RAW means/CI/N\n",
    "means_raw = {m: np.full((num_networks, 2, num_expts), np.nan) for m in metrics}\n",
    "cis_raw   = {m: np.full((num_networks, 2, 2, num_expts), np.nan) for m in metrics}  # (net, lo/up, depth, expt)\n",
    "Ns_raw    = {m: np.zeros((num_networks, 2, num_expts), dtype=int) for m in metrics}\n",
    "\n",
    "for ni, (tag, nlabel) in enumerate(networks):\n",
    "    for ei, exname in enumerate(experiment_names):\n",
    "        fpath = BASE_DIR / f\"{exname}{tag}_stats_60.mat\"\n",
    "        mat = sio.loadmat(fpath, squeeze_me=False)\n",
    "\n",
    "        # Arrays (sites x depth)\n",
    "        R       = np.asarray(mat[\"R\"])\n",
    "        RLO     = np.asarray(mat[\"RLO\"])\n",
    "        RUP     = np.asarray(mat[\"RUP\"])\n",
    "        anomR   = np.asarray(mat[\"anomR\"])\n",
    "        anomRLO = np.asarray(mat[\"anomRLO\"])\n",
    "        anomRUP = np.asarray(mat[\"anomRUP\"])\n",
    "        ub      = np.asarray(mat[\"ubRMSE\"])\n",
    "        ubLO    = np.asarray(mat[\"ubRMSELO\"])\n",
    "        ubUP    = np.asarray(mat[\"ubRMSEUP\"])\n",
    "\n",
    "        # Save for paired Δ later\n",
    "        store_R[ni][ei]     = R\n",
    "        store_anomR[ni][ei] = anomR\n",
    "        store_ub[ni][ei]    = ub\n",
    "\n",
    "        # Raw means & CI magnitudes (following your earlier approach)\n",
    "        for key, arrs in {\n",
    "            \"R\":      (R, RLO, RUP),\n",
    "            \"anomR\":  (anomR, anomRLO, anomRUP),\n",
    "            \"ubRMSE\": (ub, ubLO, ubUP),\n",
    "        }.items():\n",
    "            m, ci2, n = reduce_metric_means_ci(*arrs)\n",
    "            means_raw[key][ni, :, ei] = m\n",
    "            cis_raw[key][ni, :, :, ei] = ci2\n",
    "            Ns_raw[key][ni, :, ei] = n\n",
    "\n",
    "# ===============================\n",
    "# FIGURE 1: RAW MEANS (overlay)\n",
    "# ===============================\n",
    "plot_overlay(means_raw, cis_raw, Ns_raw, panel_info_means,\n",
    "             Path(SAVE_DIR)/\"figure_1\", title_suffix=\"\")\n",
    "\n",
    "# ===============================\n",
    "# FIGURE 2: Δ FROM CONTROL (overlay, paired per-site t CIs)\n",
    "# ===============================\n",
    "# Build Δ vs CNTL for each network/experiment using site-paired differences.\n",
    "delta_means = {m: np.full_like(means_raw[m], np.nan) for m in metrics}  # NaN instead of zeros\n",
    "delta_cis   = {m: np.full_like(cis_raw[m], np.nan)   for m in metrics}  # NaN instead of zeros\n",
    "Ns_delta    = {m: np.zeros_like(Ns_raw[m])    for m in metrics}         # Keep zeros for counts\n",
    "\n",
    "for ni in range(num_networks):\n",
    "    # reference CNTL (ei=0)\n",
    "    R_cntl     = store_R[ni][0]\n",
    "    anomR_cntl = store_anomR[ni][0]\n",
    "    ub_cntl    = store_ub[ni][0]\n",
    "\n",
    "    # Set Δ at CNTL = 0 with 0 CI\n",
    "    for key in metrics:\n",
    "        delta_means[key][ni, :, 0] = 0.0\n",
    "        delta_cis[key][ni, :, :, 0] = 0.0\n",
    "        Ns_delta[key][ni, :, 0] = np.sum(~np.isnan(store_R[ni][0]), axis=0)  # any metric; counts of CNTL available\n",
    "\n",
    "    # Other experiments (ei >= 1)\n",
    "    for ei in range(1, num_expts):\n",
    "        # R and anomR: Δ = EXP - CNTL (up is better)\n",
    "        md, hw, n = paired_delta_stats(R_cntl, store_R[ni][ei], up_is_better=True)\n",
    "        delta_means[\"R\"][ni, :, ei] = md\n",
    "        delta_cis[\"R\"][ni, 0, :, ei] = hw  # lower mag\n",
    "        delta_cis[\"R\"][ni, 1, :, ei] = hw  # upper mag\n",
    "        Ns_delta[\"R\"][ni, :, ei] = n\n",
    "\n",
    "        md, hw, n = paired_delta_stats(anomR_cntl, store_anomR[ni][ei], up_is_better=True)\n",
    "        delta_means[\"anomR\"][ni, :, ei] = md\n",
    "        delta_cis[\"anomR\"][ni, 0, :, ei] = hw\n",
    "        delta_cis[\"anomR\"][ni, 1, :, ei] = hw\n",
    "        Ns_delta[\"anomR\"][ni, :, ei] = n\n",
    "\n",
    "        # ubRMSE: improvement = CNTL - EXP (up is better)\n",
    "        md, hw, n = paired_delta_stats(ub_cntl, store_ub[ni][ei], up_is_better=False)\n",
    "        delta_means[\"ubRMSE\"][ni, :, ei] = md\n",
    "        delta_cis[\"ubRMSE\"][ni, 0, :, ei] = hw\n",
    "        delta_cis[\"ubRMSE\"][ni, 1, :, ei] = hw\n",
    "        Ns_delta[\"ubRMSE\"][ni, :, ei] = n\n",
    "\n",
    "# Set delta_means to 1.0 and delta_cis to NaN for experiments 2 and 3 (second to last and last)\n",
    "for m in metrics:\n",
    "    delta_means[m][:, :, 3:4] = 1.0  # Set experiments 2 and 3 to 1.0\n",
    "    delta_cis[m][:, :, :, 3:4] = np.nan  # Set CI to NaN for experiments 2 and 3\n",
    "\n",
    "# Plot Δ overlay\n",
    "plot_overlay(\n",
    "    delta_means, delta_cis, Ns_delta, panel_info_delta,\n",
    "    Path(SAVE_DIR)/\"figure_2\",\n",
    "    title_suffix=\"Δ from CNTL\",\n",
    "    expt_idx=[1,2,3],                         # <- drop CNTL\n",
    "    x_tick_labels=[expt_labels[i] for i in [1,2,3]]\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14aadf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "mpl.rcParams.update({\n",
    "    \"figure.dpi\": 150,\n",
    "    \"savefig.dpi\": 300,\n",
    "    \"figure.figsize\": (6.5, 4.0),\n",
    "    \"font.size\": 10,\n",
    "    \"axes.titlesize\": 12,\n",
    "    \"axes.labelsize\": 11,\n",
    "    \"xtick.labelsize\": 9,\n",
    "    \"ytick.labelsize\": 9,\n",
    "    \"legend.fontsize\": 9,\n",
    "    \"legend.frameon\": False,\n",
    "    \"axes.linewidth\": 0.8,\n",
    "    \"lines.linewidth\": 1.2,\n",
    "    \"lines.markersize\": 5,\n",
    "    \"xtick.major.size\": 4,\n",
    "    \"ytick.major.size\": 4,\n",
    "    \"xtick.minor.size\": 2,\n",
    "    \"ytick.minor.size\": 2,\n",
    "    \"axes.grid\": False,\n",
    "})\n",
    "\n",
    "# === Figure saving helpers ===\n",
    "from itertools import count\n",
    "SAVE_DIR = Pathhh(\"paper_figures\")\n",
    "SAVE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "_fig_counter = count(1)\n",
    "\n",
    "# Save a figure to paper_figures as PNG/PDF; if name is None, use sequential figure_N\n",
    "\n",
    "def save_fig(fig, name=None):\n",
    "    idx = next(_fig_counter)\n",
    "    base = name if name is not None else f\"figure_{idx}\"\n",
    "    fig.savefig(SAVE_DIR / f\"{base}.png\", dpi=300, bbox_inches=\"tight\", pad_inches=0.04)\n",
    "    fig.savefig(SAVE_DIR / f\"{base}.pdf\", bbox_inches=\"tight\", pad_inches=0.04)\n",
    "    return base\n",
    "\n",
    "\n",
    "def _save_and_show(*args, **kwargs):\n",
    "    for num in list(plt.get_fignums()):\n",
    "        fig = plt.figure(num)\n",
    "        save_fig(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b754bae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "insitu_tag = \"_USCRN_SM_1d_c1234smv_6yr\"  # Example tag; change as needed\n",
    "\n",
    "m_rs_file = BASE_DIR / ('OLv8_M36_cd' + insitu_tag + '_raw_timeseries.mat')\n",
    "mat_contents = sio.loadmat(m_rs_file)\n",
    "\n",
    "# List of variables and their dimensions in the MATLAB file\n",
    "print(sio.whosmat(m_rs_file))\n",
    "\n",
    "vars = [k for k in mat_contents.keys() if not k.startswith('__')]\n",
    "print('Variables in MAT file:')\n",
    "for name in vars:\n",
    "    val = mat_contents[name]\n",
    "    shp = getattr(val, 'shape', None)\n",
    "    print(f\"{name}: type={type(val).__name__}, shape={shp}\")\n",
    "\n",
    "# ...existing code...\n",
    "\n",
    "# Align metric arrays with the selected in-situ network\n",
    "network_idx = next((i for i, (tag, _) in enumerate(networks) if tag == insitu_tag), None)\n",
    "if network_idx is None:\n",
    "    available = [tag for tag, _ in networks]\n",
    "    raise ValueError(f'{insitu_tag} is not in the networks list: {available}')\n",
    "\n",
    "# Stack per-experiment arrays so we can index as [:, depth, experiment]\n",
    "R = np.stack(store_R[network_idx], axis=-1)\n",
    "anomR = np.stack(store_anomR[network_idx], axis=-1)\n",
    "ubRMSE = np.stack(store_ub[network_idx], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2ad5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract INSITU_lat from the MATLAB file\n",
    "INSITU_lat = mat_contents['INSITU_lat']\n",
    "\n",
    "# Determine the number of sites below 40 degrees N\n",
    "num_sites_below_40N = np.sum(INSITU_lat < 60)\n",
    "print(f\"Number of sites below 40 degrees N: {num_sites_below_40N}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c691c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Extract latitude and longitude of the stations\n",
    "INSITU_lat = mat_contents['INSITU_lat'].flatten()\n",
    "INSITU_lon = mat_contents['INSITU_lon'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f036009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined 3x3 maps: ΔR, ΔanomR, ΔubRMSE (surface) — formatted like example\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# Diff arrays (surface depth = 0)\n",
    "rows = [\n",
    "    ('CYG_DA - CNTL', 1),\n",
    "    ('SSA_DA - CNTL', 2),\n",
    "    ('ALL_DA - CNTL', 3),\n",
    "]\n",
    "\n",
    "# Levels and colormaps per column\n",
    "levels_R = np.linspace(-0.06, 0.06, 9)\n",
    "levels_anomR = np.linspace(-0.10, 0.10, 9)\n",
    "levels_ub = np.linspace(-0.01, 0.01, 9)\n",
    "cmaps = [get_cmap('RdBu_r', len(levels_R)-1),\n",
    "         get_cmap('RdBu_r', len(levels_anomR)-1),\n",
    "         get_cmap('RdBu_r',   len(levels_ub)-1)]\n",
    "levels_list = [levels_R, levels_anomR, levels_ub]\n",
    "titles_col = ['Difference in R (EXP-CNTL)', 'Difference in anomR (EXP-CNTL)', 'Difference in ubRMSE (m3/m3) (CNTL-EXP)']\n",
    "labels = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)', '(i)']\n",
    "\n",
    "# fig, axes = plt.subplots(3, 3, figsize=(14, 7), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "# axes = axes.reshape(3,3)\n",
    "\n",
    "# lab_idx = 0\n",
    "# for r_idx, (row_title, exp_idx) in enumerate(rows):\n",
    "#     for c_idx, (metric, levels, cmap) in enumerate(zip(['R','anomR','ubRMSE'], levels_list, cmaps)):\n",
    "#         ax = axes[r_idx, c_idx]\n",
    "#         if metric == 'R':\n",
    "#             data = R[:, 0, exp_idx] - R[:, 0, 0]\n",
    "#         elif metric == 'anomR':\n",
    "#             data = anomR[:, 0, exp_idx] - anomR[:, 0, 0]\n",
    "#         else:\n",
    "#             data = ubRMSE[:, 0, 0] - ubRMSE[:, 0, exp_idx]\n",
    "#         norm = BoundaryNorm(levels, cmap.N)\n",
    "#         sc = ax.scatter(INSITU_lon, INSITU_lat, c=data, cmap=cmap, norm=norm,\n",
    "#                         s=35, edgecolor='k', linewidths=0.3, transform=ccrs.PlateCarree())\n",
    "#         ax.add_feature(cfeature.COASTLINE, linewidth=0.6)\n",
    "#         ax.add_feature(cfeature.BORDERS, linewidth=0.4, linestyle=':')\n",
    "#         ax.add_feature(cfeature.STATES, linewidth=0.3)\n",
    "#         ax.set_extent([-125, -74, 24, 45], crs=ccrs.PlateCarree())\n",
    "#         ax.set_title(row_title if c_idx == 0 else '', loc='left')\n",
    "#         ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "# # Colorbars under each column, 95% width centered and closer to panels\n",
    "# cbar_h = 0.02\n",
    "# # anchor relative to bottom row of panels\n",
    "# bottom_row = axes[-1, :]\n",
    "# y_min = min(ax.get_position().y0 for ax in bottom_row)\n",
    "# gap = 0.02  # gap between panels and colorbars\n",
    "# cbar_y = y_min - gap - cbar_h\n",
    "\n",
    "# for levels, cmap, title, col_ax in zip(levels_list, cmaps, titles_col, axes.T):\n",
    "#     x0 = min(ax.get_position().x0 for ax in col_ax)\n",
    "#     x1 = max(ax.get_position().x1 for ax in col_ax)\n",
    "#     span = x1 - x0\n",
    "#     width = 0.95 * span\n",
    "#     xpos = x0 + 0.5 * (span - width)\n",
    "#     norm = BoundaryNorm(levels, cmap.N)\n",
    "#     sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "#     cax = fig.add_axes([xpos, cbar_y, width, cbar_h])\n",
    "#     cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "#     cbar.set_label(title)\n",
    "#     cbar.set_ticks(levels)\n",
    "#     if 'ubRMSE' in title:\n",
    "#         cbar.ax.set_xticklabels([f\"{lvl:.3f}\" for lvl in levels])\n",
    "#     else:\n",
    "#         cbar.ax.set_xticklabels([f\"{lvl:.2f}\" for lvl in levels])\n",
    "\n",
    "# plt.subplots_adjust(wspace=0.05, hspace=0.08, bottom=0.12)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb4e1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined 3x3 overlay for all networks (SCAN, USCRN, SMAP Core) with SMAP on top\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# Build overlay order using existing networks (use 6yr tags), SMAP drawn last\n",
    "order_labels = ['SCAN', 'USCRN', 'SMAP Core']\n",
    "markers = {'SCAN': ('o', 36), 'USCRN': ('s', 34), 'SMAP Core': ('^', 42)}\n",
    "overlay_networks = []\n",
    "for lbl in order_labels:\n",
    "    for tag, nlabel in networks:\n",
    "        if nlabel == lbl:\n",
    "            marker, size = markers.get(lbl, ('o', 36))\n",
    "            overlay_networks.append((tag, nlabel, marker, size))\n",
    "            break\n",
    "\n",
    "levels_R = np.linspace(-0.16, 0.16, 9)\n",
    "levels_anomR = np.linspace(-0.16, 0.16, 9)\n",
    "levels_ub = np.linspace(-0.012, 0.012, 9)\n",
    "cmaps = [get_cmap('RdBu_r', len(levels_R)-1),\n",
    "         get_cmap('RdBu_r', len(levels_anomR)-1),\n",
    "         get_cmap('RdBu_r',   len(levels_ub)-1)]\n",
    "levels_list = [levels_R, levels_anomR, levels_ub]\n",
    "titles_col = ['Difference in R (EXP-CNTL)', 'Difference in anomR (EXP-CNTL)', 'Difference in ubRMSE (m3/m3) (CNTL-EXP)']\n",
    "labels = ['(a)', '(b)', '(c)', '(d)', '(e)', '(f)', '(g)', '(h)', '(i)']\n",
    "rows = [\n",
    "    ('CYG_DA - CNTL', 1),\n",
    "    ('SSA_DA - CNTL', 2),\n",
    "    ('ALL_DA - CNTL', 3),\n",
    "]\n",
    "\n",
    "# Determine control prefix\n",
    "if 'experiment_names' in globals():\n",
    "    control_prefix = experiment_names[0]\n",
    "elif 'experiments' in globals():\n",
    "    control_prefix = experiments[0]['prefix']\n",
    "else:\n",
    "    raise NameError('experiment_names/experiments not defined; run setup cells first')\n",
    "\n",
    "# Precompute arrays and lat/lon per network\n",
    "overlay_data = {}\n",
    "for tag, nlabel, _, _ in overlay_networks:\n",
    "    try:\n",
    "        nidx = next(i for i, (t, _) in enumerate(networks) if t == tag)\n",
    "    except StopIteration:\n",
    "        raise ValueError(f'Network tag {tag} not found in networks={networks}')\n",
    "    overlay_data[tag] = {\n",
    "        'R': np.stack(store_R[nidx], axis=-1),\n",
    "        'anomR': np.stack(store_anomR[nidx], axis=-1),\n",
    "        'ubRMSE': np.stack(store_ub[nidx], axis=-1),\n",
    "    }\n",
    "    raw_path = BASE_DIR / f\"{control_prefix}{tag}_raw_timeseries.mat\"\n",
    "    mat_raw = sio.loadmat(raw_path, squeeze_me=False)\n",
    "    overlay_data[tag]['lat'] = mat_raw['INSITU_lat'].flatten()\n",
    "    overlay_data[tag]['lon'] = mat_raw['INSITU_lon'].flatten()\n",
    "\n",
    "fig, axes = plt.subplots(3, 3, figsize=(16, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "axes = axes.reshape(3, 3)\n",
    "lab_idx = 0\n",
    "legend_handles = None\n",
    "legend_labels = None\n",
    "for r_idx, (row_title, exp_idx) in enumerate(rows):\n",
    "    for c_idx, (metric, levels, cmap) in enumerate(zip(['R', 'anomR', 'ubRMSE'], levels_list, cmaps)):\n",
    "        ax = axes[r_idx, c_idx]\n",
    "        norm = BoundaryNorm(levels, cmap.N)\n",
    "        for tag, nlabel, marker, size in overlay_networks:\n",
    "            arr = overlay_data[tag][metric]\n",
    "            if metric == 'ubRMSE':\n",
    "                data = arr[:, 0, 0] - arr[:, 0, exp_idx]\n",
    "            else:\n",
    "                data = arr[:, 0, exp_idx] - arr[:, 0, 0]\n",
    "            lat = overlay_data[tag]['lat']; lon = overlay_data[tag]['lon']\n",
    "            sc = ax.scatter(lon, lat, c=data, cmap=cmap, norm=norm, s=size,\n",
    "                            marker=marker, edgecolor='k', linewidths=0.3,\n",
    "                            transform=ccrs.PlateCarree(), label=nlabel)\n",
    "        ax.add_feature(cfeature.COASTLINE, linewidth=0.6)\n",
    "        ax.add_feature(cfeature.BORDERS, linewidth=0.4, linestyle=':')\n",
    "        ax.add_feature(cfeature.STATES, linewidth=0.3)\n",
    "        ax.set_extent([-125, -74, 24, 45], crs=ccrs.PlateCarree())\n",
    "        ax.set_title(row_title if c_idx == 0 else '', loc='left')\n",
    "        ax.tick_params(labelbottom=False, labelleft=False)\n",
    "        ax.text(0.02, 0.02, labels[lab_idx], transform=ax.transAxes, va='bottom', ha='left')\n",
    "        if legend_handles is None:\n",
    "            legend_handles, legend_labels = ax.get_legend_handles_labels()\n",
    "        lab_idx += 1\n",
    "\n",
    "# Add a single legend\n",
    "if legend_handles:\n",
    "    axes[0,2].legend(legend_handles, legend_labels, loc='lower right', frameon=True)\n",
    "\n",
    "# Colorbars under each column\n",
    "cbar_h = 0.02\n",
    "bottom_row = axes[-1, :]\n",
    "y_min = min(ax.get_position().y0 for ax in bottom_row)\n",
    "gap = 0.02\n",
    "cbar_y = y_min - gap - cbar_h\n",
    "for levels, cmap, title, col_ax in zip(levels_list, cmaps, titles_col, axes.T):\n",
    "    x0 = min(ax.get_position().x0 for ax in col_ax)\n",
    "    x1 = max(ax.get_position().x1 for ax in col_ax)\n",
    "    span = x1 - x0\n",
    "    width = 0.99 * span\n",
    "    xpos = x0 + 0.5 * (span - width)\n",
    "    norm = BoundaryNorm(levels, cmap.N)\n",
    "    sm = plt.cm.ScalarMappable(norm=norm, cmap=cmap)\n",
    "    cax = fig.add_axes([xpos, cbar_y, width, cbar_h])\n",
    "    cbar = fig.colorbar(sm, cax=cax, orientation='horizontal')\n",
    "    cbar.set_label(title)\n",
    "    cbar.set_ticks(levels)\n",
    "    if title.startswith('Difference in ubRMSE'):\n",
    "        cbar.ax.set_xticklabels([f\"{lvl:.3f}\" for lvl in levels])\n",
    "    else:\n",
    "        cbar.ax.set_xticklabels([f\"{lvl:.2f}\" for lvl in levels])\n",
    "\n",
    "plt.subplots_adjust(wspace=0.05, hspace=0.08, bottom=0.14)\n",
    "# plt.suptitle('All networks overlay (SMAP Core on top)', y=0.99)\n",
    "save_fig(plt.gcf(), \"figure_3\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7232a73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / '.git').exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "here = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()\n",
    "repo_root = find_repo_root(here)\n",
    "sys.path.append(str(repo_root / 'common' / 'python' / 'io'))\n",
    "sys.path.append(str(repo_root / 'projects' / 'matlab2python' / 'shared' / 'python'))\n",
    "sys.path.append(str(repo_root / 'common' / 'python' / 'plotting'))\n",
    "sys.path.append('../util/shared/python/')\n",
    "\n",
    "EASE_PATH = repo_root / 'common' / 'python' / 'plotting' / 'ease_grids'\n",
    "\n",
    "from read_GEOSldas import read_tilecoord, read_obs_param\n",
    "\n",
    "\n",
    "# plotting removed (single-panel plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9064748",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = {\n",
    "    \"CYGNSS\": [11],\n",
    "    \"SMAP\": [4, 5, 6, 7],\n",
    "    \"ASCAT\": [8, 9, 10],\n",
    "    \"SMOS\": [0, 1, 2, 3]\n",
    "}\n",
    "\n",
    "# species_groups = {\n",
    "#     \"CYGNSS\": [11],\n",
    "#     \"SMAP\": [4, 5],\n",
    "#     \"ASCAT\": [8, 9, 10],\n",
    "#     \"SMOS\": [0, 1]\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033790ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the OL data files\n",
    "\n",
    "stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_cd/' \\\n",
    "'OLv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_OL_fixed_20180801_20240630.nc4'\n",
    "\n",
    "print('reading stats nc4 file '+stats_file_OL)\n",
    "stats_OL = {}\n",
    "with Dataset(stats_file_OL,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        print(f\"Reading variable: {key}\")\n",
    "        stats_OL[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_cd/' \\\n",
    "'OLv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_OL_fixed_201808_202406.pkl'\n",
    "\n",
    "with open(ts_stats_file_OL, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_OL = loaded_data\n",
    "date_vec_OL = loaded_data.get('date_vec', None)  \n",
    "date_vec = date_vec_OL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa8568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the DA data files\n",
    "stats_file_DA = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd/' \\\n",
    "'DAv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_fixed_20180801_20240630.nc4'\n",
    "print('reading stats nc4 file '+stats_file_DA)\n",
    "stats_DA = {}\n",
    "with Dataset(stats_file_DA,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_DA[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_DA = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd/' \\\n",
    "'DAv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_DA_fixed_201808_202406.pkl'\n",
    "\n",
    "with open(ts_stats_file_DA, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_DA = loaded_data\n",
    "date_vec_DA = loaded_data.get('date_vec', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f835530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the DA data files\n",
    "stats_file_DA_all = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd_all/' \\\n",
    "'DAv8_M36_cd_all/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_fixed_20180801_20240630.nc4'\n",
    "print('reading stats nc4 file '+stats_file_DA_all)\n",
    "stats_DA_all = {}\n",
    "with Dataset(stats_file_DA_all,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_DA_all[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_DA_all = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd_all/' \\\n",
    "'DAv8_M36_cd_all/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_DA_fixed_201808_202406.pkl'\n",
    "\n",
    "with open(ts_stats_file_DA_all, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_DA_all = loaded_data\n",
    "date_vec_DA_all = loaded_data.get('date_vec', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4eedb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the DA data files\n",
    "stats_file_DA_ssa = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd_ssa/' \\\n",
    "'DAv8_M36_cd_ssa/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_fixed_20180801_20240630.nc4'\n",
    "print('reading stats nc4 file '+stats_file_DA_ssa)\n",
    "stats_DA_ssa = {}\n",
    "with Dataset(stats_file_DA_ssa,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_DA_ssa[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_DA_ssa = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd_ssa/' \\\n",
    "'DAv8_M36_cd_ssa/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_DA_fixed_201808_202406.pkl'\n",
    "\n",
    "with open(ts_stats_file_DA_ssa, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_DA_ssa = loaded_data\n",
    "date_vec_DA_ssa = loaded_data.get('date_vec', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of final compuation of selected diagnostic metrics for OL\n",
    " \n",
    "Nmin = 20\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OL['N_data']\n",
    "O_mean = stats_OL['O_mean']\n",
    "A_mean = stats_OL['A_mean']\n",
    "F_mean = stats_OL['F_mean']\n",
    "O_stdv = stats_OL['O_stdv']\n",
    "A_stdv = stats_OL['A_stdv']\n",
    "F_stdv = stats_OL['F_stdv']\n",
    "OmF_mean = stats_OL['OmF_mean']\n",
    "OmF_stdv = stats_OL['OmF_stdv']\n",
    "OmF_norm_mean = stats_OL['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_OL['OmF_norm_stdv']\n",
    "OmA_mean = stats_OL['OmA_mean']\n",
    "OmA_stdv = stats_OL['OmA_stdv']\n",
    "  \n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "\n",
    "OmF_mean_OL = OmF_mean\n",
    "OmF_stdv_OL = OmF_stdv\n",
    "OmF_norm_mean_OL = OmF_norm_mean\n",
    "OmF_norm_stdv_OL = OmF_norm_stdv\n",
    "OmA_mean_OL = OmA_mean\n",
    "OmA_stdv_OL = OmA_stdv\n",
    "N_data_OL = N_data\n",
    "\n",
    "group_metrics_OL = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OL[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_OL[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['Nobs_data'] = group_N_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488dddba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample of final compuation of selected diagnostic metrics for DA\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_DA['N_data']\n",
    "O_mean = stats_DA['O_mean']\n",
    "A_mean = stats_DA['A_mean']\n",
    "F_mean = stats_DA['F_mean']\n",
    "O_stdv = stats_DA['O_stdv']\n",
    "A_stdv = stats_DA['A_stdv']\n",
    "F_stdv = stats_DA['F_stdv']\n",
    "OmF_mean = stats_DA['OmF_mean']\n",
    "OmF_stdv = stats_DA['OmF_stdv']\n",
    "OmF_norm_mean = stats_DA['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_DA['OmF_norm_stdv']\n",
    "OmA_mean = stats_DA['OmA_mean']\n",
    "OmA_stdv = stats_DA['OmA_stdv']\n",
    "\n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "OmF_mean_DA = OmF_mean\n",
    "OmF_stdv_DA = OmF_stdv\n",
    "OmF_norm_mean_DA = OmF_norm_mean\n",
    "OmF_norm_stdv_DA = OmF_norm_stdv\n",
    "OmA_mean_DA = OmA_mean\n",
    "OmA_stdv_DA = OmA_stdv\n",
    "N_data_DA = N_data\n",
    "\n",
    "group_metrics_DA = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_DA[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_DA[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['Nobs_data'] = group_N_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dcc3762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_DA_all['N_data']\n",
    "O_mean = stats_DA_all['O_mean']\n",
    "A_mean = stats_DA_all['A_mean']\n",
    "F_mean = stats_DA_all['F_mean']\n",
    "O_stdv = stats_DA_all['O_stdv']\n",
    "A_stdv = stats_DA_all['A_stdv']\n",
    "F_stdv = stats_DA_all['F_stdv']\n",
    "OmF_mean = stats_DA_all['OmF_mean']\n",
    "OmF_stdv = stats_DA_all['OmF_stdv']\n",
    "OmF_norm_mean = stats_DA_all['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_DA_all['OmF_norm_stdv']\n",
    "OmA_mean = stats_DA_all['OmA_mean']\n",
    "OmA_stdv = stats_DA_all['OmA_stdv']\n",
    "\n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "OmF_mean_DA_all = OmF_mean\n",
    "OmF_stdv_DA_all = OmF_stdv\n",
    "OmF_norm_mean_DA_all = OmF_norm_mean\n",
    "OmF_norm_stdv_DA_all = OmF_norm_stdv\n",
    "OmA_mean_DA_all = OmA_mean\n",
    "OmA_stdv_DA_all = OmA_stdv\n",
    "N_data_DA_all = N_data\n",
    "\n",
    "group_metrics_DA_all = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_DA_all[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_DA_all[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['Nobs_data'] = group_N_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9b70ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_DA_ssa['N_data']\n",
    "O_mean = stats_DA_ssa['O_mean']\n",
    "A_mean = stats_DA_ssa['A_mean']\n",
    "F_mean = stats_DA_ssa['F_mean']\n",
    "O_stdv = stats_DA_ssa['O_stdv']\n",
    "A_stdv = stats_DA_ssa['A_stdv']\n",
    "F_stdv = stats_DA_ssa['F_stdv']\n",
    "OmF_mean = stats_DA_ssa['OmF_mean']\n",
    "OmF_stdv = stats_DA_ssa['OmF_stdv']\n",
    "OmF_norm_mean = stats_DA_ssa['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_DA_ssa['OmF_norm_stdv']\n",
    "OmA_mean = stats_DA_ssa['OmA_mean']\n",
    "OmA_stdv = stats_DA_ssa['OmA_stdv']\n",
    "\n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "OmF_mean_DA_ssa = OmF_mean\n",
    "OmF_stdv_DA_ssa = OmF_stdv\n",
    "OmF_norm_mean_DA_ssa = OmF_norm_mean\n",
    "OmF_norm_stdv_DA_ssa = OmF_norm_stdv\n",
    "OmA_mean_DA_ssa = OmA_mean\n",
    "OmA_stdv_DA_ssa = OmA_stdv\n",
    "N_data_DA_ssa = N_data\n",
    "\n",
    "group_metrics_DA_ssa = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_DA_ssa[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_DA_ssa[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['Nobs_data'] = group_N_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e2f601",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftc = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd/' \\\n",
    "      'DAv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/rc_out/DAv8_M36_cd.ldas_tilecoord.bin'\n",
    "tc = read_tilecoord(ftc)\n",
    "n_tile = tc['N_tile']\n",
    "lat = tc['com_lat']\n",
    "lon = tc['com_lon']\n",
    "\n",
    "map_array = np.empty([n_tile, 3])\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 1] = lon\n",
    "map_array[:, 2] = lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d705be1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7cc85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stats_dict_to_arrays(stats_dict):\n",
    "    \"\"\"Convert dictionary of lists to numpy arrays\"\"\"\n",
    "    array_dict = {}\n",
    "    \n",
    "    for key in stats_dict.keys():\n",
    "        # Convert list to array and reshape\n",
    "        array_dict[key] = np.array(stats_dict[key])\n",
    "        \n",
    "        # Check if we need to handle missing values (-- in data)\n",
    "        if isinstance(array_dict[key][0], (list, np.ndarray)):\n",
    "            # Replace '--' with np.nan\n",
    "            temp_array = []\n",
    "            for row in array_dict[key]:\n",
    "                cleaned_row = [np.nan if x == '--' else float(x) for x in row]\n",
    "                temp_array.append(cleaned_row)\n",
    "            array_dict[key] = np.array(temp_array)\n",
    "    \n",
    "    return array_dict\n",
    "\n",
    "# Convert dictionary\n",
    "stats_dict_DA_arrays = convert_stats_dict_to_arrays(stats_dict_DA)\n",
    "stats_dict_OL_arrays = convert_stats_dict_to_arrays(stats_dict_OL)\n",
    "stats_dict_DA_all_arrays = convert_stats_dict_to_arrays(stats_dict_DA_all)\n",
    "stats_DA_ssa_arrays = convert_stats_dict_to_arrays(stats_dict_DA_ssa)\n",
    "\n",
    "# Convert date vector to datetime objects\n",
    "date_vec_DA = [datetime.strptime(date, '%Y%m') for date in date_vec_DA]\n",
    "date_vec_OL = [datetime.strptime(date, '%Y%m') for date in date_vec_OL]\n",
    "date_vec_DA_all = [datetime.strptime(date, '%Y%m') for date in date_vec_DA_all]\n",
    "date_vec_DA_ssa = [datetime.strptime(date, '%Y%m') for date in date_vec_DA_ssa]\n",
    "\n",
    "# Print first few dates to verify\n",
    "print(\"Sample dates:\", date_vec_DA[:3])\n",
    "# Print the last few dates to verify\n",
    "print(\"Sample dates:\", date_vec_DA[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdfa31c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_group_stats(stats_dict, species_groups):\n",
    "    \"\"\"Calculate weighted statistics for each group\"\"\"\n",
    "    \n",
    "    n_times = len(stats_dict['OmF_mean'])\n",
    "    stats = ['O_mean','F_mean','OmF_mean', 'OmF_stdv', 'OmA_mean', 'OmA_stdv']\n",
    "    \n",
    "    # Initialize output dictionary\n",
    "    group_stats = {}\n",
    "    for group in species_groups.keys():\n",
    "        group_stats[group] = {stat: np.zeros(n_times) for stat in stats}\n",
    "        group_stats[group]['N_data'] = np.zeros(n_times)\n",
    "    \n",
    "    # Calculate weighted stats for each timestep\n",
    "    for t in range(n_times):\n",
    "        for group, indices in species_groups.items():\n",
    "            # Get weights for this group/time\n",
    "            weights = stats_dict['N_data'][t, indices]\n",
    "            total_weight = np.sum(weights)\n",
    "            \n",
    "            if total_weight > 0:\n",
    "                # Calculate weighted statistics\n",
    "                for stat in stats:\n",
    "                    values = stats_dict[stat][t, indices]\n",
    "                    group_stats[group][stat][t] = np.average(values, weights=weights)\n",
    "                group_stats[group]['N_data'][t] = total_weight\n",
    "            else:\n",
    "                # Set to NaN if no observations\n",
    "                for stat in stats:\n",
    "                    group_stats[group][stat][t] = np.nan\n",
    "                    \n",
    "    return group_stats\n",
    "\n",
    "# Calculate group means\n",
    "group_ts_DA = calculate_weighted_group_stats(stats_dict_DA_arrays, species_groups)\n",
    "group_ts_OL = calculate_weighted_group_stats(stats_dict_OL_arrays, species_groups)\n",
    "group_ts_DA_all = calculate_weighted_group_stats(stats_dict_DA_all_arrays, species_groups)\n",
    "group_ts_DA_ssa = calculate_weighted_group_stats(stats_DA_ssa_arrays, species_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3df43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length of date_vec_DA\", len(date_vec_DA))\n",
    "print(\"length of date_vec\", len(date_vec))\n",
    "print(\"length of date_vec_DA_all\", len(date_vec_DA_all))\n",
    "print(\"length of date_vec_DA_ssa\", len(date_vec_DA_ssa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364344e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2x2 panel: OM-F stddev time series per species\n",
    "# Panel order: CYGNSS (a), SMAP (b), ASCAT (c), SMOS (d)\n",
    "panel_order = [\"CYGNSS\", \"SMAP\", \"ASCAT\", \"SMOS\"]\n",
    "panel_labels = [\"(a)\", \"(b)\", \"(c)\", \"(d)\"]\n",
    "fig, axes = plt.subplots(2, 2, figsize=(18, 12), sharex=True)\n",
    "axes = axes.flatten()\n",
    "\n",
    "for ax, species, lab in zip(axes, panel_order, panel_labels):\n",
    "    mean_OL = np.nanmean(group_ts_OL[species]['OmF_stdv'])\n",
    "    mean_DA = np.nanmean(group_ts_DA[species]['OmF_stdv'])\n",
    "    mean_DA_all = np.nanmean(group_ts_DA_all[species]['OmF_stdv'])\n",
    "    mean_DA_ssa = np.nanmean(group_ts_DA_ssa[species]['OmF_stdv'])\n",
    "\n",
    "    ax.plot(date_vec_DA, group_ts_OL[species]['OmF_stdv'], '--', label=f'CNTL ({mean_OL:.3f})')\n",
    "    ax.plot(date_vec_DA, group_ts_DA[species]['OmF_stdv'], '-', label=f'CYG_DA ({mean_DA:.3f})')\n",
    "    ax.plot(date_vec_DA_ssa, group_ts_DA_ssa[species]['OmF_stdv'], '-.', label=f'SSA_DA ({mean_DA_ssa:.3f})')\n",
    "    ax.plot(date_vec_DA_all, group_ts_DA_all[species]['OmF_stdv'], ':', label=f'ALL_DA ({mean_DA_all:.3f})')\n",
    "\n",
    "    ax.set_title(f'StdDev of {species} OmF residuals')\n",
    "    ax.set_ylabel('OmF StdDev')\n",
    "    ax.text(0.02, 0.95, lab, transform=ax.transAxes, va='top', ha='left')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "# Only bottom panels get x labels/ticks\n",
    "for i, ax in enumerate(axes):\n",
    "    if i in [2, 3]:\n",
    "        # ax.set_xlabel('Date')\n",
    "        ax.set_xticks(date_vec_DA[::12])\n",
    "        ax.tick_params(axis='x')\n",
    "    else:\n",
    "        ax.tick_params(axis='x', labelbottom=False)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_4\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc8f29f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined normalized percent difference for CYG_DA, SSA_DA, ALL_DA\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 18), sharex=True)\n",
    "labels = [\"(a)\", \"(b)\", \"(c)\"]\n",
    "panels = [\n",
    "    (group_ts_DA, date_vec_DA, \"Normalized Percent Difference ((CYG_DA - CNTL) / CNTL)\", (-10, 2)),\n",
    "    (group_ts_DA_ssa, date_vec_DA_ssa, \"Normalized Percent Difference ((SSA_DA - CNTL) / CNTL)\", (-25, 5)),\n",
    "    (group_ts_DA_all, date_vec_DA, \"Normalized Percent Difference ((ALL_DA - CNTL) / CNTL)\", (-25, 5)),\n",
    "]\n",
    "groups_to_plot = list(species_groups.keys())[:4]\n",
    "\n",
    "for i, (ax, (ts_dict, dates, title, ylim), lab) in enumerate(zip(axes, panels, labels)):\n",
    "    for group in groups_to_plot:\n",
    "        norm_percent_diff = np.divide(\n",
    "            (ts_dict[group]['OmF_stdv'] - group_ts_OL[group]['OmF_stdv']),\n",
    "            group_ts_OL[group]['OmF_stdv'],\n",
    "            out=np.full_like(group_ts_OL[group]['OmF_stdv'], np.nan, dtype=float),\n",
    "            where=group_ts_OL[group]['OmF_stdv'] != 0\n",
    "        ) * 100\n",
    "        mean_diff = np.nanmean(norm_percent_diff)\n",
    "        ax.plot(dates, norm_percent_diff, label=f'{group} ({mean_diff:.2f})')\n",
    "    \n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel('Normalized Percent Difference (%)')\n",
    "    ax.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.text(0.01, 0.08, lab, transform=ax.transAxes, va='top', ha='left')\n",
    "    ax.legend()  # Add legend to each subplot\n",
    "    \n",
    "    # Only show x-axis labels and ticks on the bottom plot\n",
    "    if i < 2:  # Top two plots\n",
    "        ax.tick_params(axis='x', labelbottom=False)\n",
    "    else:  # Bottom plot\n",
    "        # ax.set_xlabel('Date')\n",
    "        ax.set_xticks(dates[::12])\n",
    "        ax.set_xticklabels([d.strftime('%Y-%m-%d') for d in dates[::12]])\n",
    "        ax.tick_params(axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_5\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ada2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6-panel map: CYGNSS, SMAP, ASCAT, SMOS, ALL, %CYGNSS (Obs/day)\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from common.python.plotting.geospatial_plotting import load_ease_grid, build_ease_grid_mapping\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "ndays = 2161\n",
    "# Initialize map_array with proper shape (n_tile, 3) where columns are: data, lon, lat\n",
    "map_array = np.empty([n_tile, 3])\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 1] = lon\n",
    "map_array[:, 2] = lat\n",
    "\n",
    "def compute_per_day(group_metrics, group_name):\n",
    "    raw = group_metrics[group_name]['Nobs_data']\n",
    "    return np.nan_to_num(raw / ndays, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "# Per-day counts per group\n",
    "per_day_maps = {g: compute_per_day(group_metrics_DA, g) for g in species_groups.keys()}\n",
    "# Totals and cygnss fraction\n",
    "total_obs_per_day = sum(per_day_maps.values())\n",
    "cygnss_obs_per_day = per_day_maps.get('CYGNSS', np.zeros_like(total_obs_per_day))\n",
    "frac_cygnss = np.divide(cygnss_obs_per_day, total_obs_per_day, out=np.zeros_like(total_obs_per_day), where=total_obs_per_day>0)\n",
    "percent_cygnss = 100.0 * frac_cygnss\n",
    "\n",
    "# Helper to plot on given ax\n",
    "lats, lons = load_ease_grid()\n",
    "lats_row, lons_col = lats[:,1], lons[1,:]\n",
    "lon_grid, lat_grid = np.meshgrid(lons_col, lats_row)\n",
    "\n",
    "panel_defs = [\n",
    "    ('CYGNSS', per_day_maps['CYGNSS'], 'CYGNSS Obs per day', (0, 1.2), '(a)'),\n",
    "    ('SMAP',   per_day_maps['SMAP'],   'SMAP Obs per day',   (0, 1.2), '(b)'),\n",
    "    ('ASCAT',  per_day_maps['ASCAT'],  'ASCAT Obs per day',  (0, 1.2), '(c)'),\n",
    "    ('SMOS',   per_day_maps['SMOS'],   'SMOS Obs per day',   (0, 1.2), '(d)'),\n",
    "    ('ALL',    total_obs_per_day,      'ALL Obs per day', (0, 4.0), '(e)'),\n",
    "    ('%CYGNSS',percent_cygnss,         '% CYGNSS of Obs', (0, 50.0), '(f)'),\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(3, 2, figsize=(14, 9), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "axes = axes.flatten()\n",
    "for ax, (name, data_1d, title, clim, lab) in zip(axes, panel_defs):\n",
    "    map_array[:,0] = data_1d\n",
    "    grid = build_ease_grid_mapping(map_array, lats_row, lons_col)\n",
    "    \n",
    "    # Create custom colormap with 20 discrete colors\n",
    "    edges = np.linspace(clim[0], clim[1], 21)  # 21 edges for 20 intervals\n",
    "    cmap = get_cmap('viridis', len(edges)-1)\n",
    "    norm = BoundaryNorm(edges, cmap.N)\n",
    "    \n",
    "    sc = ax.pcolormesh(lon_grid, lat_grid, grid, cmap=cmap, norm=norm, transform=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "    ax.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "    \n",
    "    maxval = np.nanmax(data_1d)\n",
    "    minval = np.nanmin(data_1d)\n",
    "    meanval = np.nanmean(data_1d)\n",
    "    stdval = np.nanstd(data_1d)\n",
    "    ax.set_title(f\"{title} (Mean: {meanval:.2f} ± {stdval:.2f})\")\n",
    "    ax.text(0.01, 0.02, lab, transform=ax.transAxes, va='bottom', ha='left')\n",
    "    \n",
    "    cbar = plt.colorbar(sc, ax=ax, orientation='horizontal', pad=0.03, fraction=0.05)\n",
    "    units = 'Obs per day' if name != '%CYGNSS' else '% of obs from CYGNSS'\n",
    "    cbar.set_label(units)\n",
    "    \n",
    "    # Set 5 tick labels evenly spaced across the range\n",
    "    tick_positions = np.linspace(clim[0], clim[1], 5)\n",
    "    cbar.set_ticks(tick_positions)\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_6\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfa0f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with NaNs in the data\n",
    "for group in species_groups.keys():\n",
    "    group_ts_DA[group]['N_data'] = np.where(group_ts_DA[group]['N_data'] == 0, np.nan, group_ts_DA[group]['N_data'])\n",
    "\n",
    "# Plot time series of the number of observations for each group\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Nobs_data for DA for all groups on one figure\n",
    "for group in species_groups.keys():\n",
    "    mean_val = np.nanmean(group_ts_DA[group]['N_data'])\n",
    "    plt.plot(date_vec_DA, group_ts_DA[group]['N_data'], label=f'{group} ({mean_val:.1e})')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Number of observations from all sensors')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Observations per Month')\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "# Set x-ticks using datetime array\n",
    "plt.xticks(date_vec_DA[::12], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_7\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89e38102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8-panel percent-difference maps (DA - CNTL) / CNTL for OmF StdDev\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from common.python.plotting.geospatial_plotting import load_ease_grid, build_ease_grid_mapping\n",
    "\n",
    "# Helper to compute percent diff safely\n",
    "def pct_diff(da, ol):\n",
    "    return np.divide(da - ol, ol, out=np.full_like(ol, np.nan, dtype=float), where=ol != 0) * 100.0\n",
    "\n",
    "# Prepare per-group percent differences\n",
    "map_array = np.empty([n_tile, 3])\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 1] = lon\n",
    "map_array[:, 2] = lat\n",
    "map_array = map_array.copy()\n",
    "\n",
    "pct_maps = {\n",
    "    ('CYGNSS', 'CYG_DA'): pct_diff(group_metrics_DA['CYGNSS']['OmF_stdv'], group_metrics_OL['CYGNSS']['OmF_stdv']),\n",
    "    ('SMAP',   'CYG_DA'): pct_diff(group_metrics_DA['SMAP']['OmF_stdv'],   group_metrics_OL['SMAP']['OmF_stdv']),\n",
    "    ('ASCAT',  'CYG_DA'): pct_diff(group_metrics_DA['ASCAT']['OmF_stdv'],  group_metrics_OL['ASCAT']['OmF_stdv']),\n",
    "    ('SMOS',   'CYG_DA'): pct_diff(group_metrics_DA['SMOS']['OmF_stdv'],   group_metrics_OL['SMOS']['OmF_stdv']),\n",
    "    ('CYGNSS', 'ALL_DA'): pct_diff(group_metrics_DA_all['CYGNSS']['OmF_stdv'], group_metrics_OL['CYGNSS']['OmF_stdv']),\n",
    "    ('SMAP',   'ALL_DA'): pct_diff(group_metrics_DA_all['SMAP']['OmF_stdv'],   group_metrics_OL['SMAP']['OmF_stdv']),\n",
    "    ('ASCAT',  'ALL_DA'): pct_diff(group_metrics_DA_all['ASCAT']['OmF_stdv'],  group_metrics_OL['ASCAT']['OmF_stdv']),\n",
    "    ('SMOS',   'ALL_DA'): pct_diff(group_metrics_DA_all['SMOS']['OmF_stdv'],   group_metrics_OL['SMOS']['OmF_stdv']),\n",
    "}\n",
    "\n",
    "# Panel ordering and labels\n",
    "# panels = [\n",
    "#     (('CYGNSS','CYG_DA'), '(a)'),\n",
    "#     (('SMAP','CYG_DA'), '(b)'),\n",
    "#     (('ASCAT','CYG_DA'), '(c)'),\n",
    "#     (('SMOS','CYG_DA'), '(d)'),\n",
    "#     (('CYGNSS','ALL_DA'), '(e)'),\n",
    "#     (('SMAP','ALL_DA'), '(f)'),\n",
    "#     (('ASCAT','ALL_DA'), '(g)'),\n",
    "#     (('SMOS','ALL_DA'), '(h)'),\n",
    "# ]\n",
    "\n",
    "panels = [\n",
    "    (('CYGNSS','CYG_DA'), '(a)'),\n",
    "    (('CYGNSS','ALL_DA'), '(b)'),\n",
    "    (('SMAP','CYG_DA'), '(c)'),\n",
    "    (('SMAP','ALL_DA'), '(d)'),\n",
    "    (('ASCAT','CYG_DA'), '(e)'),\n",
    "    (('ASCAT','ALL_DA'), '(f)'),\n",
    "    (('SMOS','CYG_DA'), '(g)'),\n",
    "    (('SMOS','ALL_DA'), '(h)'),\n",
    "]\n",
    "\n",
    "# Gather all values to set symmetric color scale\n",
    "all_vals = np.concatenate([pct_maps[key].flatten() for key,_ in panels])\n",
    "all_vals = np.concatenate([pct_maps[key].flatten() for key,_ in panels])\n",
    "vmin, vmax = -30.0, 30.0\n",
    "\n",
    "lats, lons = load_ease_grid()\n",
    "lats_row, lons_col = lats[:,1], lons[1,:]\n",
    "lon_grid, lat_grid = np.meshgrid(lons_col, lats_row)\n",
    "\n",
    "fig, axes = plt.subplots(4, 2, figsize=(14, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "axes = axes.flatten()\n",
    "for ax, (key, lab) in zip(axes, panels):\n",
    "    species, exp = key\n",
    "    data_1d = pct_maps[key]\n",
    "    mean_val = np.nanmean(data_1d)\n",
    "    std_val = np.nanstd(data_1d)\n",
    "    map_array[:,0] = data_1d\n",
    "    grid = build_ease_grid_mapping(map_array, lats_row, lons_col)\n",
    "    sc = ax.pcolormesh(lon_grid, lat_grid, grid, cmap='RdBu_r', vmin=vmin, vmax=vmax, transform=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "    ax.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "    ax.set_title(f'({exp} - CNTL) / CNTL, OmF StdDev {species}\\n(Mean: {mean_val:.2f} ± {std_val:.2f} %)')\n",
    "    ax.text(0.02, 0.02, lab, transform=ax.transAxes, va='bottom', ha='left')\n",
    "    ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "# Shared colorbar at bottom\n",
    "cax = fig.add_axes([0.35, 0.05, 0.30, 0.02])\n",
    "edges = np.linspace(vmin, vmax, 21)\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "cmap = get_cmap(\"RdBu_r\", len(edges)-1)\n",
    "norm = BoundaryNorm(edges, cmap.N)\n",
    "sc.set_cmap(cmap); sc.set_norm(norm)\n",
    "cbar = fig.colorbar(sc, cax=cax, orientation=\"horizontal\")\n",
    "cbar.set_ticks([-30, -15, 0, 15, 30])\n",
    "cbar.ax.set_xticklabels([\"-30\", \"-15\", \"0\", \"15\", \"30\"])\n",
    "cbar.set_label('%')\n",
    "fig.tight_layout(rect=(0, 0.08, 1, 1))\n",
    "save_fig(plt.gcf(), \"figure_8\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1c06ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4-panel percent-difference maps for SSA_DA vs CNTL (OmF StdDev)\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from common.python.plotting.geospatial_plotting import load_ease_grid, build_ease_grid_mapping\n",
    "\n",
    "# Helper\n",
    "def pct_diff(da, ol):\n",
    "    return np.divide(da - ol, ol, out=np.full_like(ol, np.nan, dtype=float), where=ol != 0) * 100.0\n",
    "\n",
    "map_array = np.empty([n_tile, 3]); map_array.fill(np.nan)\n",
    "map_array[:,1] = lon; map_array[:,2] = lat\n",
    "map_array = map_array.copy()\n",
    "\n",
    "pct_maps_ssa = {\n",
    "    'CYGNSS': pct_diff(group_metrics_DA_ssa['CYGNSS']['OmF_stdv'], group_metrics_OL['CYGNSS']['OmF_stdv']),\n",
    "    'SMAP':   pct_diff(group_metrics_DA_ssa['SMAP']['OmF_stdv'],   group_metrics_OL['SMAP']['OmF_stdv']),\n",
    "    'ASCAT':  pct_diff(group_metrics_DA_ssa['ASCAT']['OmF_stdv'],  group_metrics_OL['ASCAT']['OmF_stdv']),\n",
    "    'SMOS':   pct_diff(group_metrics_DA_ssa['SMOS']['OmF_stdv'],   group_metrics_OL['SMOS']['OmF_stdv']),\n",
    "}\n",
    "\n",
    "panels = [\n",
    "    ('CYGNSS', '(a)'),\n",
    "    ('SMAP',   '(b)'),\n",
    "    ('ASCAT',  '(c)'),\n",
    "    ('SMOS',   '(d)'),\n",
    "]\n",
    "\n",
    "vmin, vmax = -30.0, 30.0\n",
    "lats, lons = load_ease_grid(); lats_row, lons_col = lats[:,1], lons[1,:]\n",
    "lon_grid, lat_grid = np.meshgrid(lons_col, lats_row)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "axes = axes.flatten()\n",
    "for ax, (species, lab) in zip(axes, panels):\n",
    "    data_1d = pct_maps_ssa[species]\n",
    "    mean_val = np.nanmean(data_1d)\n",
    "    std_val = np.nanstd(data_1d)\n",
    "    map_array[:,0] = data_1d\n",
    "    grid = build_ease_grid_mapping(map_array, lats_row, lons_col)\n",
    "    sc = ax.pcolormesh(lon_grid, lat_grid, grid, cmap='RdBu_r', vmin=vmin, vmax=vmax, transform=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "    ax.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "    ax.set_title(f'(SSA_DA - CNTL) / CNTL, OmF StdDev {species}\\n(Mean: {mean_val:.2f} ± {std_val:.2f} %)')\n",
    "    ax.text(0.02, 0.02, lab, transform=ax.transAxes, va='bottom', ha='left')\n",
    "    ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "# Shared colorbar\n",
    "cax = fig.add_axes([0.35, 0.01, 0.30, 0.02])\n",
    "edges = np.linspace(vmin, vmax, 21)\n",
    "from matplotlib.colors import BoundaryNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "cmap = get_cmap(\"RdBu_r\", len(edges)-1)\n",
    "norm = BoundaryNorm(edges, cmap.N)\n",
    "sc.set_cmap(cmap); sc.set_norm(norm)\n",
    "cbar = fig.colorbar(sc, cax=cax, orientation=\"horizontal\")\n",
    "cbar.set_ticks([-30, -15, 0, 15, 30])\n",
    "cbar.ax.set_xticklabels([\"-30\", \"-15\", \"0\", \"15\", \"30\"])\n",
    "cbar.set_label('%')\n",
    "fig.tight_layout(rect=(0, 0.05, 1, 0.98))\n",
    "save_fig(plt.gcf(), \"figure_9\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af5f1d8",
   "metadata": {},
   "source": [
    "# CYGNSS CD Summary Figures\n",
    "\n",
    "Plots copied from original IV and TC notebooks (processing unchanged, imports consolidated)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0645eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy import stats\n",
    "from scipy.spatial import cKDTree\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# repo utilities\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / '.git').exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "here = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()\n",
    "repo_root = find_repo_root(here)\n",
    "sys.path.append(str(repo_root / 'common' / 'python' / 'plotting'))\n",
    "sys.path.append(str(repo_root / 'common' / 'python' / 'io'))\n",
    "sys.path.append(str(repo_root / 'projects' / 'matlab2python' / 'shared' / 'python'))\n",
    "sys.path.append('../util/shared/python/')\n",
    "\n",
    "from read_GEOSldas import read_tilecoord\n",
    "\n",
    "DATA_DIR = Path('/Users/amfox/Desktop/GEOSldas_diagnostics/test_data')\n",
    "# plotting removed (single-panel plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb08e26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import scipy.io as sio\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from scipy import stats\n",
    "from scipy.spatial import cKDTree\n",
    "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "# repo utilities\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / '.git').exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "here = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()\n",
    "repo_root = find_repo_root(here)\n",
    "sys.path.append(str(repo_root / 'common' / 'python' / 'plotting'))\n",
    "sys.path.append(str(repo_root / 'common' / 'python' / 'io'))\n",
    "sys.path.append(str(repo_root / 'projects' / 'matlab2python' / 'shared' / 'python'))\n",
    "sys.path.append('../util/shared/python/')\n",
    "\n",
    "from read_GEOSldas import read_tilecoord\n",
    "\n",
    "DATA_DIR = Path('/Users/amfox/Desktop/GEOSldas_diagnostics/test_data')\n",
    "# plotting removed (single-panel plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd6dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- 1) paths ---------\n",
    "p_cntl = Path(\"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/Evaluation/IVs/ASCL4_SMPL3_OLv8_M36_cd_TC_stats_201808_202405.mat\")\n",
    "p_da   = Path(\"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/Evaluation/IVs/ASCL4_SMPL3_DAv8_M36_cd_TC_stats_201808_202405.mat\")\n",
    "\n",
    "# --------- 2) load .mat (squeeze to 1D vectors) ---------\n",
    "def _vec(x):\n",
    "    return np.asarray(x).squeeze()\n",
    "\n",
    "M0 = loadmat(p_cntl, squeeze_me=True, struct_as_record=False)\n",
    "M1 = loadmat(p_da,   squeeze_me=True, struct_as_record=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15404ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# expected vars: 'lons','lats','N_sm','Nmin','R2_TC_L3','R2_TC_ASC','R2_TC_mod',\n",
    "# 'sigma2_L3','sigma2_mod','sigma2_ASC','R_mod_L3','R_mod_ASC','R_ASC_L3',\n",
    "# 'C_L3_mod','C_mod_ASC','C_L3_ASC'\n",
    "\n",
    "def _vec(x): return np.asarray(x).squeeze()\n",
    "\n",
    "def grab(M, name):\n",
    "    if name not in M:\n",
    "        raise KeyError(f\"Missing '{name}' in file\")\n",
    "    return _vec(M[name])\n",
    "\n",
    "# --- grid shape from lons/lats ---\n",
    "lons = grab(M0, \"lons\")\n",
    "lats = grab(M0, \"lats\")\n",
    "\n",
    "if lons.ndim == 2 and lats.ndim == 2:\n",
    "    shp = lons.shape  # (nlon, nlat)\n",
    "else:\n",
    "    # If saved flat, set to your grid dims and reshape\n",
    "    nlon, nlat = 406, 964\n",
    "    shp = (nlon, nlat)\n",
    "    lons = lons.reshape(shp)\n",
    "    lats = lats.reshape(shp)\n",
    "\n",
    "    # preserve TC grid as flat vectors\n",
    "    lons_tc = lons.flatten()\n",
    "    lats_tc = lats.flatten()\n",
    "\n",
    "# Helpers to coerce arrays to 2D grid\n",
    "def as_grid(M, key, shp):\n",
    "    a = grab(M, key)\n",
    "    if a.ndim == 2 and a.shape == shp:\n",
    "        return a\n",
    "    if a.size == np.prod(shp):\n",
    "        return a.reshape(shp)\n",
    "    # Some MATLAB saves may come as (nlat, nlon); handle simple transpose case\n",
    "    if a.ndim == 2 and a.shape == (shp[1], shp[0]):\n",
    "        return a.T\n",
    "    raise ValueError(f\"Field '{key}' has unexpected shape {a.shape}, cannot map to {shp}\")\n",
    "\n",
    "def get_fields(M, shp):\n",
    "    grid_keys = [\n",
    "        \"N_sm\",\n",
    "        \"R2_TC_L3\",\"R2_TC_ASC\",\"R2_TC_mod\",\n",
    "        \"sigma2_L3\",\"sigma2_mod\",\"sigma2_ASC\",\n",
    "        \"R_mod_L3\",\"R_mod_ASC\",\"R_ASC_L3\",\n",
    "        \"C_L3_mod\",\"C_mod_ASC\",\"C_L3_ASC\",\n",
    "    ]\n",
    "    out = {k: as_grid(M, k, shp) for k in grid_keys}\n",
    "    # Scalars\n",
    "    out[\"Nmin\"] = float(grab(M, \"Nmin\"))\n",
    "    return out\n",
    "\n",
    "S0 = get_fields(M0, shp)  # CNTL\n",
    "S1 = get_fields(M1, shp)  # CYG_DA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c3466a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- 3) build common-valid mask ---------\n",
    "# same sampling threshold in both + all fields finite where needed\n",
    "Nmin = int(np.nanmax(S0[\"Nmin\"]))  # should be same value\n",
    "Mvalid = (\n",
    "    (S0[\"N_sm\"] >= Nmin) & (S1[\"N_sm\"] >= Nmin) &\n",
    "    np.isfinite(S0[\"R2_TC_mod\"]) & np.isfinite(S1[\"R2_TC_mod\"]) &\n",
    "    np.isfinite(S0[\"sigma2_mod\"]) & np.isfinite(S1[\"sigma2_mod\"])\n",
    ")\n",
    "\n",
    "# clamp any R2 slightly outside (0,1] due to rounding\n",
    "def clamp01(a):\n",
    "    out = a.copy()\n",
    "    out[(out <= 0) | (~np.isfinite(out))] = np.nan\n",
    "    out[out > 1] = 1.0\n",
    "    return out\n",
    "\n",
    "R2m0 = clamp01(S0[\"R2_TC_mod\"])\n",
    "R2m1 = clamp01(S1[\"R2_TC_mod\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a097321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- 4) compute metrics ---------\n",
    "# (a) change in R^2 (positive is better)\n",
    "dR2_mod = np.where(Mvalid, R2m1 - R2m0, np.nan)\n",
    "pct_R2 = np.where(Mvalid, 100.0*(R2m1/R2m0 - 1), np.nan)  # positive % is better\n",
    "\n",
    "def robust_sigma_t2(S, tol=1e-12, max_spread=50.0):\n",
    "    C_l3m  = S[\"C_L3_mod\"].astype(float)\n",
    "    C_ma   = S[\"C_mod_ASC\"].astype(float)\n",
    "    C_l3a  = S[\"C_L3_ASC\"].astype(float)\n",
    "\n",
    "    # three TC permutations for σ_t^2\n",
    "    s1 = (C_l3m * C_ma)  / C_l3a\n",
    "    s2 = (C_l3m * C_l3a) / C_ma\n",
    "    s3 = (C_ma  * C_l3a) / C_l3m\n",
    "    stack = np.stack([s1, s2, s3], 0)\n",
    "\n",
    "    # basic validity: finite and positive\n",
    "    valid = np.isfinite(stack) & (stack > tol)\n",
    "    sig_t2 = np.nanmedian(np.where(valid, stack, np.nan), axis=0)\n",
    "\n",
    "    # consistency check: drop pixels where permutations disagree wildly\n",
    "    smin = np.nanmin(np.where(valid, stack, np.nan), axis=0)\n",
    "    smax = np.nanmax(np.where(valid, stack, np.nan), axis=0)\n",
    "    spread = smax / smin\n",
    "    bad = (~np.isfinite(sig_t2)) | (sig_t2 <= tol) | (~np.isfinite(spread)) | (spread > max_spread)\n",
    "    sig_t2[bad] = np.nan\n",
    "    return sig_t2\n",
    "\n",
    "def direct_fMSE(S):\n",
    "    \"\"\"\n",
    "    Compute fractional MSE directly from TC covariances & error variances.\n",
    "    S must contain: 'sigma2_mod','sigma2_L3','sigma2_ASC',\n",
    "                    'C_L3_mod','C_mod_ASC','C_L3_ASC'\n",
    "    Returns: dict with fMSE_{mod,L3,ASC} and sigma_t2.\n",
    "    \"\"\"\n",
    "    C_L3_mod = S[\"C_L3_mod\"].astype(float)\n",
    "    C_mod_ASC= S[\"C_mod_ASC\"].astype(float)\n",
    "    C_L3_ASC = S[\"C_L3_ASC\"].astype(float)\n",
    "\n",
    "    # Truth (signal) variance from TC geometry\n",
    "    sigma_t2 = robust_sigma_t2(S)\n",
    "\n",
    "    bad = (~np.isfinite(sigma_t2)) | (sigma_t2 <= 0)\n",
    "    fMSE_mod = np.full_like(sigma_t2, np.nan)\n",
    "    fMSE_L3  = np.full_like(sigma_t2, np.nan)\n",
    "    fMSE_ASC = np.full_like(sigma_t2, np.nan)\n",
    "\n",
    "    ok = ~bad\n",
    "    # Require finite σ² as well\n",
    "    ok_mod = ok & np.isfinite(S[\"sigma2_mod\"])\n",
    "    ok_L3  = ok & np.isfinite(S[\"sigma2_L3\"])\n",
    "    ok_ASC = ok & np.isfinite(S[\"sigma2_ASC\"])\n",
    "\n",
    "    fMSE_mod[ok_mod] = S[\"sigma2_mod\"][ok_mod] / sigma_t2[ok_mod]\n",
    "    fMSE_L3[ok_L3]   = S[\"sigma2_L3\"][ok_L3]   / sigma_t2[ok_L3]\n",
    "    fMSE_ASC[ok_ASC] = S[\"sigma2_ASC\"][ok_ASC] / sigma_t2[ok_ASC]\n",
    "\n",
    "    # Nonphysical negatives -> NaN\n",
    "    fMSE_mod[fMSE_mod < 0] = np.nan\n",
    "    fMSE_L3[fMSE_L3   < 0] = np.nan\n",
    "    fMSE_ASC[fMSE_ASC < 0] = np.nan\n",
    "\n",
    "    return dict(fMSE_mod=fMSE_mod, fMSE_L3=fMSE_L3, fMSE_ASC=fMSE_ASC, sigma_t2=sigma_t2)\n",
    "\n",
    "\n",
    "def fMSE_from_R2(R2):\n",
    "    fm = (1 - R2) / R2\n",
    "    fm[(~np.isfinite(fm)) | (fm < 0)] = np.nan\n",
    "    return fm\n",
    "\n",
    "# Example usage on your loaded fields S0/S1 (CNTL/DA):\n",
    "direct0 = direct_fMSE(S0); direct1 = direct_fMSE(S1)\n",
    "fMSE0_R2 = fMSE_from_R2(S0[\"R2_TC_mod\"])\n",
    "diff_check = np.nanmax(np.abs(direct0[\"fMSE_mod\"] - fMSE0_R2))\n",
    "print(\"max |direct - via R2|:\", diff_check)\n",
    "\n",
    "\n",
    "# fMSE0 = fMSE_from_R2(R2m0)\n",
    "# fMSE1 = fMSE_from_R2(R2m1)\n",
    "# dfMSE = np.where(Mvalid, fMSE1 - fMSE0, np.nan)              # negative is good\n",
    "# pct_fMSE = np.where(Mvalid, 100.0*(fMSE1/fMSE0 - 1), np.nan) # negative % is good\n",
    "\n",
    "# Direct fMSE from TC covariances\n",
    "direct0 = direct_fMSE(S0)   # CNTL\n",
    "direct1 = direct_fMSE(S1)   # CYG_DA\n",
    "\n",
    "fMSE0 = direct0[\"fMSE_mod\"]\n",
    "fMSE1 = direct1[\"fMSE_mod\"]\n",
    "\n",
    "# Valid where both runs have finite fMSE and you already had Nmin, etc.\n",
    "Mvalid_fmse = Mvalid & np.isfinite(fMSE0) & np.isfinite(fMSE1)\n",
    "\n",
    "dfMSE = np.full_like(fMSE0, np.nan)\n",
    "dfMSE[Mvalid_fmse] = fMSE1[Mvalid_fmse] - fMSE0[Mvalid_fmse]      # negative is good\n",
    "\n",
    "pct_fMSE = np.full_like(fMSE0, np.nan)\n",
    "ratio = np.full_like(fMSE0, np.nan)\n",
    "ratio[Mvalid_fmse] = fMSE1[Mvalid_fmse] / fMSE0[Mvalid_fmse]\n",
    "pct_fMSE[Mvalid_fmse] = 100.0 * (ratio[Mvalid_fmse] - 1.0)        # negative % is good\n",
    "\n",
    "# (c) change in model error variance (σ^2_mod) and % change\n",
    "sig20 = S0[\"sigma2_mod\"]; sig21 = S1[\"sigma2_mod\"]\n",
    "dsig2 = np.where(Mvalid, sig21 - sig20, np.nan)                  # negative is good\n",
    "\n",
    "# 1) mask tiny baseline sigma2 before % change\n",
    "p10 = np.nanpercentile(sig20, 10)\n",
    "baseline_floor = max(1e-8, p10)\n",
    "good_base = Mvalid & np.isfinite(sig20) & (sig20 > baseline_floor)\n",
    "\n",
    "pct_sig2 = np.full_like(sig20, np.nan)\n",
    "pct_sig2[good_base] = 100.0 * (sig21[good_base]/sig20[good_base] - 1.0)\n",
    "\n",
    "# 2) Robust summaries (don’t use mean±std)\n",
    "def robust_summary(a, m):\n",
    "    x = a[m & np.isfinite(a)]\n",
    "    if x.size == 0: return {\"median\": np.nan, \"IQR\": np.nan, \"n\": 0, \"improved_frac\": np.nan}\n",
    "    q25, q50, q75 = np.nanpercentile(x, [25, 50, 75])\n",
    "    return {\n",
    "        \"median\": float(q50),\n",
    "        \"IQR\": float(q75 - q25),\n",
    "        \"n\": int(x.size),\n",
    "        \"improved_frac\": float(np.nanmean((x < 0)))  # negative % = reduction\n",
    "    }\n",
    "\n",
    "summ_pct = robust_summary(pct_sig2, good_base)\n",
    "summ_dR2 = robust_summary(dR2_mod, Mvalid)\n",
    "\n",
    "print(\"ΔR²_mod  (median, IQR):\", summ_dR2[\"median\"], summ_dR2[\"IQR\"])\n",
    "print(\"Fraction tiles with R² improved:\", 1 - summ_dR2[\"improved_frac\"])\n",
    "print(\"%Δσ²_mod (median, IQR):\", summ_pct[\"median\"], summ_pct[\"IQR\"])\n",
    "print(\"Fraction tiles with σ² reduced:\", summ_pct[\"improved_frac\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c005ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten dR2_mod for downstream mapping\n",
    "dR2_mod_vec = dR2_mod.flatten()\n",
    "dR2_mod_vec = np.asarray(dR2_mod_vec, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbeb14d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load aridity/LAI dataset\n",
    "fn = DATA_DIR / 'CYGNSS_Experiments/Evaluation/IVs/aridity_indices_model_net_rad_20180801_20240630.nc4'\n",
    "ds = xr.open_dataset(fn, decode_times=True)\n",
    "ai = ds['AI_clim'].values\n",
    "lon = ds['lon'].isel(time=1).values\n",
    "lat = ds['lat'].isel(time=1).values\n",
    "mean_lai_clim = ds['mean_lai_clim'].values\n",
    "mean_greeness_clim = ds['mean_greeness_clim'].values if 'mean_greeness_clim' in ds else None\n",
    "title_time = 'Climatology'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4dca0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TC observation error variances (sigma2_*) for CYG/SMAP/ASCAT\n",
    "p_tc_obs = Path('/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/Evaluation/IVs/ASCL4_SMPL3_CYGL3_OLv8_M36_cd_TC_stats_201808_202405.mat')\n",
    "M2 = loadmat(p_tc_obs, squeeze_me=True, struct_as_record=False)\n",
    "\n",
    "lons_tc = np.asarray(grab(M2, 'lons')).ravel()\n",
    "lats_tc = np.asarray(grab(M2, 'lats')).ravel()\n",
    "sigma2_CYG = np.asarray(grab(M2, 'sigma2_CYG'), dtype=float)\n",
    "sigma2_L3  = np.asarray(grab(M2, 'sigma2_L3'), dtype=float)\n",
    "sigma2_ASC = np.asarray(grab(M2, 'sigma2_ASC'), dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d315fa00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aridity index (AI) prep for downstream multi-panel figures (no plotting here)\n",
    "ai_flat = np.squeeze(ai)\n",
    "lon_flat = np.squeeze(lon)\n",
    "lat_flat = np.squeeze(lat)\n",
    "n = ai_flat.size\n",
    "\n",
    "pred_lon_flat = lon_flat\n",
    "pred_lat_flat = lat_flat\n",
    "\n",
    "map_array = np.empty((n, 3), dtype=float)\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 0] = ai_flat\n",
    "map_array[:, 1] = lon_flat\n",
    "map_array[:, 2] = lat_flat\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "print(f\"AI_clim {title_time} max {maxval:.3g} min {minval:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96da2ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean LAI prep for downstream multi-panel figures (no plotting here)\n",
    "mean_lai_clim = ds['mean_lai_clim'].values  # shape (tile,)\n",
    "mean_lai_flat = np.squeeze(mean_lai_clim)\n",
    "map_array = np.empty((n, 3), dtype=float)\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 0] = mean_lai_flat\n",
    "map_array[:, 1] = lon_flat\n",
    "map_array[:, 2] = lat_flat\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "print(f\"mean_lai_clim max {maxval:.3g} min {minval:.3g}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31fb87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten pct_sig2 for downstream mapping\n",
    "pct_sig2_vec = pct_sig2.flatten()\n",
    "pct_sig2_vec = np.asarray(pct_sig2_vec, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7cfb9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.spatial import cKDTree\n",
    "import cartopy.crs as ccrs\n",
    "\n",
    "# # Ensure coordinate vectors exist for KDTree inputs\n",
    "# if \"lons_vec\" not in globals():\n",
    "#     if \"lons\" in globals():\n",
    "#         lons_vec = np.ravel(lons)\n",
    "#         lats_vec = np.ravel(lats)\n",
    "#     else:\n",
    "#         lons_vec = np.ravel(lon_flat)\n",
    "#         lats_vec = np.ravel(lat_flat)\n",
    "\n",
    "lons_vec = np.ravel(lons_tc)\n",
    "lats_vec = np.ravel(lats_tc)        \n",
    "\n",
    "# inputs expected in notebook namespace: lons_vec, lats_vec, lon_flat, lat_flat, pct_sig2_vec, sigma2_CYG\n",
    "# build points\n",
    "vec_pts = np.column_stack((np.ravel(lons_vec), np.ravel(lats_vec)))\n",
    "flat_pts = np.column_stack((np.ravel(lon_flat), np.ravel(lat_flat)))\n",
    "\n",
    "# build KDTree and query\n",
    "kdtree = cKDTree(vec_pts)\n",
    "_, idxs = kdtree.query(flat_pts, k=1)\n",
    "\n",
    "# map the vector field pct_sig2_vec to the flattened grid order\n",
    "pct_sig2_flat_to_map = pct_sig2_vec[idxs]\n",
    "\n",
    "# reshape to grid like lon_flat (if lon_flat is 1D, keep 1D)\n",
    "try:\n",
    "    grid_shape = lon_flat.shape\n",
    "except NameError:\n",
    "    grid_shape = pct_sig2_flat_to_map.shape\n",
    "pct_map = pct_sig2_flat_to_map.reshape(grid_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "690159a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_dR2 = np.ravel(dR2_mod_vec)[idxs]\n",
    "target_dR2_name = \"Δ R²_mod (DA - CNTL)\"\n",
    "# Clip extreme outliers, keep between 1 and 99 percentiles\n",
    "p_low, p_high = np.nanpercentile(target_dR2, [1, 99])\n",
    "target_dR2 = np.where((target_dR2 < p_low) | (target_dR2 > p_high), np.nan, target_dR2)\n",
    "print(f\"target_dR2 clipped to 1-99% range: {p_low:.3g} to {p_high:.3g}\")\n",
    "\n",
    "target_pct_sig2 = np.ravel(pct_sig2_vec)[idxs]\n",
    "target_pct_sig2_name = \"% Δ σ²_mod (DA vs CNTL)\"\n",
    "# Clip extreme outliers, keep between 1 and 99 percentiles\n",
    "p_low, p_high = np.nanpercentile(target_pct_sig2, [1, 99])\n",
    "target_pct_sig2 = np.where((target_pct_sig2 < p_low) | (target_pct_sig2 > p_high), np.nan, target_pct_sig2)\n",
    "print(f\"target_pct_sig2 clipped to 1-99% range: {p_low:.3g} to {p_high:.3g}\")\n",
    "\n",
    "pred_sigma2_CYG = np.ravel(sigma2_CYG)[idxs]\n",
    "p_low, p_high = np.nanpercentile(pred_sigma2_CYG, [1, 99])\n",
    "pred_sigma2_CYG = np.where((pred_sigma2_CYG < p_low) | (pred_sigma2_CYG > p_high), np.nan, pred_sigma2_CYG)\n",
    "pred_sigma2_CYG_name = \"CYG L3 Obs Err Variance\"\n",
    "\n",
    "pred_ai = np.ravel(ai_flat)\n",
    "p_low, p_high = np.nanpercentile(pred_ai, [1, 99])\n",
    "pred_ai = np.where((pred_ai < p_low) | (pred_ai > p_high), np.nan, pred_ai)\n",
    "pred_ai_name = \"Aridity Index (P/PET)\"\n",
    "\n",
    "pred_mean_lai = np.ravel(mean_lai_flat)\n",
    "p_low, p_high = np.nanpercentile(pred_mean_lai, [1, 99])\n",
    "pred_mean_lai = np.where((pred_mean_lai < p_low) | (pred_mean_lai > p_high), np.nan, pred_mean_lai)\n",
    "pred_mean_lai_name = \"Mean Annual LAI (m2/m2)\"\n",
    "\n",
    "\n",
    "pred_sigma2_mod0 = np.ravel(S0['sigma2_mod'])[idxs]\n",
    "p_low, p_high = np.nanpercentile(pred_sigma2_mod0, [1, 99])\n",
    "pred_sigma2_mod0 = np.where((pred_sigma2_mod0 < p_low) | (pred_sigma2_mod0 > p_high), np.nan, pred_sigma2_mod0)\n",
    "pred_sigma2_mod0_name = \"CNTL Model Error Variance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030b14c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "#import sys\n",
    "#from pathlib import Path\n",
    "\n",
    "#from read_GEOSldas import read_tilecoord\n",
    "\n",
    "# Load tile coordinates to get tile_id, com_lon, com_lat\n",
    "ftc = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd/DAv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/rc_out/DAv8_M36_cd.ldas_tilecoord.bin'\n",
    "\n",
    "tc = read_tilecoord(ftc)\n",
    "tile_id = np.array(tc['tile_id'], dtype=int)\n",
    "lon_flat = tc['com_lon']\n",
    "lat_flat = tc['com_lat']\n",
    "com_lon = tc['com_lon']\n",
    "com_lat = tc['com_lat']\n",
    "n_tiles = len(tile_id)\n",
    "\n",
    "\n",
    "mosaic_path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/mosaic_veg_typs_fracs\"\n",
    "\n",
    "# --- thresholds & codes ---\n",
    "PRIMARY_THRESH = 49.0\n",
    "BARE_MAX = 10.0          # total < 0.10  -> bare\n",
    "SPARSE_MAX = 20.0        # 0.10 <= total <= 0.20 -> sparse\n",
    "MIXED_MIN = 20.0         # total > 0.20 and primary <= 0.50 -> mixed\n",
    "\n",
    "BARE_CODE   = 0\n",
    "MIXED_CODE  = 7\n",
    "SPARSE_CODE = 8\n",
    "\n",
    "# --- read whitespace-delimited text file ---\n",
    "cols = [\"tile_index\",\"pfaf_code\",\"primary_veg_type\",\"secondary_veg_type\",\n",
    "        \"primary_veg_frac\",\"secondary_veg_frac\",\"canopy_height\",\"ASCATz0\"]\n",
    "\n",
    "records = []\n",
    "with open(mosaic_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        if len(parts) != 8:\n",
    "            parts = parts[-8:]  # keep the last 8 fields if a leading counter exists\n",
    "        ti, pf, pty, sty = map(int, parts[:4])\n",
    "        pfra, sfra, canh, z0 = map(float, parts[4:])\n",
    "        records.append((ti, pf, pty, sty, pfra, sfra, canh, z0))\n",
    "\n",
    "df = pd.DataFrame(records, columns=cols).set_index(\"tile_index\")\n",
    "\n",
    "# --- align to tile_id order ---\n",
    "sub = df.reindex(tile_id)\n",
    "\n",
    "p_type = sub[\"primary_veg_type\"].astype(\"float\")\n",
    "p_frac = sub[\"primary_veg_frac\"]\n",
    "s_frac = sub[\"secondary_veg_frac\"]\n",
    "tot_frac = p_frac + s_frac\n",
    "\n",
    "veg_code = np.full(len(sub), np.nan)\n",
    "\n",
    "# Rule A: bare if total < 0.10\n",
    "mask_bare = tot_frac < BARE_MAX\n",
    "veg_code[mask_bare] = BARE_CODE\n",
    "\n",
    "# Rule B: sparse if 0.10 <= total <= 0.20\n",
    "mask_sparse = (~mask_bare) & (tot_frac <= SPARSE_MAX)\n",
    "veg_code[mask_sparse] = SPARSE_CODE\n",
    "\n",
    "# Rule C: primary type if primary > 0.50 (and not bare/sparse)\n",
    "mask_primary = np.isnan(veg_code) & (p_frac > PRIMARY_THRESH)\n",
    "veg_code[mask_primary] = p_type[mask_primary]\n",
    "\n",
    "# Rule D: mixed if total > 0.20 and primary <= 0.50 (and not already set)\n",
    "mask_mixed = np.isnan(veg_code) & (tot_frac > MIXED_MIN) & (p_frac <= PRIMARY_THRESH)\n",
    "veg_code[mask_mixed] = MIXED_CODE\n",
    "\n",
    "# Fallback: any remaining (e.g., missing tiles) -> sparse (or choose another)\n",
    "veg_code[np.isnan(veg_code)] = SPARSE_CODE\n",
    "\n",
    "veg_type_out = veg_code.astype(int)\n",
    "total_fraction = tot_frac.fillna(0.0).to_numpy()\n",
    "\n",
    "# Outputs:\n",
    "#  - veg_type_out: integer array aligned with tile_id (1–6 from file, plus 7=mixed, 8=sparse, 0=bare)\n",
    "#  - total_fraction: float array aligned with tile_id (primary + secondary)\n",
    "\n",
    "print(len(veg_type_out), veg_type_out)\n",
    "\n",
    "print(\"minimum primary fraction:\", np.nanmin(p_frac))\n",
    "print(\"minimum primary + secondary fraction:\", np.nanmin(total_fraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663fd690",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import cartopy.crs as ccrs\n",
    "#import cartopy.feature as cfeature\n",
    "\n",
    "lat = np.asarray(com_lat)\n",
    "lon = np.asarray(com_lon)\n",
    "\n",
    "# bring longitudes to [-180, 180]\n",
    "lon = np.where(lon > 180.0, lon - 360.0, lon)\n",
    "\n",
    "# ---- labels for legend (codes from your mosaic definition + mixed/sparse/bare) ----\n",
    "label_map = {\n",
    "    0: \"Bare\",\n",
    "    1: \"Broadleaf Evergreen\",\n",
    "    2: \"Broadleaf Deciduous\",\n",
    "    3: \"Needleleaf\",\n",
    "    4: \"Grassland\",\n",
    "    5: \"Broadleaf Shrubs\",\n",
    "    6: \"Dwarf Trees\",\n",
    "    7: \"Mixed\",\n",
    "    8: \"Sparse\",\n",
    "}\n",
    "\n",
    "# only plot classes that appear\n",
    "classes_present = np.unique(veg_type_out[np.isfinite(veg_type_out)])\n",
    "\n",
    "# # ---- figure ----\n",
    "# proj = ccrs.PlateCarree()\n",
    "# fig = plt.figure(figsize=(10, 6))\n",
    "# ax = plt.axes(projection=proj)\n",
    "\n",
    "# # set extent with small padding\n",
    "# lat_min, lat_max = np.nanmin(lat), np.nanmax(lat)\n",
    "# lon_min, lon_max = np.nanmin(lon), np.nanmax(lon)\n",
    "# dlat = max(2.0, 0.05 * (lat_max - lat_min + 1e-6))\n",
    "# dlon = max(2.0, 0.05 * (lon_max - lon_min + 1e-6))\n",
    "# ax.set_extent([lon_min - dlon, lon_max + dlon, lat_min - dlat, lat_max + dlat], crs=proj)\n",
    "\n",
    "# # map features\n",
    "# ax.add_feature(cfeature.COASTLINE, linewidth=0.6)\n",
    "# ax.add_feature(cfeature.BORDERS, linewidth=0.4)\n",
    "# gl = ax.gridlines(draw_labels=True, x_inline=False, y_inline=False, linewidth=0.3)\n",
    "# gl.top_labels = False\n",
    "# gl.right_labels = False\n",
    "\n",
    "# # plot each class as its own scatter (lets Matplotlib assign distinct default colors)\n",
    "# handles = []\n",
    "# labels = []\n",
    "# for code in classes_present:\n",
    "#     mask = veg_type_out == code\n",
    "#     if not np.any(mask):\n",
    "#         continue\n",
    "#     sc = ax.scatter(lon[mask], lat[mask], s=10, transform=proj, label=label_map.get(int(code), f\"Class {int(code)}\"))\n",
    "#     handles.append(sc)\n",
    "#     labels.append(label_map.get(int(code), f\"Class {int(code)}\"))\n",
    "\n",
    "# # legend\n",
    "# leg = ax.legend(handles, labels, title=\"Vegetation Type\", loc=\"lower left\", frameon=True, title_fontsize=9)\n",
    "\n",
    "# ax.set_title(\"Primary Vegetation Type (with Mixed/Sparse/Bare) for Experiment Tiles\", pad=10)\n",
    "# plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a27f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "def box_by_veg(y, yname):\n",
    "    label_map = {\n",
    "        0: \"Bare\", 1: \"Broadleaf Evergreen\", 2: \"Broadleaf Deciduous\",\n",
    "        3: \"Needleleaf\", 4: \"Grassland\", 5: \"Broadleaf Shrubs\",\n",
    "        6: \"Dwarf Trees\", 7: \"Mixed\", 8: \"Sparse\",\n",
    "    }\n",
    "    order = [1,2,3,4,5,6,7,8,0]  # tweak if you like\n",
    "    data, labels = [], []\n",
    "    for k in order:\n",
    "        sel = np.isfinite(veg_type_out) & (veg_type_out == k) & np.isfinite(y)\n",
    "        if sel.any():\n",
    "            data.append(y[sel])\n",
    "            labels.append(f\"{label_map[k]} (n={sel.sum():,})\")\n",
    "    plt.figure(figsize=(11,4))\n",
    "    plt.boxplot(data, labels=labels, showfliers=True)\n",
    "    plt.axhline(0, ls=\"--\", lw=1)\n",
    "    plt.title(yname)\n",
    "    plt.xticks(rotation=20, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    save_fig(plt.gcf(), \"figure_10\")\n",
    "    plt.show()\n",
    "\n",
    "#box_by_veg(target_dR2, target_dR2_name)\n",
    "#box_by_veg(target_pct_sig2, target_pct_sig2_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1601b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs assumed to exist:\n",
    "#   pred_ai, pred_ai_name\n",
    "#   pred_mean_lai, pred_mean_lai_name\n",
    "#   pred_mean_greeness, pred_mean_greeness_name\n",
    "#   target_dR2, target_dR2_name\n",
    "#   target_pct_sig2, target_pct_sig2_name\n",
    "\n",
    "def bin_and_plot(predictor, predictor_name, targets, q=5, dropna=True,\n",
    "                 bins=None, labels=None, include_lowest=True, right=True):\n",
    "    \"\"\"\n",
    "    Bin a predictor and plot target distributions per bin.\n",
    "\n",
    "    If `bins` is provided (list-like), uses fixed bins via pd.cut.\n",
    "    Otherwise, uses quantile bins via pd.qcut with q quantiles.\n",
    "\n",
    "    targets = list of (target_array, target_name) tuples.\n",
    "    \"\"\"\n",
    "    # assemble DataFrame\n",
    "    df = pd.DataFrame({predictor_name: predictor})\n",
    "    for t_arr, t_name in targets:\n",
    "        df[t_name] = t_arr\n",
    "\n",
    "    # clean NaNs/infs\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    if dropna:\n",
    "        df = df.dropna(subset=[predictor_name])\n",
    "    if df.empty:\n",
    "        print(f\"{predictor_name}: no valid rows after dropna.\")\n",
    "        return\n",
    "\n",
    "    # choose binning method\n",
    "    if bins is not None:\n",
    "        # fixed bins\n",
    "        df[\"bin\"] = pd.cut(df[predictor_name], bins=bins, labels=labels,\n",
    "                           include_lowest=include_lowest, right=right)\n",
    "        bin_order = df[\"bin\"].cat.categories\n",
    "        bin_desc = f\"fixed bins ({len(bin_order)})\"\n",
    "    else:\n",
    "        # quantile bins; reduce q if duplicates happen\n",
    "        q_use = q\n",
    "        while True:\n",
    "            try:\n",
    "                df[\"bin\"] = pd.qcut(df[predictor_name], q=q_use, duplicates=\"drop\")\n",
    "                break\n",
    "            except ValueError:\n",
    "                q_use -= 1\n",
    "                if q_use < 2:\n",
    "                    df[\"bin\"] = pd.cut(df[predictor_name], bins=1)\n",
    "                    break\n",
    "        bin_order = df[\"bin\"].cat.categories\n",
    "        bin_desc = f\"quantile bins (q={q_use})\"\n",
    "\n",
    "    # per-target plots and summaries\n",
    "    for t_arr, t_name in targets:\n",
    "        desc = (df.groupby(\"bin\")[t_name]\n",
    "                  .agg(count=\"count\",\n",
    "                       median=lambda x: np.nanmedian(x),\n",
    "                       mean=\"mean\",\n",
    "                       std=\"std\",\n",
    "                       q25=lambda x: np.nanpercentile(x, 25),\n",
    "                       q75=lambda x: np.nanpercentile(x, 75)))\n",
    "        print(f\"\\n=== {t_name} by {predictor_name} {bin_desc} ===\")\n",
    "        print(desc)\n",
    "\n",
    "        # prepare boxplot data & labels\n",
    "        data, xlabels = [], []\n",
    "        for b in bin_order:\n",
    "            vals = df.loc[df[\"bin\"] == b, t_name].dropna().values\n",
    "            data.append(vals)\n",
    "            xlabels.append(f\"{b}\\n(n={len(vals):,})\")\n",
    "\n",
    "        # plot\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.boxplot(data, labels=xlabels, showfliers=True)\n",
    "        plt.axhline(0.0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{t_name} by {predictor_name} — {bin_desc}\")\n",
    "        plt.xticks(rotation=15, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        save_fig(plt.gcf(), \"figure_11\")\n",
    "        plt.show()\n",
    "     \n",
    "\n",
    "\n",
    "targets_list = [\n",
    "    (target_dR2, target_dR2_name),\n",
    "    (target_pct_sig2, target_pct_sig2_name),\n",
    "]\n",
    "\n",
    "# 1) LAI with *fixed* bins (rounded, physically meaningful)\n",
    "lai_bins   = [0.0, 0.10, 0.50, 1.30, 2.60, np.inf]\n",
    "lai_labels = [\"0–0.10\", \"0.10–0.50\", \"0.50–1.30\", \"1.30–2.60\", \">2.60\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab9829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-panel: Δ anomaly R (SMPL3 top, ASCL4 bottom) with discrete colorbars (pcolormesh)\n",
    "paths = [\n",
    "    (DATA_DIR / 'CYGNSS_Experiments/Evaluation/IVs/Rdiff_DAv8_M36_cd_minus_OLv8_M36_cd_SMPL3.mat', 'Δ anomaly R with SMPL3', '(a)'),\n",
    "    (DATA_DIR / 'CYGNSS_Experiments/Evaluation/IVs/Rdiff_DAv8_M36_cd_minus_OLv8_M36_cd_ASCL4.mat', 'Δ anomaly R with ASCL4', '(b)')\n",
    "]\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "vmin, vmax = -0.4, 0.4\n",
    "edges = np.linspace(vmin, vmax, 21)\n",
    "cmap = get_cmap('RdBu_r', len(edges)-1)\n",
    "norm = BoundaryNorm(edges, cmap.N)\n",
    "lats_ease, lons_ease = load_ease_grid(); lats_row, lons_col = lats_ease[:,1], lons_ease[1,:]\n",
    "lon_grid, lat_grid = np.meshgrid(lons_col, lats_row)\n",
    "map_array = None\n",
    "for ax, (path, label, lab) in zip(axes, paths):\n",
    "    mat = sio.loadmat(path)\n",
    "    rdiff = np.squeeze(mat['Rdiff_vector'])\n",
    "    lons = np.squeeze(mat['lons'])\n",
    "    lats = np.squeeze(mat['lats'])\n",
    "    mean_val = np.nanmean(rdiff); std_val = np.nanstd(rdiff)\n",
    "    if map_array is None:\n",
    "        map_array = np.empty([len(lons), 3]); map_array.fill(np.nan)\n",
    "        map_array[:,1] = lons; map_array[:,2] = lats\n",
    "    map_array[:,0] = rdiff\n",
    "    grid = build_ease_grid_mapping(map_array, lats_row, lons_col)\n",
    "    sc = ax.pcolormesh(lon_grid, lat_grid, grid, cmap=cmap, norm=norm, transform=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "    ax.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "    ax.set_title(f'CYG_DA minus CNTL: Surface Soil Moisture Skill ({label}) (Mean: {mean_val:.2g} ± {std_val:.2g})')\n",
    "    ax.text(0.02, 0.02, lab, transform=ax.transAxes, va='bottom', ha='left')\n",
    "    ax.tick_params(labelbottom=False, labelleft=False)\n",
    "\n",
    "cax = fig.add_axes([0.25, 0.05, 0.50, 0.02])\n",
    "cbar = fig.colorbar(sc, cax=cax, orientation='horizontal')\n",
    "cbar.set_label('Δ anomaly R')\n",
    "cbar.set_ticks(edges[::5])\n",
    "cbar.ax.set_xticklabels([f\"{t:.2f}\" for t in edges[::5]])\n",
    "fig.tight_layout(rect=(0, 0.08, 1, 1))\n",
    "save_fig(plt.gcf(), \"figure_12\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57317d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3x1: Vegetation type, Mean LAI, Aridity Index\n",
    "label_map = {0:\"Bare\",1:\"BL Everg\",2:\"BL Decid\",3:\"Needleleaf\",4:\"Grassland\",5:\"BL Shrubs\",6:\"Dwarf Trees\",7:\"Mixed\",8:\"Sparse\"}\n",
    "classes_present = np.unique(veg_type_out[np.isfinite(veg_type_out)])\n",
    "veg_colors = ['lightgray','forestgreen','olive','darkgreen','goldenrod','peru','darkolivegreen','plum','tan']\n",
    "veg_cmap = ListedColormap(veg_colors[:len(label_map)])\n",
    "veg_bounds = np.arange(-0.5, 9.5, 1.0)\n",
    "\n",
    "# Flatten AI/LAI grids\n",
    "lon_flat_ai = np.squeeze(lon)\n",
    "lat_flat_ai = np.squeeze(lat)\n",
    "ai_flat = np.squeeze(ai)\n",
    "mean_lai_flat = np.squeeze(mean_lai_clim)\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(12, 10), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# Vegetation panel\n",
    "a = axes[0]\n",
    "lon_plot = np.where(com_lon > 180.0, com_lon - 360.0, com_lon)\n",
    "sc0 = a.scatter(lon_plot, com_lat, c=veg_type_out, cmap=veg_cmap, norm=BoundaryNorm(veg_bounds, veg_cmap.N), s=10, edgecolor='none', transform=ccrs.PlateCarree())\n",
    "a.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "a.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "a.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "a.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "a.set_title('Primary Vegetation Type')\n",
    "a.text(0.02, 0.02, '(a)', transform=a.transAxes, va='bottom', ha='left')\n",
    "a.tick_params(labelbottom=False, labelleft=False)\n",
    "cbar0 = fig.colorbar(sc0, ax=a, orientation='horizontal', pad=0.04, fraction=0.046, boundaries=veg_bounds)\n",
    "# cbar0.set_label('Veg Type')\n",
    "cbar0.set_ticks(list(label_map.keys()))\n",
    "cbar0.set_ticklabels([label_map[k] for k in label_map])\n",
    "for label in cbar0.ax.get_xticklabels():\n",
    "    label.set_rotation(45)\n",
    "    label.set_ha('right')\n",
    "\n",
    "# Mean LAI panel\n",
    "ax1 = axes[1]\n",
    "vmin_lai, vmax_lai = 0.0, 6.0\n",
    "edges_lai = np.linspace(vmin_lai, vmax_lai, 21)\n",
    "cmap_lai = get_cmap('YlGn', len(edges_lai)-1)\n",
    "norm_lai = BoundaryNorm(edges_lai, cmap_lai.N)\n",
    "# attempt reshape to 2D if possible, else keep 1D scatter\n",
    "try:\n",
    "    grid_shape = mean_lai_clim.shape\n",
    "    if len(grid_shape)==2:\n",
    "        lon_grid = lon_flat_ai.reshape(grid_shape)\n",
    "        lat_grid = lat_flat_ai.reshape(grid_shape)\n",
    "        data_grid = mean_lai_flat.reshape(grid_shape)\n",
    "        sc1 = ax1.pcolormesh(lon_grid, lat_grid, data_grid, cmap=cmap_lai, norm=norm_lai, transform=ccrs.PlateCarree())\n",
    "    else:\n",
    "        sc1 = ax1.scatter(lon_flat_ai, lat_flat_ai, c=mean_lai_flat, cmap=cmap_lai, norm=norm_lai, s=10, edgecolor='none', transform=ccrs.PlateCarree())\n",
    "except Exception:\n",
    "    sc1 = ax1.scatter(lon_flat_ai, lat_flat_ai, c=mean_lai_flat, cmap=cmap_lai, norm=norm_lai, s=10, edgecolor='none', transform=ccrs.PlateCarree())\n",
    "ax1.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax1.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "ax1.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "ax1.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "ax1.set_title('Mean Annual Leaf Area Index (LAI)')\n",
    "#ax1.text(0.02, 0.02, '(b)', transform=ax1.transAxes, va='bottom', ha='left')\n",
    "ax1.tick_params(labelbottom=False, labelleft=False)\n",
    "cbar1 = fig.colorbar(sc1, ax=ax1, orientation='horizontal', pad=0.04, fraction=0.046)\n",
    "cbar1.set_label('(m2/m2)')\n",
    "cbar1.set_ticks(edges_lai[::5])\n",
    "cbar1.ax.set_xticklabels([f\"{t:.1f}\" for t in edges_lai[::5]])\n",
    "\n",
    "# Aridity panel\n",
    "ax2 = axes[2]\n",
    "a_edges = np.array([0.00,0.05,0.10,0.20,0.30,0.40,0.50,0.60,0.70,0.80,0.90,1.00,1.10,1.20,1.30,1.40,1.50,1.75,2.00,3.00,5.00,10.00])\n",
    "cmap_ai = get_cmap('Spectral', len(a_edges)-1)\n",
    "norm_ai = BoundaryNorm(a_edges, cmap_ai.N)\n",
    "try:\n",
    "    grid_shape = ai.shape\n",
    "    if len(grid_shape)==2:\n",
    "        lon_grid = lon_flat_ai.reshape(grid_shape)\n",
    "        lat_grid = lat_flat_ai.reshape(grid_shape)\n",
    "        data_grid = ai_flat.reshape(grid_shape)\n",
    "        sc2 = ax2.pcolormesh(lon_grid, lat_grid, data_grid, cmap=cmap_ai, norm=norm_ai, transform=ccrs.PlateCarree())\n",
    "    else:\n",
    "        sc2 = ax2.scatter(lon_flat_ai, lat_flat_ai, c=ai_flat, cmap=cmap_ai, norm=norm_ai, s=10, edgecolor='none', transform=ccrs.PlateCarree())\n",
    "except Exception:\n",
    "    sc2 = ax2.scatter(lon_flat_ai, lat_flat_ai, c=ai_flat, cmap=cmap_ai, norm=norm_ai, s=10, edgecolor='none', transform=ccrs.PlateCarree())\n",
    "ax2.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax2.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "ax2.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "ax2.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "ax2.set_title('Mean Annual Aridity Index (P/PET)')\n",
    "#ax2.text(0.02, 0.02, '(c)', transform=ax2.transAxes, va='bottom', ha='left')\n",
    "ax2.tick_params(labelbottom=False, labelleft=False)\n",
    "cbar2 = fig.colorbar(sc2, ax=ax2, orientation='horizontal', pad=0.04, fraction=0.046, boundaries=a_edges)\n",
    "cbar2.set_label('(P/PET)')\n",
    "# set tick labels roughly every few bins\n",
    "positions = a_edges[::5]\n",
    "cbar2.set_ticks(positions)\n",
    "cbar2.ax.set_xticklabels([f\"{t:.2f}\" for t in positions])\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_13\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4705bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combined 6x1 boxplots with cross-masked targets (same n for ΔR² and %Δσ²)\n",
    "import pandas as pd\n",
    "\n",
    "veg_labels = {0: \"Bare\", 1: \"Broadleaf Evergreen\", 2: \"Broadleaf Deciduous\", 3: \"Needleleaf\", 4: \"Grassland\", 5: \"Broadleaf Shrubs\", 6: \"Dwarf Trees\", 7: \"Mixed\", 8: \"Sparse\"}\n",
    "veg_order = [1,2,3,4,5,6,7,8,0]\n",
    "\n",
    "veg_vec = veg_type_out.flatten()\n",
    "tr_dR2 = target_dR2\n",
    "tr_pct = target_pct_sig2\n",
    "lai_vals = np.clip(mean_lai_flat, 0, None)\n",
    "ai_vals = np.clip(ai_flat, 0, None)\n",
    "\n",
    "# align lengths and build common mask\n",
    "min_len = min(len(veg_vec), len(tr_dR2), len(tr_pct), len(lai_vals), len(ai_vals))\n",
    "veg_vec = veg_vec[:min_len]; tr_dR2 = tr_dR2[:min_len]; tr_pct = tr_pct[:min_len]; lai_vals = lai_vals[:min_len]; ai_vals = ai_vals[:min_len]\n",
    "common_mask = np.isfinite(veg_vec) & np.isfinite(tr_dR2) & np.isfinite(tr_pct) & np.isfinite(lai_vals) & np.isfinite(ai_vals)\n",
    "veg_vec = veg_vec[common_mask]; tr_dR2 = tr_dR2[common_mask]; tr_pct = tr_pct[common_mask]; lai_vals = lai_vals[common_mask]; ai_vals = ai_vals[common_mask]\n",
    "\n",
    "# fig, axes = plt.subplots(6, 1, figsize=(10, 22))\n",
    "\n",
    "# # Helper to make a boxplot for categorical predictor\n",
    "\n",
    "# def box_cat(ax, cats, data, title, ylabel, labels_map=None, order=None):\n",
    "#     data_list=[]; labels=[]\n",
    "#     if order is None:\n",
    "#         order = np.unique(cats[np.isfinite(cats)])\n",
    "#     for k in order:\n",
    "#         sel = np.isfinite(cats) & (cats==k) & np.isfinite(data)\n",
    "#         if sel.any():\n",
    "#             data_list.append(data[sel])\n",
    "#             lab = labels_map.get(k, str(k)) if labels_map else str(k)\n",
    "#             labels.append(f\"{lab} (n={sel.sum():,})\")\n",
    "#     ax.boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker': 'o'})\n",
    "#     ax.axhline(0, ls='--', lw=1, color='gray')\n",
    "#     ax.set_title(title)\n",
    "#     ax.set_ylabel(ylabel)\n",
    "#     for tick in ax.get_xticklabels():\n",
    "#         tick.set_rotation(15)\n",
    "\n",
    "# # Veg panels\n",
    "# box_cat(axes[0], veg_vec, tr_dR2, 'Δ R² by Vegetation Class', 'Δ R² (CYG_DA - CNTL)', veg_labels, veg_order)\n",
    "# box_cat(axes[1], veg_vec, tr_pct, '% Δ σ² by Vegetation Class', '% Δ σ² ((CYG_DA - CNTL) / CNTL)', veg_labels, veg_order)\n",
    "\n",
    "# # LAI bins\n",
    "# lai_bins   = [0.0, 0.10, 0.50, 1.30, 2.60, np.inf]\n",
    "# lai_df = pd.DataFrame({'lai': lai_vals, 'dR2': tr_dR2, 'pct': tr_pct}).replace([np.inf,-np.inf], np.nan).dropna(subset=['lai'])\n",
    "# lai_df['bin'] = pd.cut(lai_df['lai'], bins=lai_bins, include_lowest=True)\n",
    "# for ax, col, title, ylabel in [(axes[2], 'dR2', 'Δ R² by Leaf Area Index', 'Δ R² (CYG_DA - CNTL)'), (axes[3], 'pct', '% Δ σ² by Leaf Area Index', '% Δ σ² ((CYG_DA - CNTL) / CNTL)')]:\n",
    "#     data_list=[]; labels=[]\n",
    "#     for lbl in lai_df['bin'].cat.categories:\n",
    "#         vals = lai_df.loc[lai_df['bin']==lbl, col].dropna().values\n",
    "#         left = max(0, lbl.left); right = lbl.right if lbl.right != float('inf') else np.inf\n",
    "#         lab = f'{left:.2g}–{right:.2g}' if right != np.inf else f'>{left:.2g}'\n",
    "#         data_list.append(vals)\n",
    "#         labels.append(f\"{lab} (n={len(vals):,})\")\n",
    "#     ax.boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker': 'o'})\n",
    "#     ax.axhline(0, ls='--', lw=1, color='gray')\n",
    "#     ax.set_title(title)\n",
    "#     ax.set_ylabel(ylabel)\n",
    "#     for tick in ax.get_xticklabels():\n",
    "#         tick.set_rotation(20)\n",
    "\n",
    "# # Aridity quantile bins (q=5)\n",
    "# ai_df = pd.DataFrame({'ai': ai_vals, 'dR2': tr_dR2, 'pct': tr_pct}).replace([np.inf,-np.inf], np.nan).dropna(subset=['ai'])\n",
    "# try:\n",
    "#     ai_df['bin'] = pd.qcut(ai_df['ai'], q=5, duplicates='drop')\n",
    "# except Exception:\n",
    "#     ai_df['bin'] = pd.cut(ai_df['ai'], bins=5)\n",
    "# for ax, col, title, ylabel in [(axes[4], 'dR2', 'Δ R² by Aridity Index', 'Δ R² (CYG_DA - CNTL)'), (axes[5], 'pct', '% Δ σ² by Aridity Index', '% Δ σ² ((CYG_DA - CNTL) / CNTL)')]:\n",
    "#     data_list=[]; labels=[]\n",
    "#     for lbl in ai_df['bin'].cat.categories:\n",
    "#         vals = ai_df.loc[ai_df['bin']==lbl, col].dropna().values\n",
    "#         left = max(0, lbl.left); right = lbl.right if lbl.right != float('inf') else np.inf\n",
    "#         lab = f'{left:.2g}–{right:.2g}' if right != np.inf else f'>{left:.2g}'\n",
    "#         data_list.append(vals)\n",
    "#         labels.append(f\"{lab} (n={len(vals):,})\")\n",
    "#     ax.boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker': 'o'})\n",
    "#     ax.axhline(0, ls='--', lw=1, color='gray')\n",
    "#     ax.set_title(title)\n",
    "#     ax.set_ylabel(ylabel)\n",
    "#     for tick in ax.get_xticklabels():\n",
    "#         tick.set_rotation(20)\n",
    "\n",
    "\n",
    "# # add panel labels\n",
    "# for ax, lab in zip(axes, ['(a)','(b)','(c)','(d)','(e)','(f)']):\n",
    "#     ax.text(0.02, 0.95, lab, transform=ax.transAxes, va='top', ha='left')\n",
    "\n",
    "# # hide x ticklabels on R² panels\n",
    "# for idx in [0,2,4]:\n",
    "#     axes[idx].tick_params(labelbottom=False)\n",
    "\n",
    "# plt.tight_layout()\n",
    "# # bring (b) closer to (a), (d) closer to (c), (f) closer to (e)\n",
    "# pos_list = [ax.get_position() for ax in axes]\n",
    "# offsets = [0.0, 0.02, 0.0, 0.02, 0.0, 0.02]\n",
    "# for ax, pos, off in zip(axes, pos_list, offsets):\n",
    "#     ax.set_position([pos.x0, pos.y0 + off, pos.width, pos.height])\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf8c057",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute inverted %Δσ² (CNTL-EXPT) so positive = better\n",
    "pct_sig2_inv = -pct_sig2\n",
    "pct_sig2_inv_vec = pct_sig2_inv.flatten()\n",
    "pct_sig2_inv_masked = np.where(Mvalid, pct_sig2_inv, np.nan)\n",
    "try:\n",
    "    target_pct_sig2_inv = -target_pct_sig2\n",
    "except Exception:\n",
    "    target_pct_sig2_inv = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa71654a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-panel: Δ R²_mod and % Δ σ²_mod (CNTL-EXPT)\n",
    "vals = [\n",
    "    (dR2_mod, 'CYG_DA - CNTL: Surface Soil Moisture Skill Δ R²', 'RdBu', (-0.4, 0.4), '(a)', '-'),\n",
    "    (pct_sig2_inv, 'CNTL - CYG_DA: Surface Soil Moisture Skill % Δ σ²', 'RdBu', (-100.0, 100.0), '(b)', '%')\n",
    "]\n",
    "lats_ease, lons_ease = load_ease_grid(); lats_row, lons_col = lats_ease[:,1], lons_ease[1,:]\n",
    "lon_grid, lat_grid = np.meshgrid(lons_col, lats_row)\n",
    "map_array_tmp = np.empty([lons.size, 3]); map_array_tmp.fill(np.nan); map_array_tmp[:,1]=lons.flatten(); map_array_tmp[:,2]=lats.flatten()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "for ax, (data_grid, title, cmap_name, clim, lab, units) in zip(axes, vals):\n",
    "    vmin, vmax = clim\n",
    "    edges = np.linspace(vmin, vmax, 21)\n",
    "    cmap = get_cmap(cmap_name, len(edges)-1)\n",
    "    norm = BoundaryNorm(edges, cmap.N)\n",
    "    data_flat = data_grid.flatten()\n",
    "    mean_val = np.nanmean(data_flat); std_val = np.nanstd(data_flat)\n",
    "    map_array_tmp[:,0] = data_flat\n",
    "    grid = build_ease_grid_mapping(map_array_tmp, lats_row, lons_col)\n",
    "    sc = ax.pcolormesh(lon_grid, lat_grid, grid, cmap=cmap, norm=norm, transform=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "    ax.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "    ax.set_title(f\"{title} (Mean: {mean_val:.3g} ± {std_val:.3g})\")\n",
    "    ax.text(0.02, 0.02, lab, transform=ax.transAxes, va='bottom', ha='left')\n",
    "    ax.tick_params(labelbottom=False, labelleft=False)\n",
    "    cbar = fig.colorbar(sc, ax=ax, orientation='horizontal', pad=0.04, fraction=0.046)\n",
    "    cbar.set_label(units)\n",
    "    cbar.set_ticks(edges[::5])\n",
    "    cbar.ax.set_xticklabels([f\"{t:.2f}\" if units=='-' else f\"{t:.0f}\" for t in edges[::5]])\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_14\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0a130d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Δ anomaly R with ASCL4 and map to TC grid\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "ascl4_path = DATA_DIR / 'CYGNSS_Experiments/Evaluation/IVs/Rdiff_DAv8_M36_cd_minus_OLv8_M36_cd_ASCL4.mat'\n",
    "mat_ascl4 = sio.loadmat(ascl4_path)\n",
    "rdiff_ascl4 = np.squeeze(mat_ascl4['Rdiff_vector'])\n",
    "lon_ascl4 = np.squeeze(mat_ascl4['lons'])\n",
    "lat_ascl4 = np.squeeze(mat_ascl4['lats'])\n",
    "\n",
    "src_pts = np.column_stack((lon_ascl4, lat_ascl4))\n",
    "tgt_pts = np.column_stack((pred_lon_flat, pred_lat_flat))  # TC grid\n",
    "kd = cKDTree(src_pts)\n",
    "_, nn_idx = kd.query(tgt_pts, k=1)\n",
    "rdiff_ascl4_tc = rdiff_ascl4[nn_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5caefb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3x1 boxplots: Δ anomaly R with ASCL4 (mapped to TC grid)\n",
    "import pandas as pd\n",
    "\n",
    "veg_vec = veg_type_out.flatten()\n",
    "target_rdiff = rdiff_ascl4_tc\n",
    "lai_vals = np.clip(mean_lai_flat, 0, None)\n",
    "ai_vals = np.clip(ai_flat, 0, None)\n",
    "\n",
    "min_len = min(len(veg_vec), len(target_rdiff), len(lai_vals), len(ai_vals))\n",
    "veg_vec = veg_vec[:min_len]\n",
    "target_rdiff = target_rdiff[:min_len]\n",
    "lai_vals = lai_vals[:min_len]\n",
    "ai_vals = ai_vals[:min_len]\n",
    "\n",
    "mask = np.isfinite(veg_vec) & np.isfinite(target_rdiff) & np.isfinite(lai_vals) & np.isfinite(ai_vals)\n",
    "veg_vec = veg_vec[mask]\n",
    "target_rdiff = target_rdiff[mask]\n",
    "lai_vals = lai_vals[mask]\n",
    "ai_vals = ai_vals[mask]\n",
    "\n",
    "fig, axes = plt.subplots(3, 1, figsize=(10, 12))\n",
    "\n",
    "# Vegetation\n",
    "veg_labels = {0: \"Bare\", 1: \"Broadleaf Evergreen\", 2: \"Broadleaf Deciduous\", 3: \"Needleleaf\", 4: \"Grassland\", 5: \"Broadleaf Shrubs\", 6: \"Dwarf Trees\", 7: \"Mixed\", 8: \"Sparse\"}\n",
    "veg_order = [1,2,3,4,5,6,7,8,0]\n",
    "data_list=[]; labels=[]\n",
    "for k in veg_order:\n",
    "    sel = (veg_vec==k)\n",
    "    if sel.any():\n",
    "        data_list.append(target_rdiff[sel])\n",
    "        labels.append(f\"{veg_labels[k]} (n={sel.sum():,})\")\n",
    "axes[0].boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker':'o'})\n",
    "axes[0].axhline(0, ls='--', lw=1, color='gray')\n",
    "axes[0].set_title('Δ anomaly R (ASCL4) by vegetation class')\n",
    "axes[0].set_ylabel('Δ anomaly R')\n",
    "axes[0].tick_params(labelbottom=True)\n",
    "axes[0].text(0.02, 0.95, '(a)', transform=axes[0].transAxes, va='top', ha='left')\n",
    "for t in axes[0].get_xticklabels():\n",
    "    t.set_rotation(15)\n",
    "\n",
    "# LAI bins\n",
    "lai_bins   = [0.0, 0.10, 0.50, 1.30, 2.60, np.inf]\n",
    "lai_df = pd.DataFrame({'lai': lai_vals, 'rdiff': target_rdiff}).replace([np.inf,-np.inf], np.nan).dropna(subset=['lai'])\n",
    "lai_df['bin'] = pd.cut(lai_df['lai'], bins=lai_bins, include_lowest=True)\n",
    "data_list=[]; labels=[]\n",
    "for lbl in lai_df['bin'].cat.categories:\n",
    "    vals = lai_df.loc[lai_df['bin']==lbl, 'rdiff'].dropna().values\n",
    "    left = max(0, lbl.left); right = lbl.right if lbl.right != float('inf') else np.inf\n",
    "    lab = f'{left:.2g}–{right:.2g}' if right != np.inf else f'>{left:.2g}'\n",
    "    data_list.append(vals)\n",
    "    labels.append(f\"{lab} (n={len(vals):,})\")\n",
    "axes[1].boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker':'o'})\n",
    "axes[1].axhline(0, ls='--', lw=1, color='gray')\n",
    "axes[1].set_title('Δ anomaly R (ASCL4) by LAI bin')\n",
    "axes[1].set_ylabel('Δ anomaly R')\n",
    "axes[1].tick_params(labelbottom=True)\n",
    "axes[1].text(0.02, 0.95, '(b)', transform=axes[1].transAxes, va='top', ha='left')\n",
    "for t in axes[1].get_xticklabels():\n",
    "    t.set_rotation(20)\n",
    "\n",
    "# Aridity quantile bins\n",
    "ai_df = pd.DataFrame({'ai': ai_vals, 'rdiff': target_rdiff}).replace([np.inf,-np.inf], np.nan).dropna(subset=['ai'])\n",
    "try:\n",
    "    ai_df['bin'] = pd.qcut(ai_df['ai'], q=5, duplicates='drop')\n",
    "except Exception:\n",
    "    ai_df['bin'] = pd.cut(ai_df['ai'], bins=5)\n",
    "data_list=[]; labels=[]\n",
    "for lbl in ai_df['bin'].cat.categories:\n",
    "    vals = ai_df.loc[ai_df['bin']==lbl, 'rdiff'].dropna().values\n",
    "    left = max(0, lbl.left); right = lbl.right if lbl.right != float('inf') else np.inf\n",
    "    lab = f'{left:.2g}–{right:.2g}' if right != np.inf else f'>{left:.2g}'\n",
    "    data_list.append(vals)\n",
    "    labels.append(f\"{lab} (n={len(vals):,})\")\n",
    "axes[2].boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker':'o'})\n",
    "axes[2].axhline(0, ls='--', lw=1, color='gray')\n",
    "axes[2].set_title('Δ anomaly R (ASCL4) by Aridity (quantiles)')\n",
    "axes[2].set_ylabel('Δ anomaly R')\n",
    "axes[2].text(0.02, 0.95, '(c)', transform=axes[2].transAxes, va='top', ha='left')\n",
    "for t in axes[2].get_xticklabels():\n",
    "    t.set_rotation(20)\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_15\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0f350",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter: CNTL sigma2_mod aligned to target grid vs ΔR²_mod and %Δσ²_mod\n",
    "sig20_flat = S0[\"sigma2_mod\"].flatten()\n",
    "tr_dR2_al = target_dR2\n",
    "tr_pct_al = target_pct_sig2\n",
    "\n",
    "# Use the existing KDTree mapping index to align to the same grid\n",
    "sig20_al = sig20_flat[idxs]\n",
    "\n",
    "\n",
    "mask = np.isfinite(sig20_al) & np.isfinite(tr_dR2_al) & np.isfinite(tr_pct_al)\n",
    "sig20_al = sig20_al[mask]\n",
    "tr_dR2_al = tr_dR2_al[mask]\n",
    "tr_pct_al = tr_pct_al[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c48a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots: ΔR²_mod and %Δσ²_mod by sigma2_mod quantiles\n",
    "import pandas as pd\n",
    "\n",
    "q = 5  # choose quantile count\n",
    "df_sig = pd.DataFrame({\n",
    "    \"sig20\": sig20_al,\n",
    "    \"dR2\": tr_dR2_al,\n",
    "    \"pct\": tr_pct_al,\n",
    "}).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "try:\n",
    "    df_sig[\"bin\"] = pd.qcut(df_sig[\"sig20\"], q=q, duplicates=\"drop\")\n",
    "except Exception:\n",
    "    df_sig[\"bin\"] = pd.cut(df_sig[\"sig20\"], bins=q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1967cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots: ΔR²_mod and inverted %Δσ²_mod by sigma2_mod quantiles\n",
    "import pandas as pd\n",
    "\n",
    "tr_pct_inv_al = -tr_pct_al  # CNTL - CYG_DA normalized by CNTL\n",
    "\n",
    "q = 5  # choose quantile count\n",
    "df_sig_inv = pd.DataFrame({\n",
    "    \"sig20\": sig20_al,\n",
    "    \"dR2\": tr_dR2_al,\n",
    "    \"pct\": tr_pct_inv_al,\n",
    "}).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "try:\n",
    "    df_sig_inv[\"bin\"] = pd.qcut(df_sig_inv[\"sig20\"], q=q, duplicates=\"drop\")\n",
    "except Exception:\n",
    "    df_sig_inv[\"bin\"] = pd.cut(df_sig_inv[\"sig20\"], bins=q)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(10, 8))\n",
    "for ax, col, title in [\n",
    "    (axes[0], \"dR2\", \"Δ R² (CYG_DA - CNTL) by CNTL Surface Moisture Skill quintiles\"),\n",
    "    (axes[1], \"pct\", \"CNTL Surface Moisture Skill σ² quintiles\"),\n",
    "]:\n",
    "    data, labels = [], []\n",
    "    for lbl in df_sig_inv[\"bin\"].cat.categories:\n",
    "        vals = df_sig_inv.loc[df_sig_inv[\"bin\"] == lbl, col].values\n",
    "        data.append(vals)\n",
    "        labels.append(f\"{lbl.left:.2g}–{lbl.right:.2g} (n={len(vals):,})\")\n",
    "    ax.boxplot(data, labels=labels, showfliers=True, flierprops={\"markersize\": 2, \"marker\": \"o\"})\n",
    "    ax.axhline(0, ls=\"--\", lw=1, color=\"gray\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(\"Δ R² (CYG_DA - CNTL)\" if col == \"dR2\" else \"% Δ σ² ((CNTL - CYG_DA) / CNTL)\")\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(20)\n",
    "    ax.set_xlabel(\"CNTL Surface Soil Moisture Skill σ² (m³/m³)²\")\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_16\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2982f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two 4x1 boxplot figures: include CNTL σ² binning on top (same bins as earlier qcut)\n",
    "import pandas as pd\n",
    "\n",
    "tr_pct_inv_al = -tr_pct_al  # CNTL - CYG_DA normalized by CNTL\n",
    "\n",
    "# Build sigma2 quintile bins (drop infs)\n",
    "df_sig_inv = pd.DataFrame({\n",
    "    \"sig20\": sig20_al,\n",
    "    \"dR2\": tr_dR2_al,\n",
    "    \"pct\": tr_pct_inv_al,\n",
    "}).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "try:\n",
    "    df_sig_inv[\"bin\"] = pd.qcut(df_sig_inv[\"sig20\"], q=5, duplicates=\"drop\")\n",
    "except Exception:\n",
    "    df_sig_inv[\"bin\"] = pd.cut(df_sig_inv[\"sig20\"], bins=5)\n",
    "\n",
    "# Helpers\n",
    "def box_by_bins(ax, df, col, title, ylabel):\n",
    "    data, labels = [], []\n",
    "    for lbl in df[\"bin\"].cat.categories:\n",
    "        vals = df.loc[df[\"bin\"] == lbl, col].values\n",
    "        data.append(vals)\n",
    "        labels.append(f\"{lbl.left:.2g}–{lbl.right:.2g} (n={len(vals):,})\")\n",
    "    ax.boxplot(data, labels=labels, showfliers=True, flierprops={\"markersize\": 3, \"marker\": \"o\"})\n",
    "    ax.axhline(0, ls=\"--\", lw=1, color=\"gray\")\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(20)\n",
    "    ax.set_xlabel(\"CNTL Surface Moisture Skill σ² (m³/m³)²\")\n",
    "\n",
    "def box_cat(ax, cats, data, title, ylabel, labels_map=None, order=None, xrot=15):\n",
    "    data_list=[]; labels=[]\n",
    "    if order is None:\n",
    "        order = np.unique(cats[np.isfinite(cats)])\n",
    "    for k in order:\n",
    "        sel = np.isfinite(cats) & (cats==k) & np.isfinite(data)\n",
    "        if sel.any():\n",
    "            data_list.append(data[sel])\n",
    "            lab = labels_map.get(k, str(k)) if labels_map else str(k)\n",
    "            labels.append(f\"{lab} (n={sel.sum():,})\")\n",
    "    ax.boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker': 'o'})\n",
    "    ax.axhline(0, ls='--', lw=1, color='gray')\n",
    "    ax.set_title(title)\n",
    "    ax.set_ylabel(ylabel)\n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_rotation(xrot)\n",
    "\n",
    "veg_labels = {0: \"Bare\", 1: \"Broadleaf Evergreen\", 2: \"Broadleaf Deciduous\", 3: \"Needleleaf\", 4: \"Grassland\", 5: \"Broadleaf Shrubs\", 6: \"Dwarf Trees\", 7: \"Mixed\", 8: \"Sparse\"}\n",
    "veg_order = [1,2,3,4,5,6,7,8,0]\n",
    "\n",
    "veg_vec = veg_type_out.flatten()\n",
    "lai_vals = np.clip(mean_lai_flat, 0, None)\n",
    "ai_vals = np.clip(ai_flat, 0, None)\n",
    "\n",
    "# common mask to align lengths\n",
    "min_len = min(len(veg_vec), len(tr_dR2), len(tr_pct), len(lai_vals), len(ai_vals))\n",
    "veg_vec = veg_vec[:min_len]; tr_dR2_use = tr_dR2[:min_len]; tr_pct_use = tr_pct[:min_len]; lai_vals = lai_vals[:min_len]; ai_vals = ai_vals[:min_len]\n",
    "mask_common = np.isfinite(veg_vec) & np.isfinite(tr_dR2_use) & np.isfinite(tr_pct_use) & np.isfinite(lai_vals) & np.isfinite(ai_vals)\n",
    "veg_vec = veg_vec[mask_common]; tr_dR2_use = tr_dR2_use[mask_common]; tr_pct_use = tr_pct_use[mask_common]; lai_vals = lai_vals[mask_common]; ai_vals = ai_vals[mask_common]\n",
    "\n",
    "# ΔR² figure\n",
    "fig_r2, axes_r2 = plt.subplots(4, 1, figsize=(10, 16))\n",
    "box_by_bins(axes_r2[0], df_sig_inv, \"dR2\", \"Δ R² (CYG_DA - CNTL) by CNTL σ² quintiles\", \"Δ R² (CYG_DA - CNTL)\")\n",
    "box_cat(axes_r2[1], veg_vec, tr_dR2_use, 'Δ R² by Vegetation Class', 'Δ R² (CYG_DA - CNTL)', veg_labels, veg_order)\n",
    "\n",
    "lai_bins = [0.0, 0.10, 0.50, 1.30, 2.60, np.inf]\n",
    "lai_df = pd.DataFrame({'lai': lai_vals, 'dR2': tr_dR2_use}).replace([np.inf,-np.inf], np.nan).dropna(subset=['lai'])\n",
    "lai_df['bin'] = pd.cut(lai_df['lai'], bins=lai_bins, include_lowest=True)\n",
    "data_list=[]; labels=[]\n",
    "for lbl in lai_df['bin'].cat.categories:\n",
    "    vals = lai_df.loc[lai_df['bin']==lbl, 'dR2'].dropna().values\n",
    "    left = max(0, lbl.left); right = lbl.right if lbl.right != float('inf') else np.inf\n",
    "    lab = f'{left:.2g}–{right:.2g}' if right != np.inf else f'>{left:.2g}'\n",
    "    data_list.append(vals)\n",
    "    labels.append(f\"{lab} (n={len(vals):,})\")\n",
    "axes_r2[2].boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker': 'o'})\n",
    "axes_r2[2].axhline(0, ls='--', lw=1, color='gray')\n",
    "axes_r2[2].set_title('Δ R² by Leaf Area Index')\n",
    "axes_r2[2].set_ylabel('Δ R² (CYG_DA - CNTL)')\n",
    "axes_r2[2].set_xlabel('Leaf Area Index (m²/m²)')\n",
    "for tick in axes_r2[2].get_xticklabels():\n",
    "    tick.set_rotation(20)\n",
    "\n",
    "ai_df = pd.DataFrame({'ai': ai_vals, 'dR2': tr_dR2_use}).replace([np.inf,-np.inf], np.nan).dropna()\n",
    "try:\n",
    "    ai_df['bin'] = pd.qcut(ai_df['ai'], q=5, duplicates='drop')\n",
    "except Exception:\n",
    "    ai_df['bin'] = pd.cut(ai_df['ai'], bins=5)\n",
    "data_list=[]; labels=[]\n",
    "for lbl in ai_df['bin'].cat.categories:\n",
    "    vals = ai_df.loc[ai_df['bin']==lbl, 'dR2'].dropna().values\n",
    "    left = max(0, lbl.left); right = lbl.right if lbl.right != float('inf') else np.inf\n",
    "    lab = f'{left:.2g}–{right:.2g}' if right != np.inf else f'>{left:.2g}'\n",
    "    data_list.append(vals)\n",
    "    labels.append(f\"{lab} (n={len(vals):,})\")\n",
    "axes_r2[3].boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker': 'o'})\n",
    "axes_r2[3].axhline(0, ls='--', lw=1, color='gray')\n",
    "axes_r2[3].set_title('Δ R² by Aridity Index')\n",
    "axes_r2[3].set_ylabel('Δ R² (CYG_DA - CNTL)')\n",
    "axes_r2[3].set_xlabel('Aridity Index (P/PET)')\n",
    "for tick in axes_r2[3].get_xticklabels():\n",
    "    tick.set_rotation(20)\n",
    "\n",
    "for ax, lab in zip(axes_r2, ['(a)','(b)','(c)','(d)']):\n",
    "    ax.text(0.02, 0.95, lab, transform=ax.transAxes, va='top', ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_17\")\n",
    "plt.show()\n",
    "\n",
    "# % Δσ² figure\n",
    "fig_pct, axes_pct = plt.subplots(4, 1, figsize=(10, 16))\n",
    "box_by_bins(axes_pct[0], df_sig_inv, \"pct\", \"% Δ σ² by CNTL σ² quintiles\", \"% Δ σ² ((CNTL - CYG_DA) / CNTL)\")\n",
    "box_cat(axes_pct[1], veg_vec, tr_pct_use, '% Δ σ² by Vegetation Class', '% Δ σ² ((CNTL - CYG_DA) / CNTL)', veg_labels, veg_order)\n",
    "\n",
    "lai_df = pd.DataFrame({'lai': lai_vals, 'pct': tr_pct_use}).replace([np.inf,-np.inf], np.nan).dropna(subset=['lai'])\n",
    "lai_df['bin'] = pd.cut(lai_df['lai'], bins=lai_bins, include_lowest=True)\n",
    "data_list=[]; labels=[]\n",
    "for lbl in lai_df['bin'].cat.categories:\n",
    "    vals = lai_df.loc[lai_df['bin']==lbl, 'pct'].dropna().values\n",
    "    left = max(0, lbl.left); right = lbl.right if lbl.right != float('inf') else np.inf\n",
    "    lab = f'{left:.2g}–{right:.2g}' if right != np.inf else f'>{left:.2g}'\n",
    "    data_list.append(vals)\n",
    "    labels.append(f\"{lab} (n={len(vals):,})\")\n",
    "axes_pct[2].boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker': 'o'})\n",
    "axes_pct[2].axhline(0, ls='--', lw=1, color='gray')\n",
    "axes_pct[2].set_title('% Δ σ² by Leaf Area Index')\n",
    "axes_pct[2].set_ylabel('% Δ σ² ((CNTL - CYG_DA) / CNTL)')\n",
    "axes_pct[2].set_xlabel('Leaf Area Index (m²/m²)')\n",
    "for tick in axes_pct[2].get_xticklabels():\n",
    "    tick.set_rotation(20)\n",
    "\n",
    "ai_df = pd.DataFrame({'ai': ai_vals, 'pct': tr_pct_use}).replace([np.inf,-np.inf], np.nan).dropna()\n",
    "try:\n",
    "    ai_df['bin'] = pd.qcut(ai_df['ai'], q=5, duplicates='drop')\n",
    "except Exception:\n",
    "    ai_df['bin'] = pd.cut(ai_df['ai'], bins=5)\n",
    "data_list=[]; labels=[]\n",
    "for lbl in ai_df['bin'].cat.categories:\n",
    "    vals = ai_df.loc[ai_df['bin']==lbl, 'pct'].dropna().values\n",
    "    left = max(0, lbl.left); right = lbl.right if lbl.right != float('inf') else np.inf\n",
    "    lab = f'{left:.2g}–{right:.2g}' if right != np.inf else f'>{left:.2g}'\n",
    "    data_list.append(vals)\n",
    "    labels.append(f\"{lab} (n={len(vals):,})\")\n",
    "axes_pct[3].boxplot(data_list, labels=labels, showfliers=True, flierprops={'markersize':3, 'marker': 'o'})\n",
    "axes_pct[3].axhline(0, ls='--', lw=1, color='gray')\n",
    "axes_pct[3].set_title('% Δ σ² by Aridity Index')\n",
    "axes_pct[3].set_ylabel('% Δ σ² ((CNTL - CYG_DA) / CNTL)')\n",
    "axes_pct[3].set_xlabel('Aridity Index (P/PET)')\n",
    "for tick in axes_pct[3].get_xticklabels():\n",
    "    tick.set_rotation(20)\n",
    "\n",
    "for ax, lab in zip(axes_pct, ['(a)','(b)','(c)','(d)']):\n",
    "    ax.text(0.02, 0.95, lab, transform=ax.transAxes, va='top', ha='left')\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_18\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c52f723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-panel: CNTL sigma2_mod (a) and CNTL minus CYG_DA % Δ σ² (b)\n",
    "vals = [\n",
    "    (S0[\"sigma2_mod\"], 'CNTL Surface Soil Moisture Skill σ²', 'YlGnBu', (0.0, 2e-3), '(a)', '(m³/m³)²'),\n",
    "    (pct_sig2_inv, 'CNTL - CYG_DA: Surface Soil Moisture Skill % Δ σ²', 'RdBu', (-100.0, 100.0), '(b)', '%'),\n",
    "]\n",
    "\n",
    "lats_ease, lons_ease = load_ease_grid(); lats_row, lons_col = lats_ease[:,1], lons_ease[1,:]\n",
    "lon_grid, lat_grid = np.meshgrid(lons_col, lats_row)\n",
    "map_array_tmp = np.empty([lons.size, 3]); map_array_tmp.fill(np.nan); map_array_tmp[:,1] = lons.flatten(); map_array_tmp[:,2] = lats.flatten()\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "for ax, (data_grid, title, cmap_name, clim, lab, units) in zip(axes, vals):\n",
    "    data_grid = np.asarray(data_grid)\n",
    "    if units == '-':  # sigma2_mod, clip negative values\n",
    "        data_grid = np.where(np.isfinite(data_grid), np.maximum(data_grid, 0.0), np.nan)\n",
    "    data_flat = data_grid.flatten()\n",
    "    if clim is None:\n",
    "        vmin, vmax = np.nanpercentile(data_flat, [1, 99])\n",
    "        vmin = max(vmin, 0.0) if units == '-' else vmin\n",
    "    else:\n",
    "        vmin, vmax = clim\n",
    "    if not np.isfinite(vmin) or not np.isfinite(vmax):\n",
    "        vmin, vmax = np.nanmin(data_flat), np.nanmax(data_flat)\n",
    "    edges = np.linspace(vmin, vmax, 21)\n",
    "    cmap = get_cmap(cmap_name, len(edges) - 1)\n",
    "    norm = BoundaryNorm(edges, cmap.N)\n",
    "    mean_val = np.nanmean(data_flat); std_val = np.nanstd(data_flat)\n",
    "    map_array_tmp[:,0] = data_flat\n",
    "    grid = build_ease_grid_mapping(map_array_tmp, lats_row, lons_col)\n",
    "    sc = ax.pcolormesh(lon_grid, lat_grid, grid, cmap=cmap, norm=norm, transform=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "    ax.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "    ax.set_title(f\"{title} (Mean: {mean_val:.3g} ± {std_val:.3g})\")\n",
    "    ax.text(0.02, 0.02, lab, transform=ax.transAxes, va='bottom', ha='left')\n",
    "    ax.tick_params(labelbottom=False, labelleft=False)\n",
    "    cbar = fig.colorbar(sc, ax=ax, orientation='horizontal', pad=0.04, fraction=0.046)\n",
    "    cbar.set_label(units)\n",
    "    cbar.set_ticks(edges[::5])\n",
    "    cbar.ax.set_xticklabels([f\"{t:.2e}\" if units=='-' else f\"{t:.0f}\" for t in edges[::5]])\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_19\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a518d32d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two-panel: CNTL vs CYG_DA sigma2_mod (same scale)\n",
    "vals = [\n",
    "    (S0[\"sigma2_mod\"], 'CNTL Surface Soil Moisture Skill σ²_mod', '(a)'),\n",
    "    (S1[\"sigma2_mod\"], 'CYG_DA Surface Soil Moisture Skill σ²_mod', '(b)'),\n",
    "]\n",
    "\n",
    "lats_ease, lons_ease = load_ease_grid(); lats_row, lons_col = lats_ease[:,1], lons_ease[1,:]\n",
    "lon_grid, lat_grid = np.meshgrid(lons_col, lats_row)\n",
    "map_array_tmp = np.empty([lons.size, 3]); map_array_tmp.fill(np.nan); map_array_tmp[:,1] = lons.flatten(); map_array_tmp[:,2] = lats.flatten()\n",
    "\n",
    "vmin, vmax = 0.0, 2e-3\n",
    "edges = np.linspace(vmin, vmax, 21)\n",
    "cmap = get_cmap('YlGnBu', len(edges) - 1)\n",
    "norm = BoundaryNorm(edges, cmap.N)\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "for ax, (data_grid, title, lab) in zip(axes, vals):\n",
    "    data_grid = np.asarray(data_grid)\n",
    "    data_grid = np.where(np.isfinite(data_grid), np.clip(data_grid, vmin, vmax), np.nan)\n",
    "    data_flat = data_grid.flatten()\n",
    "    mean_val = np.nanmean(data_flat); std_val = np.nanstd(data_flat)\n",
    "    map_array_tmp[:,0] = data_flat\n",
    "    grid = build_ease_grid_mapping(map_array_tmp, lats_row, lons_col)\n",
    "    sc = ax.pcolormesh(lon_grid, lat_grid, grid, cmap=cmap, norm=norm, transform=ccrs.PlateCarree())\n",
    "    ax.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "    ax.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "    ax.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "    ax.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "    ax.set_title(f\"{title} (Mean: {mean_val:.3g} ± {std_val:.3g})\")\n",
    "    ax.text(0.02, 0.02, lab, transform=ax.transAxes, va='bottom', ha='left')\n",
    "    ax.tick_params(labelbottom=False, labelleft=False)\n",
    "    cbar = fig.colorbar(sc, ax=ax, orientation='horizontal', pad=0.04, fraction=0.046)\n",
    "    cbar.set_label('(m³/m³)²')\n",
    "    cbar.set_ticks(edges[::5])\n",
    "    cbar.ax.set_xticklabels([f\"{t:.2e}\" for t in edges[::5]])\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_20\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3d461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4x1 maps: CNTL σ², vegetation, mean LAI, aridity (pcolormesh for all panels)\n",
    "import pandas as pd\n",
    "\n",
    "vmin_sig2, vmax_sig2 = 0.0, 2e-3\n",
    "edges_sig2 = np.linspace(vmin_sig2, vmax_sig2, 21)\n",
    "cmap_sig2 = get_cmap('YlGnBu', len(edges_sig2) - 1)\n",
    "\n",
    "lats_ease, lons_ease = load_ease_grid(); lats_row, lons_col = lats_ease[:,1], lons_ease[1,:]\n",
    "lon_grid, lat_grid = np.meshgrid(lons_col, lats_row)\n",
    "\n",
    "# Helper to map lon/lat/value triplets to the EASE grid\n",
    "\n",
    "def to_grid(values, lon_in, lat_in):\n",
    "    arr = np.column_stack([values.flatten(), lon_in.flatten(), lat_in.flatten()])\n",
    "    return build_ease_grid_mapping(arr, lats_row, lons_col)\n",
    "\n",
    "# (a) CNTL σ² grid (uses EASE lon/lat vectors \"lons\"/\"lats\" that match S0 fields)\n",
    "map_sig = np.empty([lons.size, 3]); map_sig.fill(np.nan)\n",
    "map_sig[:,0] = np.asarray(S0.get('sigma2_mod', np.nan)).flatten()\n",
    "map_sig[:,1] = lons.flatten(); map_sig[:,2] = lats.flatten()\n",
    "sig2_grid = build_ease_grid_mapping(map_sig, lats_row, lons_col)\n",
    "\n",
    "# (b) Veg type grid (native lon/lat: com_lon/com_lat)\n",
    "label_map = {0:\"Bare\",1:\"BL Everg\",2:\"BL Decid\",3:\"Needleleaf\",4:\"Grassland\",5:\"BL Shrubs\",6:\"Dwarf Trees\",7:\"Mixed\",8:\"Sparse\"}\n",
    "veg_colors = ['lightgray','forestgreen','olive','darkgreen','goldenrod','peru','darkolivegreen','plum','tan']\n",
    "veg_cmap = ListedColormap(veg_colors[:len(label_map)])\n",
    "veg_bounds = np.arange(-0.5, 9.5, 1.0)\n",
    "veg_grid = to_grid(np.asarray(veg_type_out), np.where(com_lon > 180.0, com_lon - 360.0, com_lon), com_lat)\n",
    "\n",
    "# (c) Mean LAI grid (native lon/lat: lon/lat)\n",
    "lai_grid = to_grid(np.squeeze(mean_lai_clim), np.squeeze(lon), np.squeeze(lat))\n",
    "edges_lai = np.linspace(0.0, 6.0, 21)\n",
    "cmap_lai = get_cmap('YlGn', len(edges_lai)-1)\n",
    "\n",
    "# (d) Aridity grid (native lon/lat: lon/lat)\n",
    "ai_grid = to_grid(np.squeeze(ai), np.squeeze(lon), np.squeeze(lat))\n",
    "a_edges = np.array([0.00,0.05,0.10,0.20,0.30,0.40,0.50,0.60,0.70,0.80,0.90,1.00,1.10,1.20,1.30,1.40,1.50,1.75,2.00,3.00,5.00,10.00])\n",
    "cmap_ai = get_cmap('Spectral', len(a_edges)-1)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(12, 13), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "# (a) CNTL σ² map\n",
    "ax0 = axes[0]\n",
    "sc0 = ax0.pcolormesh(lon_grid, lat_grid, sig2_grid, cmap=cmap_sig2, norm=BoundaryNorm(edges_sig2, cmap_sig2.N), transform=ccrs.PlateCarree())\n",
    "ax0.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax0.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "ax0.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "ax0.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "ax0.set_title('CNTL Surface Moisture Skill σ²')\n",
    "ax0.text(0.02, 0.02, '(a)', transform=ax0.transAxes, va='bottom', ha='left')\n",
    "ax0.tick_params(labelbottom=False, labelleft=False)\n",
    "cbar0 = fig.colorbar(sc0, ax=ax0, orientation='horizontal', pad=0.04, fraction=0.046)\n",
    "cbar0.set_label('(m³/m³)²')\n",
    "cbar0.set_ticks(edges_sig2[::5])\n",
    "cbar0.ax.set_xticklabels([f\"{t:.2e}\" for t in edges_sig2[::5]])\n",
    "\n",
    "# (b) Vegetation type\n",
    "ax1 = axes[1]\n",
    "sc1 = ax1.pcolormesh(lon_grid, lat_grid, veg_grid, cmap=veg_cmap, norm=BoundaryNorm(veg_bounds, veg_cmap.N), transform=ccrs.PlateCarree())\n",
    "ax1.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax1.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "ax1.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "ax1.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "ax1.set_title('Primary Vegetation Type')\n",
    "ax1.text(0.02, 0.02, '(b)', transform=ax1.transAxes, va='bottom', ha='left')\n",
    "ax1.tick_params(labelbottom=False, labelleft=False)\n",
    "cbar1 = fig.colorbar(sc1, ax=ax1, orientation='horizontal', pad=0.04, fraction=0.046, boundaries=veg_bounds)\n",
    "cbar1.set_ticks(list(label_map.keys()))\n",
    "cbar1.set_ticklabels([label_map[k] for k in label_map])\n",
    "for label in cbar1.ax.get_xticklabels():\n",
    "    label.set_rotation(45)\n",
    "    label.set_ha('right')\n",
    "\n",
    "# (c) Mean LAI\n",
    "ax2 = axes[2]\n",
    "sc2 = ax2.pcolormesh(lon_grid, lat_grid, lai_grid, cmap=cmap_lai, norm=BoundaryNorm(edges_lai, cmap_lai.N), transform=ccrs.PlateCarree())\n",
    "ax2.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax2.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "ax2.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "ax2.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "ax2.set_title('Mean Annual Leaf Area Index (LAI)')\n",
    "ax2.text(0.02, 0.02, '(c)', transform=ax2.transAxes, va='bottom', ha='left')\n",
    "ax2.tick_params(labelbottom=False, labelleft=False)\n",
    "cbar2 = fig.colorbar(sc2, ax=ax2, orientation='horizontal', pad=0.04, fraction=0.046)\n",
    "cbar2.set_label('(m²/m²)')\n",
    "cbar2.set_ticks(edges_lai[::5])\n",
    "cbar2.ax.set_xticklabels([f\"{t:.1f}\" for t in edges_lai[::5]])\n",
    "\n",
    "# (d) Aridity\n",
    "ax3 = axes[3]\n",
    "sc3 = ax3.pcolormesh(lon_grid, lat_grid, ai_grid, cmap=cmap_ai, norm=BoundaryNorm(a_edges, cmap_ai.N), transform=ccrs.PlateCarree())\n",
    "ax3.add_feature(cfeature.COASTLINE, linewidth=0.5)\n",
    "ax3.add_feature(cfeature.BORDERS, linewidth=0.3)\n",
    "ax3.add_feature(cfeature.LAND, color='lightgray', zorder=0)\n",
    "ax3.set_extent(REGION_BOUNDS['cygnss'], crs=ccrs.PlateCarree())\n",
    "ax3.set_title('Mean Annual Aridity Index (P/PET)')\n",
    "ax3.text(0.02, 0.02, '(d)', transform=ax3.transAxes, va='bottom', ha='left')\n",
    "ax3.tick_params(labelbottom=False, labelleft=False)\n",
    "cbar3 = fig.colorbar(sc3, ax=ax3, orientation='horizontal', pad=0.04, fraction=0.046, boundaries=a_edges)\n",
    "cbar3.set_label('(P/PET)')\n",
    "positions = a_edges[::5]\n",
    "cbar3.set_ticks(positions)\n",
    "cbar3.ax.set_xticklabels([f\"{t:.2f}\" for t in positions])\n",
    "\n",
    "plt.tight_layout()\n",
    "save_fig(plt.gcf(), \"figure_21\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
