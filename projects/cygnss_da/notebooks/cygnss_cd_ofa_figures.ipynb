{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_repo_root(start: Path) -> Path:\n",
    "    for p in [start] + list(start.parents):\n",
    "        if (p / '.git').exists():\n",
    "            return p\n",
    "    return start\n",
    "\n",
    "here = Path(__file__).resolve().parent if '__file__' in globals() else Path.cwd()\n",
    "repo_root = find_repo_root(here)\n",
    "sys.path.append(str(repo_root / 'common' / 'python' / 'io'))\n",
    "sys.path.append(str(repo_root / 'projects' / 'matlab2python' / 'shared' / 'python'))\n",
    "sys.path.append(str(repo_root / 'common' / 'python' / 'plotting'))\n",
    "sys.path.append('../util/shared/python/')\n",
    "\n",
    "EASE_PATH = repo_root / 'common' / 'python' / 'plotting' / 'ease_grids'\n",
    "\n",
    "from read_GEOSldas import read_tilecoord, read_obs_param\n",
    "\n",
    "from geospatial_plotting import plot_region, REGION_BOUNDS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = {\n",
    "    \"SMOS\": [0, 1, 2, 3],\n",
    "    \"SMAP\": [4, 5, 6, 7],\n",
    "    \"ASCAT\": [8, 9, 10],\n",
    "    \"CYGNSS\": [11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading stats nc4 file /Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_cd/OLv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_OL_20180801_20240630.nc4\n",
      "Reading variable: O_mean\n",
      "Reading variable: O_stdv\n",
      "Reading variable: F_mean\n",
      "Reading variable: F_stdv\n",
      "Reading variable: A_mean\n",
      "Reading variable: A_stdv\n",
      "Reading variable: OmF_mean\n",
      "Reading variable: OmF_stdv\n",
      "Reading variable: OmA_mean\n",
      "Reading variable: OmA_stdv\n",
      "Reading variable: OmF_norm_mean\n",
      "Reading variable: OmF_norm_stdv\n",
      "Reading variable: N_data\n"
     ]
    }
   ],
   "source": [
    "# Read in the OL data files\n",
    "\n",
    "stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_cd/' \\\n",
    "'OLv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_OL_20180801_20240630.nc4'\n",
    "\n",
    "print('reading stats nc4 file '+stats_file_OL)\n",
    "stats_OL = {}\n",
    "with Dataset(stats_file_OL,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        print(f\"Reading variable: {key}\")\n",
    "        stats_OL[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_cd/' \\\n",
    "'OLv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_OL_201808_202406.pkl'\n",
    "\n",
    "with open(ts_stats_file_OL, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_OL = loaded_data\n",
    "date_vec_OL = loaded_data.get('date_vec', None)  \n",
    "date_vec = date_vec_OL "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading stats nc4 file /Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd/DAv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20180801_20240630.nc4\n"
     ]
    }
   ],
   "source": [
    "# Read in the DA data files\n",
    "stats_file_DA = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd/' \\\n",
    "'DAv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20180801_20240630.nc4'\n",
    "print('reading stats nc4 file '+stats_file_DA)\n",
    "stats_DA = {}\n",
    "with Dataset(stats_file_DA,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_DA[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_DA = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd/' \\\n",
    "'DAv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_DA_201808_202406.pkl'\n",
    "\n",
    "with open(ts_stats_file_DA, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_DA = loaded_data\n",
    "date_vec_DA = loaded_data.get('date_vec', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading stats nc4 file /Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd_all/DAv8_M36_cd_all/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20180801_20240630.nc4\n"
     ]
    }
   ],
   "source": [
    "# Read in the DA data files\n",
    "stats_file_DA_all = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd_all/' \\\n",
    "'DAv8_M36_cd_all/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20180801_20240630.nc4'\n",
    "print('reading stats nc4 file '+stats_file_DA_all)\n",
    "stats_DA_all = {}\n",
    "with Dataset(stats_file_DA_all,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_DA_all[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_DA_all = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd_all/' \\\n",
    "'DAv8_M36_cd_all/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_DA_201808_202406.pkl'\n",
    "\n",
    "with open(ts_stats_file_DA_all, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_DA_all = loaded_data\n",
    "date_vec_DA_all = loaded_data.get('date_vec', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading stats nc4 file /Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd_ssa/DAv8_M36_cd_ssa/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20180801_20240630.nc4\n"
     ]
    }
   ],
   "source": [
    "# Read in the DA data files\n",
    "stats_file_DA_ssa = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd_ssa/' \\\n",
    "'DAv8_M36_cd_ssa/output/SMAP_EASEv2_M36_GLOBAL/figures/temporal_stats_DA_20180801_20240630.nc4'\n",
    "print('reading stats nc4 file '+stats_file_DA_ssa)\n",
    "stats_DA_ssa = {}\n",
    "with Dataset(stats_file_DA_ssa,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_DA_ssa[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_DA_ssa = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd_ssa/' \\\n",
    "'DAv8_M36_cd_ssa/output/SMAP_EASEv2_M36_GLOBAL/figures/spatial_stats_DA_201808_202406.pkl'\n",
    "\n",
    "with open(ts_stats_file_DA_ssa, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_DA_ssa = loaded_data\n",
    "date_vec_DA_ssa = loaded_data.get('date_vec', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/3977554994.py:44: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_OL[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/3977554994.py:45: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_OL[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/3977554994.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_OL[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/3977554994.py:47: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_OL[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/3977554994.py:48: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_OL[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/3977554994.py:49: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_OL[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n"
     ]
    }
   ],
   "source": [
    "# Sample of final compuation of selected diagnostic metrics for OL\n",
    " \n",
    "Nmin = 20\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OL['N_data']\n",
    "O_mean = stats_OL['O_mean']\n",
    "A_mean = stats_OL['A_mean']\n",
    "F_mean = stats_OL['F_mean']\n",
    "O_stdv = stats_OL['O_stdv']\n",
    "A_stdv = stats_OL['A_stdv']\n",
    "F_stdv = stats_OL['F_stdv']\n",
    "OmF_mean = stats_OL['OmF_mean']\n",
    "OmF_stdv = stats_OL['OmF_stdv']\n",
    "OmF_norm_mean = stats_OL['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_OL['OmF_norm_stdv']\n",
    "OmA_mean = stats_OL['OmA_mean']\n",
    "OmA_stdv = stats_OL['OmA_stdv']\n",
    "  \n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "\n",
    "OmF_mean_OL = OmF_mean\n",
    "OmF_stdv_OL = OmF_stdv\n",
    "OmF_norm_mean_OL = OmF_norm_mean\n",
    "OmF_norm_stdv_OL = OmF_norm_stdv\n",
    "OmA_mean_OL = OmA_mean\n",
    "OmA_stdv_OL = OmA_stdv\n",
    "N_data_OL = N_data\n",
    "\n",
    "group_metrics_OL = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OL[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_OL[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['Nobs_data'] = group_N_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/4095136516.py:41: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/4095136516.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/4095136516.py:43: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/4095136516.py:44: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/4095136516.py:45: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/4095136516.py:46: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sample of final compuation of selected diagnostic metrics for DA\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_DA['N_data']\n",
    "O_mean = stats_DA['O_mean']\n",
    "A_mean = stats_DA['A_mean']\n",
    "F_mean = stats_DA['F_mean']\n",
    "O_stdv = stats_DA['O_stdv']\n",
    "A_stdv = stats_DA['A_stdv']\n",
    "F_stdv = stats_DA['F_stdv']\n",
    "OmF_mean = stats_DA['OmF_mean']\n",
    "OmF_stdv = stats_DA['OmF_stdv']\n",
    "OmF_norm_mean = stats_DA['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_DA['OmF_norm_stdv']\n",
    "OmA_mean = stats_DA['OmA_mean']\n",
    "OmA_stdv = stats_DA['OmA_stdv']\n",
    "\n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "OmF_mean_DA = OmF_mean\n",
    "OmF_stdv_DA = OmF_stdv\n",
    "OmF_norm_mean_DA = OmF_norm_mean\n",
    "OmF_norm_stdv_DA = OmF_norm_stdv\n",
    "OmA_mean_DA = OmA_mean\n",
    "OmA_stdv_DA = OmA_stdv\n",
    "N_data_DA = N_data\n",
    "\n",
    "group_metrics_DA = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_DA[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_DA[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['Nobs_data'] = group_N_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/452541659.py:39: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_all[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/452541659.py:40: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_all[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/452541659.py:41: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_all[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/452541659.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_all[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/452541659.py:43: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_all[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/452541659.py:44: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_all[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n"
     ]
    }
   ],
   "source": [
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_DA_all['N_data']\n",
    "O_mean = stats_DA_all['O_mean']\n",
    "A_mean = stats_DA_all['A_mean']\n",
    "F_mean = stats_DA_all['F_mean']\n",
    "O_stdv = stats_DA_all['O_stdv']\n",
    "A_stdv = stats_DA_all['A_stdv']\n",
    "F_stdv = stats_DA_all['F_stdv']\n",
    "OmF_mean = stats_DA_all['OmF_mean']\n",
    "OmF_stdv = stats_DA_all['OmF_stdv']\n",
    "OmF_norm_mean = stats_DA_all['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_DA_all['OmF_norm_stdv']\n",
    "OmA_mean = stats_DA_all['OmA_mean']\n",
    "OmA_stdv = stats_DA_all['OmA_stdv']\n",
    "\n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "OmF_mean_DA_all = OmF_mean\n",
    "OmF_stdv_DA_all = OmF_stdv\n",
    "OmF_norm_mean_DA_all = OmF_norm_mean\n",
    "OmF_norm_stdv_DA_all = OmF_norm_stdv\n",
    "OmA_mean_DA_all = OmA_mean\n",
    "OmA_stdv_DA_all = OmA_stdv\n",
    "N_data_DA_all = N_data\n",
    "\n",
    "group_metrics_DA_all = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_DA_all[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_DA_all[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_all[group]['Nobs_data'] = group_N_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/1084405669.py:39: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_ssa[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/1084405669.py:40: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_ssa[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/1084405669.py:41: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_ssa[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/1084405669.py:42: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_ssa[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/1084405669.py:43: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_ssa[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
      "/var/folders/p3/6g36x17x60d12xdgb49ryq4r0000gr/T/ipykernel_50492/1084405669.py:44: RuntimeWarning: invalid value encountered in divide\n",
      "  group_metrics_DA_ssa[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n"
     ]
    }
   ],
   "source": [
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_DA_ssa['N_data']\n",
    "O_mean = stats_DA_ssa['O_mean']\n",
    "A_mean = stats_DA_ssa['A_mean']\n",
    "F_mean = stats_DA_ssa['F_mean']\n",
    "O_stdv = stats_DA_ssa['O_stdv']\n",
    "A_stdv = stats_DA_ssa['A_stdv']\n",
    "F_stdv = stats_DA_ssa['F_stdv']\n",
    "OmF_mean = stats_DA_ssa['OmF_mean']\n",
    "OmF_stdv = stats_DA_ssa['OmF_stdv']\n",
    "OmF_norm_mean = stats_DA_ssa['OmF_norm_mean']\n",
    "OmF_norm_stdv = stats_DA_ssa['OmF_norm_stdv']\n",
    "OmA_mean = stats_DA_ssa['OmA_mean']\n",
    "OmA_stdv = stats_DA_ssa['OmA_stdv']\n",
    "\n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "OmF_mean_DA_ssa = OmF_mean\n",
    "OmF_stdv_DA_ssa = OmF_stdv\n",
    "OmF_norm_mean_DA_ssa = OmF_norm_mean\n",
    "OmF_norm_stdv_DA_ssa = OmF_norm_stdv\n",
    "OmA_mean_DA_ssa = OmA_mean\n",
    "OmA_stdv_DA_ssa = OmA_stdv\n",
    "N_data_DA_ssa = N_data\n",
    "\n",
    "group_metrics_DA_ssa = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_DA_ssa[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_DA_ssa[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA_ssa[group]['Nobs_data'] = group_N_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading from /Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd/DAv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/rc_out/DAv8_M36_cd.ldas_tilecoord.bin\n",
      "done reading file\n"
     ]
    }
   ],
   "source": [
    "ftc = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd/' \\\n",
    "      'DAv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/rc_out/DAv8_M36_cd.ldas_tilecoord.bin'\n",
    "tc = read_tilecoord(ftc)\n",
    "n_tile = tc['N_tile']\n",
    "lat = tc['com_lat']\n",
    "lon = tc['com_lon']\n",
    "\n",
    "map_array = np.empty([n_tile, 3])\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 1] = lon\n",
    "map_array[:, 2] = lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../test_data/EASE2_M36km.lats.964x406x1.double'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m     minval \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(map_array[:, \u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;66;03m# Plot group map\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m     fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplot_region\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_array\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mregion_bounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mREGION_BOUNDS\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcygnss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmeanflag\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplot_title\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mgroup\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m Ndata: DAv8_M36_201808_202406 \u001b[39;49m\u001b[38;5;130;43;01m\\n\u001b[39;49;00m\u001b[38;5;124;43m (Max: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mmaxval\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.3g\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m Min: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mminval\u001b[49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m.3g\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43munits\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCnt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     fig\u001b[38;5;241m.\u001b[39mtight_layout()\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# ASCAT = 6121\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# SMOS = 5047\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# SMAP = 3287\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/geosldas-analysis/common/python/plotting/geospatial_plotting.py:128\u001b[0m, in \u001b[0;36mplot_region\u001b[0;34m(array, region_bounds, ease_path, saveflag, meanflag, plot_title, units, cmin, cmax, cmap, norm, output_dir, save_fmt, save_dpi, star_lon, star_lat, overlay_points, discrete_edges, base_cmap)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_region\u001b[39m(array, region_bounds, ease_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../test_data\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    122\u001b[0m                 saveflag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, meanflag\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, plot_title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mregional_plot\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m    123\u001b[0m                 units\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mna\u001b[39m\u001b[38;5;124m'\u001b[39m, cmin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cmax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, norm\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    124\u001b[0m                 output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./plots\u001b[39m\u001b[38;5;124m'\u001b[39m, save_fmt\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m, save_dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m600\u001b[39m, \n\u001b[1;32m    125\u001b[0m                 star_lon\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, star_lat\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, overlay_points\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    126\u001b[0m                 discrete_edges\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, base_cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpectral\u001b[39m\u001b[38;5;124m\"\u001b[39m):  \u001b[38;5;66;03m# returns fig, ax in Jupyter\u001b[39;00m\n\u001b[1;32m    127\u001b[0m     lon_min, lon_max, lat_min, lat_max \u001b[38;5;241m=\u001b[39m region_bounds\n\u001b[0;32m--> 128\u001b[0m     lats, lons \u001b[38;5;241m=\u001b[39m \u001b[43mload_ease_grid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mease_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m     lats_row, lons_col \u001b[38;5;241m=\u001b[39m lats[:,\u001b[38;5;241m1\u001b[39m], lons[\u001b[38;5;241m1\u001b[39m,:]\n\u001b[1;32m    130\u001b[0m     grid \u001b[38;5;241m=\u001b[39m build_ease_grid_mapping(array, lats_row, lons_col) \n",
      "File \u001b[0;32m~/Desktop/geosldas-analysis/common/python/plotting/geospatial_plotting.py:45\u001b[0m, in \u001b[0;36mload_ease_grid\u001b[0;34m(ease_path)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_ease_grid\u001b[39m(ease_path):\n\u001b[0;32m---> 45\u001b[0m     lats \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mease_path\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/EASE2_M36km.lats.964x406x1.double\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m406\u001b[39m,\u001b[38;5;241m964\u001b[39m))\n\u001b[1;32m     46\u001b[0m     lons \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromfile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mease_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/EASE2_M36km.lons.964x406x1.double\u001b[39m\u001b[38;5;124m'\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat64)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m406\u001b[39m,\u001b[38;5;241m964\u001b[39m))\n\u001b[1;32m     47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lats, lons\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../test_data/EASE2_M36km.lats.964x406x1.double'"
     ]
    }
   ],
   "source": [
    "for group in species_groups.keys():\n",
    "\n",
    "    map_array[:, 0] = group_metrics_DA[group]['Nobs_data']\n",
    "\n",
    "    maxval = np.nanmax(map_array[:, 0])\n",
    "    minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "    # Plot group map\n",
    "    fig, ax = plot_region(\n",
    "        map_array,\n",
    "        region_bounds=REGION_BOUNDS['cygnss'],\n",
    "        meanflag=True,\n",
    "        plot_title=f'{group} Ndata: DAv8_M36_201808_202406 \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "        units='Cnt'\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "\n",
    "# ASCAT = 6121\n",
    "# SMOS = 5047\n",
    "# SMAP = 3287\n",
    "\n",
    "ndays = 2161\n",
    "\n",
    "# Accumulators (same length as your map pixels)\n",
    "total_obs_per_day = np.zeros(map_array.shape[0], dtype=float)\n",
    "cygnss_obs_per_day = np.zeros_like(total_obs_per_day)\n",
    "\n",
    "for group in species_groups.keys():\n",
    "\n",
    "    # Pull raw counts for this group\n",
    "    raw = group_metrics_DA[group]['Nobs_data']  # shape (npix,)\n",
    "    # Convert to obs/day for this group (safe for NaNs/inf)\n",
    "    per_day = np.nan_to_num(raw / ndays, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "    # Keep your existing per-group plot behavior\n",
    "    map_array[:, 0] = per_day\n",
    "\n",
    "    maxval = np.nanmax(map_array[:, 0])\n",
    "    minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "    # Plot group map\n",
    "    fig, ax = plot_region(\n",
    "        map_array,\n",
    "        region_bounds=REGION_BOUNDS['cygnss'],\n",
    "        meanflag=True,\n",
    "        plot_title=(f'{group} Obs per day: DAv8_M36_201808_202406\\n'\n",
    "                    f'(Max: {maxval:.3g} Min: {minval:.3g})'),\n",
    "        units='Obs per day',\n",
    "        cmin=0.0,\n",
    "        cmax=2.0\n",
    "    )\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # --- ADD INSIDE THE LOOP: accumulate totals & remember CYGNSS ---\n",
    "    total_obs_per_day += per_day\n",
    "    if group.upper() == 'CYGNSS':\n",
    "        cygnss_obs_per_day = per_day\n",
    "\n",
    "# --- ADD AFTER THE LOOP: plot ALL and %CYGNSS ---\n",
    "\n",
    "# (A) ALL sensors: obs/day\n",
    "map_array[:, 0] = total_obs_per_day\n",
    "maxval_all = np.nanmax(map_array[:, 0])\n",
    "minval_all = np.nanmin(map_array[:, 0])\n",
    "\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=('ALL Sensors Obs per day: DAv8_M36_201808_202406\\n'\n",
    "                f'(Max: {maxval_all:.3g} Min: {minval_all:.3g})'),\n",
    "    units='Obs per day',\n",
    "    cmin=0.0,\n",
    "    cmax=5.0  # adjust if your totals exceed this\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# (B) % of obs that are CYGNSS\n",
    "frac_cygnss = np.divide(\n",
    "    cygnss_obs_per_day, total_obs_per_day,\n",
    "    out=np.zeros_like(total_obs_per_day), where=total_obs_per_day > 0\n",
    ")\n",
    "percent_cygnss = 100.0 * frac_cygnss\n",
    "\n",
    "map_array[:, 0] = percent_cygnss\n",
    "maxval_pct = np.nanmax(map_array[:, 0])\n",
    "minval_pct = np.nanmin(map_array[:, 0])\n",
    "\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=('% CYGNSS of ALL Obs: DAv8_M36_201808_202406\\n'\n",
    "                f'(Max: {maxval_pct:.3g}% Min: {minval_pct:.3g}%)'),\n",
    "    units='% of obs from CYGNSS',\n",
    "    cmin=0.0,\n",
    "    cmax=80.0\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stats_dict_to_arrays(stats_dict):\n",
    "    \"\"\"Convert dictionary of lists to numpy arrays\"\"\"\n",
    "    array_dict = {}\n",
    "    \n",
    "    for key in stats_dict.keys():\n",
    "        # Convert list to array and reshape\n",
    "        array_dict[key] = np.array(stats_dict[key])\n",
    "        \n",
    "        # Check if we need to handle missing values (-- in data)\n",
    "        if isinstance(array_dict[key][0], (list, np.ndarray)):\n",
    "            # Replace '--' with np.nan\n",
    "            temp_array = []\n",
    "            for row in array_dict[key]:\n",
    "                cleaned_row = [np.nan if x == '--' else float(x) for x in row]\n",
    "                temp_array.append(cleaned_row)\n",
    "            array_dict[key] = np.array(temp_array)\n",
    "    \n",
    "    return array_dict\n",
    "\n",
    "# Convert dictionary\n",
    "stats_dict_DA_arrays = convert_stats_dict_to_arrays(stats_dict_DA)\n",
    "stats_dict_OL_arrays = convert_stats_dict_to_arrays(stats_dict_OL)\n",
    "stats_dict_DA_all_arrays = convert_stats_dict_to_arrays(stats_dict_DA_all)\n",
    "stats_DA_ssa_arrays = convert_stats_dict_to_arrays(stats_dict_DA_ssa)\n",
    "\n",
    "# Convert date vector to datetime objects\n",
    "date_vec_DA = [datetime.strptime(date, '%Y%m') for date in date_vec_DA]\n",
    "date_vec_OL = [datetime.strptime(date, '%Y%m') for date in date_vec_OL]\n",
    "date_vec_DA_all = [datetime.strptime(date, '%Y%m') for date in date_vec_DA_all]\n",
    "date_vec_DA_ssa = [datetime.strptime(date, '%Y%m') for date in date_vec_DA_ssa]\n",
    "\n",
    "# Print first few dates to verify\n",
    "print(\"Sample dates:\", date_vec_DA[:3])\n",
    "# Print the last few dates to verify\n",
    "print(\"Sample dates:\", date_vec_DA[-3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_group_stats(stats_dict, species_groups):\n",
    "    \"\"\"Calculate weighted statistics for each group\"\"\"\n",
    "    \n",
    "    n_times = len(stats_dict['OmF_mean'])\n",
    "    stats = ['O_mean','F_mean','OmF_mean', 'OmF_stdv', 'OmA_mean', 'OmA_stdv']\n",
    "    \n",
    "    # Initialize output dictionary\n",
    "    group_stats = {}\n",
    "    for group in species_groups.keys():\n",
    "        group_stats[group] = {stat: np.zeros(n_times) for stat in stats}\n",
    "        group_stats[group]['N_data'] = np.zeros(n_times)\n",
    "    \n",
    "    # Calculate weighted stats for each timestep\n",
    "    for t in range(n_times):\n",
    "        for group, indices in species_groups.items():\n",
    "            # Get weights for this group/time\n",
    "            weights = stats_dict['N_data'][t, indices]\n",
    "            total_weight = np.sum(weights)\n",
    "            \n",
    "            if total_weight > 0:\n",
    "                # Calculate weighted statistics\n",
    "                for stat in stats:\n",
    "                    values = stats_dict[stat][t, indices]\n",
    "                    group_stats[group][stat][t] = np.average(values, weights=weights)\n",
    "                group_stats[group]['N_data'][t] = total_weight\n",
    "            else:\n",
    "                # Set to NaN if no observations\n",
    "                for stat in stats:\n",
    "                    group_stats[group][stat][t] = np.nan\n",
    "                    \n",
    "    return group_stats\n",
    "\n",
    "# Calculate group means\n",
    "group_ts_DA = calculate_weighted_group_stats(stats_dict_DA_arrays, species_groups)\n",
    "group_ts_OL = calculate_weighted_group_stats(stats_dict_OL_arrays, species_groups)\n",
    "group_ts_DA_all = calculate_weighted_group_stats(stats_dict_DA_all_arrays, species_groups)\n",
    "group_ts_DA_ssa = calculate_weighted_group_stats(stats_DA_ssa_arrays, species_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length of date_vec_DA\", len(date_vec_DA))\n",
    "print(\"length of date_vec\", len(date_vec))\n",
    "print(\"length of date_vec_DA_all\", len(date_vec_DA_all))\n",
    "print(\"length of date_vec_DA_ssa\", len(date_vec_DA_ssa))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each species\n",
    "for group in species_groups.keys():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot OmF_mean for OL and DA\n",
    "    mean_O = np.nanmean(group_ts_OL[group]['O_mean'])\n",
    "    mean_F = np.nanmean(group_ts_OL[group]['F_mean'])\n",
    "    \n",
    "    plt.plot(date_vec_DA, group_ts_OL[group]['O_mean'], '--', label=f'{group} O_mean (Mean: {mean_O:.3f})')\n",
    "    plt.plot(date_vec_DA, group_ts_OL[group]['F_mean'], '-', label=f'{group} F_mean (Mean: {mean_F:.3f})')\n",
    "    \n",
    "    # Add black dotted line for Y = 0\n",
    "    # plt.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'O and F Mean for {group}: DAv8_M36_201808_202406')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('O and F Mean')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set x-ticks to every 6 months\n",
    "    # Set x-ticks using datetime array\n",
    "    plt.xticks(date_vec_DA[::12], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each species\n",
    "for group in species_groups.keys():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot OmF_mean for OL and DA\n",
    "    mean_OL = np.nanmean(group_ts_OL[group]['OmF_mean'])\n",
    "    mean_DA = np.nanmean(group_ts_DA[group]['OmF_mean'])\n",
    "    \n",
    "    plt.plot(date_vec_DA, group_ts_OL[group]['OmF_mean'], '--', label=f'{group} OL (Mean: {mean_OL:.3f})')\n",
    "    plt.plot(date_vec_DA, group_ts_DA[group]['OmF_mean'], '-', label=f'{group} DA (Mean: {mean_DA:.3f})')\n",
    "    \n",
    "    # Add black dotted line for Y = 0\n",
    "    plt.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'O-F Mean for {group}: DAv8_M36_201808_202406')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('O-F Mean')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set x-ticks to every 24 months\n",
    "    # Set x-ticks using datetime array\n",
    "    plt.xticks(date_vec_DA[::12], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each species\n",
    "for group in species_groups.keys():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot OmF_mean for OL and DA\n",
    "    mean_OL = np.nanmean(group_ts_OL[group]['OmF_stdv'])\n",
    "    mean_DA = np.nanmean(group_ts_DA[group]['OmF_stdv'])\n",
    "    mean_DA_all = np.nanmean(group_ts_DA_all[group]['OmF_stdv'])\n",
    "    mean_DA_ssa = np.nanmean(group_ts_DA_ssa[group]['OmF_stdv'])\n",
    "    \n",
    "    plt.plot(date_vec_DA, group_ts_OL[group]['OmF_stdv'], '--', label=f'{group} CNTL (Mean: {mean_OL:.3f})')\n",
    "    plt.plot(date_vec_DA, group_ts_DA[group]['OmF_stdv'], '-', label=f'{group} CYG_DA (Mean: {mean_DA:.3f})')\n",
    "    plt.plot(date_vec_DA_ssa, group_ts_DA_ssa[group]['OmF_stdv'], '-.', label=f'{group} SSA_DA (Mean: {mean_DA_ssa:.3f})')\n",
    "    plt.plot(date_vec_DA_all, group_ts_DA_all[group]['OmF_stdv'], ':', label=f'{group} ALL_DA (Mean: {mean_DA_all:.3f})')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'O-F StdDev for {group}: DAv8_M36_201808_202406')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('O-F StdDev')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set y-axis minimum to zero\n",
    "    # plt.ylim(bottom=0)\n",
    "    \n",
    "    # Set x-ticks using datetime array\n",
    "    plt.xticks(date_vec_DA[::12], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with NaNs in the data\n",
    "for group in species_groups.keys():\n",
    "    group_ts_DA[group]['N_data'] = np.where(group_ts_DA[group]['N_data'] == 0, np.nan, group_ts_DA[group]['N_data'])\n",
    "\n",
    "# Plot time series of the number of observations for each group\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Nobs_data for DA for all groups on one figure\n",
    "for group in species_groups.keys():\n",
    "    plt.plot(date_vec_DA, group_ts_DA[group]['N_data'], label=f'{group} DA')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Number of Observations for All Groups (DA): DAv8_M36_201808_202406')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Observations per Month')\n",
    "plt.legend()\n",
    "\n",
    "# Set x-ticks using datetime array\n",
    "plt.xticks(date_vec_DA[::12], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace zeros with NaNs in the data\n",
    "for group in species_groups.keys():\n",
    "    group_ts_DA[group]['N_data'] = np.where(group_ts_DA[group]['N_data'] == 0, np.nan, group_ts_DA[group]['N_data'])\n",
    "\n",
    "# Plot time series of the number of observations for each group\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot Nobs_data for DA for all groups on one figure\n",
    "for group in species_groups.keys():\n",
    "    plt.plot(date_vec_DA, group_ts_DA[group]['N_data'], label=f'{group}')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Number of observations from all sensors')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Observations per Month')\n",
    "plt.legend()\n",
    "\n",
    "# Set x-ticks using datetime array\n",
    "plt.xticks(date_vec_DA[::12], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each species group\n",
    "for group in species_groups.keys():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Calculate normalized percent difference\n",
    "    norm_percent_diff = np.divide(\n",
    "        (group_ts_DA[group]['OmF_stdv'] - group_ts_OL[group]['OmF_stdv']),\n",
    "        group_ts_OL[group]['OmF_stdv'],\n",
    "        out=np.full_like(group_ts_OL[group]['OmF_stdv'], np.nan, dtype=float),\n",
    "        where=group_ts_OL[group]['OmF_stdv'] != 0\n",
    "    ) * 100\n",
    "    \n",
    "    mean_diff = np.nanmean(norm_percent_diff)\n",
    "    \n",
    "    # Plot normalized percent difference\n",
    "    plt.plot(date_vec_DA, norm_percent_diff, label=f'{group} (Mean: {mean_diff:.3f}%)')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'Normalized Percent Difference (DA - OL) for {group}: DAv8_M36_201808_202406')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Normalized Percent Difference (%)')\n",
    "    plt.axhline(y=0, color='black', linestyle=':', linewidth=1)  # Add black dotted line for Y = 0\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set x-ticks using datetime array\n",
    "    plt.xticks(date_vec_DA[::12], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the first three groups on the same plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define the first three groups\n",
    "groups_to_plot = list(species_groups.keys())[:4]\n",
    "\n",
    "# Plot normalized percent difference for each group\n",
    "for group in groups_to_plot:\n",
    "    norm_percent_diff = np.divide(\n",
    "        (group_ts_DA[group]['OmF_stdv'] - group_ts_OL[group]['OmF_stdv']),\n",
    "        group_ts_OL[group]['OmF_stdv'],\n",
    "        out=np.full_like(group_ts_OL[group]['OmF_stdv'], np.nan, dtype=float),\n",
    "        where=group_ts_OL[group]['OmF_stdv'] != 0\n",
    "    ) * 100\n",
    "    \n",
    "    mean_diff = np.nanmean(norm_percent_diff)\n",
    "    plt.plot(date_vec_DA, norm_percent_diff, label=f'{group} (Mean: {mean_diff:.2f}%)')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Normalized Percent Difference ((CYG_DA - CNTL) / CNTL): DAv8_M36_201808_202406')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized Percent Difference (%)')\n",
    "plt.axhline(y=0, color='black', linestyle=':', linewidth=1)  # Add black dotted line for Y = 0\n",
    "plt.ylim(-10, 2)\n",
    "plt.legend()\n",
    "\n",
    "# Set x-ticks using datetime array\n",
    "plt.xticks(date_vec_DA[::12], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###################\n",
    "\n",
    "# Plot the first three groups on the same plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define the first three groups\n",
    "groups_to_plot = list(species_groups.keys())[:4]\n",
    "\n",
    "# Plot normalized percent difference for each group\n",
    "for group in groups_to_plot:\n",
    "    norm_percent_diff = np.divide(\n",
    "        (group_ts_DA_all[group]['OmF_stdv'] - group_ts_OL[group]['OmF_stdv']),\n",
    "        group_ts_OL[group]['OmF_stdv'],\n",
    "        out=np.full_like(group_ts_OL[group]['OmF_stdv'], np.nan, dtype=float),\n",
    "        where=group_ts_OL[group]['OmF_stdv'] != 0\n",
    "    ) * 100\n",
    "    \n",
    "    mean_diff = np.nanmean(norm_percent_diff)\n",
    "    plt.plot(date_vec_DA, norm_percent_diff, label=f'{group} (Mean: {mean_diff:.2f}%)')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Normalized Percent Difference ((ALL_DA - CNTL) / CNTL): DAv8_M36_201808_202406')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized Percent Difference (%)')\n",
    "plt.axhline(y=0, color='black', linestyle=':', linewidth=1)  # Add black dotted line for Y = 0\n",
    "plt.ylim(-25, 5)\n",
    "plt.legend()\n",
    "\n",
    "# Set x-ticks using datetime array\n",
    "plt.xticks(date_vec_DA[::12], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "###################\n",
    "\n",
    "# Plot the first three groups on the same plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Define the first three groups\n",
    "groups_to_plot = list(species_groups.keys())[:4]\n",
    "\n",
    "# Plot normalized percent difference for each group\n",
    "for group in groups_to_plot:\n",
    "    norm_percent_diff = np.divide(\n",
    "        (group_ts_DA_ssa[group]['OmF_stdv'] - group_ts_OL[group]['OmF_stdv']),\n",
    "        group_ts_OL[group]['OmF_stdv'],\n",
    "        out=np.full_like(group_ts_OL[group]['OmF_stdv'], np.nan, dtype=float),\n",
    "        where=group_ts_OL[group]['OmF_stdv'] != 0\n",
    "    ) * 100\n",
    "    \n",
    "    mean_diff = np.nanmean(norm_percent_diff)\n",
    "    plt.plot(date_vec_DA_ssa, norm_percent_diff, label=f'{group} (Mean: {mean_diff:.2f}%)')\n",
    "\n",
    "# Customize plot\n",
    "plt.title('Normalized Percent Difference ((SSA_DA - CNTL) / CNTL): DAv8_M36_201808_202406')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Normalized Percent Difference (%)')\n",
    "plt.axhline(y=0, color='black', linestyle=':', linewidth=1)  # Add black dotted line for Y = 0\n",
    "plt.ylim(-25, 5)\n",
    "plt.legend()\n",
    "\n",
    "# Set x-ticks using datetime array\n",
    "plt.xticks(date_vec_DA[::12], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'SMAP'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'CYG_DA - CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='K'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(CYG_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_all[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(ALL_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_ssa[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(SSA_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'SMOS'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'CYG_DA - CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='K'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(CYG_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_all[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(ALL_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_ssa[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(SSA_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'ASCAT'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'CYG_DA - CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='m3/m3'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(CYG_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_all[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(ALL_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_ssa[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(SSA_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'CYGNSS'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'CYG_DA - CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='m3/m3'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA_all[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'ALL_DA - CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='m3/m3'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(CYG_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_all[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(ALL_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = np.divide(\n",
    "    (group_metrics_DA_ssa[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']),\n",
    "    group_metrics_OL[group_name]['OmF_stdv'],\n",
    "    out=np.full_like(group_metrics_OL[group_name]['OmF_stdv'], np.nan, dtype=float),\n",
    "    where=group_metrics_OL[group_name]['OmF_stdv']!=0\n",
    ") * 100\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'(SSA_DA - CNTL) / CNTL OmF StdDev {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    cmin=-40,\n",
    "    cmax=40,\n",
    "    units='%'\n",
    ")\n",
    "fig.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}