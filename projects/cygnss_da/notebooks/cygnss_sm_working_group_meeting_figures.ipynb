{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from netCDF4 import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import sys;       sys.path.append('../util/shared/python/')\n",
    "from read_GEOSldas          import read_tilecoord, read_obs_param\n",
    "\n",
    "from mapper_functions import plot_aus_tight_pcm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_groups = {\n",
    "    \"SMOS\": [0, 1, 2, 3],\n",
    "    \"SMAP\": [4, 5, 6, 7],\n",
    "    \"ASCAT\": [8, 9, 10],\n",
    "    \"CYGNSS\": [11]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the OL data files\n",
    "\n",
    "stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_Aus/' \\\n",
    "'OLv8_M36_Aus/output/SMAP_EASEv2_M36_GLOBAL/figures/tmp_stats_OL_obsfrom_DA_20180801_20230801.nc4'\n",
    "\n",
    "print('reading stats nc4 file '+stats_file_OL)\n",
    "stats_OL = {}\n",
    "with Dataset(stats_file_OL,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_OL[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_OL = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_Aus/' \\\n",
    "'OLv8_M36_Aus/output/SMAP_EASEv2_M36_GLOBAL/figures/stats_OL_DA_Obs_from_DA_OLv8_M36_Aus_201808_202308.pkl'\n",
    "\n",
    "with open(ts_stats_file_OL, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_OL = loaded_data['stats_dict']\n",
    "date_vec_OL = loaded_data['date_vec']    \n",
    "date_vec = date_vec_OL    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the DA data files\n",
    "stats_file_DA = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_Aus_v3/' \\\n",
    "'DAv8_M36_Aus/output/SMAP_EASEv2_M36_GLOBAL/figures/tmp_stats_DA_20180801_20230801.nc4'\n",
    "print('reading stats nc4 file '+stats_file_DA)\n",
    "stats_DA = {}\n",
    "with Dataset(stats_file_DA,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_DA[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_DA = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_Aus_v3/' \\\n",
    "'DAv8_M36_Aus/output/SMAP_EASEv2_M36_GLOBAL/figures/stats_DAv8_M36_Aus_201808_202308.pkl'\n",
    "\n",
    "with open(ts_stats_file_DA, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_DA = loaded_data['stats_dict']\n",
    "date_vec_DA = loaded_data['date_vec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the OO data files (no bias correction for CYGNSS)\n",
    "\n",
    "stats_file_OO = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_Aus/' \\\n",
    "'OLv8_M36_Aus/output/SMAP_EASEv2_M36_GLOBAL/figures/tmp_stats_OL_20180801_20230801.nc4'\n",
    "\n",
    "print('reading stats nc4 file '+stats_file_OO)\n",
    "stats_OO = {}\n",
    "with Dataset(stats_file_OO,'r') as nc:\n",
    "    for key, value in nc.variables.items():\n",
    "        stats_OO[key] = value[:].filled(np.nan)\n",
    "\n",
    "ts_stats_file_OO = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_Aus/' \\\n",
    "'OLv8_M36_Aus/output/SMAP_EASEv2_M36_GLOBAL/figures/stats_OLv8_M36_Aus_201808_202308.pkl'\n",
    "\n",
    "with open(ts_stats_file_OO, 'rb') as f:\n",
    "    loaded_data = pickle.load(f)\n",
    "stats_dict_OO = loaded_data['stats_dict']\n",
    "date_vec_OO = loaded_data['date_vec']      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of final compuation of selected diagnostic metrics for OL\n",
    " \n",
    "Nmin = 20\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OL['N_data']\n",
    "O_mean = stats_OL['obs_mean']\n",
    "# mean(x-y) = E[x] - E[y]   \n",
    "OmF_mean = stats_OL['obs_mean'] - stats_OL['fcst_mean']\n",
    "OmA_mean = stats_OL['obs_mean'] - stats_OL['ana_mean']\n",
    "# var(x-y) = var(x) + var(y) - 2cov(x,y)\n",
    "# cov(x,y) = E[xy] - E[x]E[y]\n",
    "OmF_stdv  = np.sqrt(stats_OL['obs_variance'] + stats_OL['fcst_variance'] - \\\n",
    "                    2 * (stats_OL['oxf_mean'] - stats_OL['obs_mean']*stats_OL['fcst_mean']))\n",
    "                    \n",
    "OmA_stdv  = np.sqrt(stats_OL['obs_variance'] + stats_OL['ana_variance'] - \\\n",
    "                    2 * (stats_OL['oxa_mean'] - stats_OL['obs_mean']*stats_OL['ana_mean']))\n",
    "\n",
    " # \"fcstvar\" is assumed constant here for convenience. Modify if necessary\n",
    "OmF_norm_mean = OmF_mean / np.sqrt(stats_OL['obsvar_mean'] + stats_OL['fcstvar_mean']) \n",
    "OmF_norm_stdv = np.sqrt(OmF_stdv**2 / (stats_OL['obsvar_mean'] + stats_OL['fcstvar_mean']) )\n",
    "  \n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "\n",
    "OmF_mean_OL = OmF_mean\n",
    "OmF_stdv_OL = OmF_stdv\n",
    "OmF_norm_mean_OL = OmF_norm_mean\n",
    "OmF_norm_stdv_OL = OmF_norm_stdv\n",
    "OmA_mean_OL = OmA_mean\n",
    "OmA_stdv_OL = OmA_stdv\n",
    "N_data_OL = N_data\n",
    "\n",
    "group_metrics_OL = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OL[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_OL[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OL[group]['Nobs_data'] = group_N_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Sample of final compuation of selected diagnostic metrics for DA\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_DA['N_data']\n",
    "O_mean = stats_DA['obs_mean']\n",
    "# mean(x-y) = E[x] - E[y]\n",
    "OmF_mean = stats_DA['obs_mean'] - stats_DA['fcst_mean']\n",
    "OmA_mean = stats_DA['obs_mean'] - stats_DA['ana_mean']\n",
    "# var(x-y) = var(x) + var(y) - 2cov(x,y)\n",
    "# cov(x,y) = E[xy] - E[x]E[y]\n",
    "OmF_stdv  = np.sqrt(stats_DA['obs_variance'] + stats_DA['fcst_variance'] - \\\n",
    "                    2 * (stats_DA['oxf_mean'] - stats_DA['obs_mean']*stats_DA['fcst_mean']))\n",
    "OmA_stdv  = np.sqrt(stats_DA['obs_variance'] + stats_DA['ana_variance'] - \\\n",
    "                    2 * (stats_DA['oxa_mean'] - stats_DA['obs_mean']*stats_DA['ana_mean']))\n",
    "# \"fcstvar\" is assumed constant here for convenience. Modify if necessary\n",
    "OmF_norm_mean = OmF_mean / np.sqrt(stats_DA['obsvar_mean'] + stats_DA['fcstvar_mean'])\n",
    "OmF_norm_stdv = np.sqrt(OmF_stdv**2 / (stats_DA['obsvar_mean'] + stats_DA['fcstvar_mean']) )\n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "OmF_mean_DA = OmF_mean\n",
    "OmF_stdv_DA = OmF_stdv\n",
    "OmF_norm_mean_DA = OmF_norm_mean\n",
    "OmF_norm_stdv_DA = OmF_norm_stdv\n",
    "OmA_mean_DA = OmA_mean\n",
    "OmA_stdv_DA = OmA_stdv\n",
    "N_data_DA = N_data\n",
    "\n",
    "group_metrics_DA = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_DA[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_DA[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_DA[group]['Nobs_data'] = group_N_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample of final compuation of selected diagnostic metrics for OO (no bias correction for CYGNSS)\n",
    "\n",
    "# Then computer metrics of O-F, O-A, etc. based on above computed\n",
    "N_data = stats_OO['N_data']\n",
    "O_mean = stats_OO['obs_mean']\n",
    "# mean(x-y) = E[x] - E[y]\n",
    "OmF_mean = stats_OO['obs_mean'] - stats_OO['fcst_mean']\n",
    "OmA_mean = stats_OO['obs_mean'] - stats_OO['ana_mean']\n",
    "# var(x-y) = var(x) + var(y) - 2cov(x,y)\n",
    "# cov(x,y) = E[xy] - E[x]E[y]\n",
    "OmF_stdv  = np.sqrt(stats_OO['obs_variance'] + stats_OO['fcst_variance'] - \\\n",
    "                    2 * (stats_OO['oxf_mean'] - stats_OO['obs_mean']*stats_OO['fcst_mean']))\n",
    "OmA_stdv  = np.sqrt(stats_OO['obs_variance'] + stats_OO['ana_variance'] - \\\n",
    "                    2 * (stats_OO['oxa_mean'] - stats_OO['obs_mean']*stats_OO['ana_mean']))\n",
    "# \"fcstvar\" is assumed constant here for convenience. Modify if necessary\n",
    "OmF_norm_mean = OmF_mean / np.sqrt(stats_OO['obsvar_mean'] + stats_OO['fcstvar_mean'])\n",
    "OmF_norm_stdv = np.sqrt(OmF_stdv**2 / (stats_OO['obsvar_mean'] + stats_OO['fcstvar_mean']) )\n",
    "# Mask out data points with insufficent observations using the Nmin threshold\n",
    "# Do NOT apply to N_data\n",
    "OmF_mean[     N_data < Nmin] = np.nan\n",
    "OmF_stdv[     N_data < Nmin] = np.nan\n",
    "OmF_norm_mean[N_data < Nmin] = np.nan\n",
    "OmF_norm_stdv[N_data < Nmin] = np.nan\n",
    "OmA_mean[     N_data < Nmin] = np.nan\n",
    "OmA_stdv[     N_data < Nmin] = np.nan\n",
    "N_data[       N_data < Nmin] = 0\n",
    "OmF_mean_OO = OmF_mean\n",
    "OmF_stdv_OO = OmF_stdv\n",
    "OmF_norm_mean_OO = OmF_norm_mean\n",
    "OmF_norm_stdv_OO = OmF_norm_stdv\n",
    "OmA_mean_OO = OmA_mean\n",
    "OmA_stdv_OO = OmA_stdv\n",
    "N_data_OO = N_data\n",
    "\n",
    "group_metrics_OO = {}\n",
    "\n",
    "for group, species_indices in species_groups.items():\n",
    "    group_metrics_OO[group] = {}\n",
    "    group_N_data = np.nansum(N_data[:, species_indices], axis=1)\n",
    "    \n",
    "    group_metrics_OO[group]['OmF_mean'] = np.nansum(OmF_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OO[group]['OmF_stdv'] = np.nansum(OmF_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OO[group]['OmF_norm_mean'] = np.nansum(OmF_norm_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OO[group]['OmF_norm_stdv'] = np.nansum(OmF_norm_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OO[group]['OmA_mean'] = np.nansum(OmA_mean[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OO[group]['OmA_stdv'] = np.nansum(OmA_stdv[:, species_indices] * N_data[:, species_indices], axis=1) / group_N_data\n",
    "    group_metrics_OO[group]['Nobs_data'] = group_N_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ftc = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_Aus/' \\\n",
    "      'OLv8_M36_Aus/output/SMAP_EASEv2_M36_GLOBAL/figures/OLv8_M36_Aus.ldas_tilecoord.bin'\n",
    "tc = read_tilecoord(ftc)\n",
    "n_tile = tc['N_tile']\n",
    "lat = tc['com_lat']\n",
    "lon = tc['com_lon']\n",
    "\n",
    "map_array = np.empty([n_tile, 3])\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 1] = lon\n",
    "map_array[:, 2] = lat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for group in species_groups.keys():\n",
    "\n",
    "    group_name = group\n",
    "    map_array[:, 0] = group_metrics_OL[group_name]['Nobs_data']\n",
    "    # Get statistics\n",
    "    maxval = np.nanmax(map_array[:, 0])\n",
    "    minval = np.nanmin(map_array[:, 0])\n",
    "    # Plot group map\n",
    "    plot_aus_tight_pcm(\n",
    "        map_array,\n",
    "        False,\n",
    "        True,\n",
    "        f'Ndata {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "        'count',\n",
    "        0,\n",
    "        3500\n",
    "    )\n",
    "\n",
    "\n",
    "group_name = 'SMOS'\n",
    "\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['Nobs_data']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'Ndata {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'count', \n",
    "    0, \n",
    "    1500\n",
    ")\n",
    "\n",
    "group_name = 'SMAP'\n",
    "\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['Nobs_data']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'Ndata {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'count', \n",
    "    0, \n",
    "    3500\n",
    ")\n",
    "\n",
    "group_name = 'ASCAT'\n",
    "\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['Nobs_data']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'Ndata {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'count', \n",
    "    0, \n",
    "    4000\n",
    ")\n",
    "\n",
    "group_name = 'CYGNSS'\n",
    "\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['Nobs_data']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "total_obs = np.nansum(map_array[:, 0])\n",
    "print(f'Total observations for {group_name}: {total_obs}')\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'Ndata {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'count', \n",
    "    0, \n",
    "    2500\n",
    ")\n",
    "\n",
    "denominator = group_metrics_DA['SMAP']['Nobs_data'] / 2\n",
    "map_array[:, 0] = ((group_metrics_DA['SMAP']['Nobs_data'] - group_metrics_DA['CYGNSS']['Nobs_data']) / denominator) *100\n",
    "\n",
    "map_array[:, 0] = ((group_metrics_DA['CYGNSS']['Nobs_data'] - (group_metrics_DA['SMAP']['Nobs_data'] / 2)) / denominator) * 100\n",
    "\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(CYGNSS - SMAP) / SMAP Ndata \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -100, \n",
    "    100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'CYGNSS'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OL[group_name]['OmF_mean']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL scaled OmF_mean {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'count', \n",
    "    -0.1, \n",
    "    0.1\n",
    ")\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL scaled OmF_mean {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'count', \n",
    "    -0.01, \n",
    "    0.01\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OO[group_name]['OmF_mean']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL not scaled OmF_mean {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'count', \n",
    "    -0.1, \n",
    "    0.1\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OO[group_name]['OmF_mean'] - group_metrics_OL[group_name]['OmF_mean']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'Difference {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'count', \n",
    "    -0.1, \n",
    "    0.1\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_mean']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA scaled OmF_mean {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'count', \n",
    "    -0.01, \n",
    "    0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_stats_dict_to_arrays(stats_dict):\n",
    "    \"\"\"Convert dictionary of lists to numpy arrays\"\"\"\n",
    "    array_dict = {}\n",
    "    \n",
    "    for key in stats_dict.keys():\n",
    "        # Convert list to array and reshape\n",
    "        array_dict[key] = np.array(stats_dict[key])\n",
    "        \n",
    "        # Check if we need to handle missing values (-- in data)\n",
    "        if isinstance(array_dict[key][0], (list, np.ndarray)):\n",
    "            # Replace '--' with np.nan\n",
    "            temp_array = []\n",
    "            for row in array_dict[key]:\n",
    "                cleaned_row = [np.nan if x == '--' else float(x) for x in row]\n",
    "                temp_array.append(cleaned_row)\n",
    "            array_dict[key] = np.array(temp_array)\n",
    "    \n",
    "    return array_dict\n",
    "\n",
    "# Convert dictionary\n",
    "stats_dict_DA_arrays = convert_stats_dict_to_arrays(stats_dict_DA)\n",
    "stats_dict_OL_arrays = convert_stats_dict_to_arrays(stats_dict_OL)\n",
    "stats_dict_OO_arrays = convert_stats_dict_to_arrays(stats_dict_OO)\n",
    "# Convert date vector to datetime objects\n",
    "date_vec_DA = [datetime.strptime(date, '%Y%m') for date in date_vec_DA]\n",
    "date_vec_OL = [datetime.strptime(date, '%Y%m') for date in date_vec_OL]\n",
    "date_vec_OO = [datetime.strptime(date, '%Y%m') for date in date_vec_OO]\n",
    "\n",
    "# Print first few dates to verify\n",
    "print(\"Sample dates:\", date_vec_DA[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_weighted_group_stats(stats_dict, species_groups):\n",
    "    \"\"\"Calculate weighted statistics for each group\"\"\"\n",
    "    \n",
    "    n_times = len(stats_dict['OmF_mean'])\n",
    "    stats = ['OmF_mean', 'OmF_stdv', 'OmA_mean', 'OmA_stdv']\n",
    "    \n",
    "    # Initialize output dictionary\n",
    "    group_stats = {}\n",
    "    for group in species_groups.keys():\n",
    "        group_stats[group] = {stat: np.zeros(n_times) for stat in stats}\n",
    "        group_stats[group]['Ndata'] = np.zeros(n_times)\n",
    "    \n",
    "    # Calculate weighted stats for each timestep\n",
    "    for t in range(n_times):\n",
    "        for group, indices in species_groups.items():\n",
    "            # Get weights for this group/time\n",
    "            weights = stats_dict['Ndata'][t, indices]\n",
    "            total_weight = np.sum(weights)\n",
    "            \n",
    "            if total_weight > 0:\n",
    "                # Calculate weighted statistics\n",
    "                for stat in stats:\n",
    "                    values = stats_dict[stat][t, indices]\n",
    "                    group_stats[group][stat][t] = np.average(values, weights=weights)\n",
    "                group_stats[group]['Ndata'][t] = total_weight\n",
    "            else:\n",
    "                # Set to NaN if no observations\n",
    "                for stat in stats:\n",
    "                    group_stats[group][stat][t] = np.nan\n",
    "                    \n",
    "    return group_stats\n",
    "\n",
    "# Calculate group means\n",
    "group_ts_DA = calculate_weighted_group_stats(stats_dict_DA_arrays, species_groups)\n",
    "group_ts_OL = calculate_weighted_group_stats(stats_dict_OL_arrays, species_groups)\n",
    "group_ts_OO = calculate_weighted_group_stats(stats_dict_OO_arrays, species_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"length of date_vec_DA\", len(date_vec_DA))\n",
    "print(\"length of date_vec\", len(date_vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each species\n",
    "for group in species_groups.keys():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot OmF_mean for OL and DA\n",
    "    mean_OL = np.nanmean(group_ts_OL[group]['OmF_mean'])\n",
    "    mean_DA = np.nanmean(group_ts_DA[group]['OmF_mean'])\n",
    "    \n",
    "    plt.plot(date_vec_DA, group_ts_OL[group]['OmF_mean'], '--', label=f'{group} OL (Mean: {mean_OL:.3f})')\n",
    "    plt.plot(date_vec_DA, group_ts_DA[group]['OmF_mean'], '-', label=f'{group} DA (Mean: {mean_DA:.3f})')\n",
    "    \n",
    "    # Add black dotted line for Y = 0\n",
    "    plt.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'O-F Mean for {group}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('O-F Mean')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set x-ticks to every 6 months\n",
    "    # Set x-ticks using datetime array\n",
    "    plt.xticks(date_vec_DA[::6], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot OmF_mean for OL and DA\n",
    "mean_OL = np.nanmean(group_ts_OL['CYGNSS']['OmF_mean'])\n",
    "mean_DA = np.nanmean(group_ts_DA['CYGNSS']['OmF_mean'])\n",
    "mean_OO = np.nanmean(group_ts_OO['CYGNSS']['OmF_mean'])\n",
    "\n",
    "plt.plot(date_vec_DA, group_ts_OL['CYGNSS']['OmF_mean'], '--', label=f'CYGNSS OL (Mean: {mean_OL:.3f})')\n",
    "plt.plot(date_vec_DA, group_ts_DA['CYGNSS']['OmF_mean'], '-', label=f'CYGNSS DA (Mean: {mean_DA:.3f})')\n",
    "plt.plot(date_vec_DA, group_ts_OO['CYGNSS']['OmF_mean'], '-', label=f'CYGNSS OL NS (Mean: {mean_OO:.3f})')\n",
    "\n",
    "# Add black dotted line for Y = 0\n",
    "plt.axhline(y=0, color='black', linestyle=':', linewidth=1)\n",
    "\n",
    "# Customize plot\n",
    "plt.title(f'O-F Mean for {group}')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('O-F Mean')\n",
    "plt.legend()\n",
    "\n",
    "# Set x-ticks to every 6 months\n",
    "# Set x-ticks using datetime array\n",
    "plt.xticks(date_vec_DA[::6], rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual plots for each species\n",
    "for group in species_groups.keys():\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Plot OmF_mean for OL and DA\n",
    "    mean_OL = np.nanmean(group_ts_OL[group]['OmF_stdv'])\n",
    "    mean_DA = np.nanmean(group_ts_DA[group]['OmF_stdv'])\n",
    "    \n",
    "    plt.plot(date_vec_DA, group_ts_OL[group]['OmF_stdv'], '--', label=f'{group} OL (Mean: {mean_OL:.3f})')\n",
    "    plt.plot(date_vec_DA, group_ts_DA[group]['OmF_stdv'], '-', label=f'{group} DA (Mean: {mean_DA:.3f})')\n",
    "    \n",
    "    # Customize plot\n",
    "    plt.title(f'O-F StdDev for {group}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('O-F StdDev')\n",
    "    plt.legend()\n",
    "    \n",
    "    # Set y-axis minimum to zero\n",
    "    # plt.ylim(bottom=0)\n",
    "    \n",
    "    # Set x-ticks using datetime array\n",
    "    plt.xticks(date_vec_DA[::6], rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'CYGNSS'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'm3 m-3', \n",
    "    0., \n",
    "    0.1\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'm3 m-3', \n",
    "    0., \n",
    "    0.1\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA - OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'm3 m-3', \n",
    "    -0.01, \n",
    "    0.01\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = ((group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']) / group_metrics_OL[group_name]['OmF_stdv']) * 100\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -30, \n",
    "    30\n",
    ")\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    True, \n",
    "    True, \n",
    "    'DA - CNTL: Î” Relative StdDev of CYGNSS SM OmF', \n",
    "    '%', \n",
    "    -30, \n",
    "    30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'SMAP'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    "    0., \n",
    "    25\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    "    0., \n",
    "    25\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA - OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    "    -2, \n",
    "    2\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = ((group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']) / group_metrics_OL[group_name]['OmF_stdv']) * 100\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -30, \n",
    "    30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'SMOS'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    "    0., \n",
    "    25\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    "    0., \n",
    "    25\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA - OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'K', \n",
    "    -2, \n",
    "    2\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = ((group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']) / group_metrics_OL[group_name]['OmF_stdv']) * 100\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -30, \n",
    "    30\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_name = 'ASCAT'\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'm3 m-3', \n",
    "    0., \n",
    "    0.1\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'm3 m-3', \n",
    "    0., \n",
    "    0.1\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'DA - OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    'm3 m-3', \n",
    "    -0.01, \n",
    "    0.01\n",
    ")\n",
    "\n",
    "# Set observation counts from stored metrics\n",
    "map_array[:, 0] = ((group_metrics_DA[group_name]['OmF_stdv'] - group_metrics_OL[group_name]['OmF_stdv']) / group_metrics_OL[group_name]['OmF_stdv']) * 100\n",
    "\n",
    "# Get statistics\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "plot_aus_tight_pcm(\n",
    "    map_array, \n",
    "    False, \n",
    "    True, \n",
    "    f'(DA - OL) / OL OmF_stdv {group_name} \\n (Max: {maxval:.3g} Min: {minval:.3g})', \n",
    "    '%', \n",
    "    -30, \n",
    "    30\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
