{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python 3.x\n",
    "# pip install numpy scipy xarray matplotlib netcdf4\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy.io import loadmat\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "from geospatial_plotting import plot_region, REGION_BOUNDS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- 1) paths ---------\n",
    "p_cntl = Path(\"../test_data/CYGNSS_Experiments/Evaluation/IVs/ASCL4_SMPL3_OLv8_M36_cd_TC_stats_201808_202405.mat\")\n",
    "p_da   = Path(\"../test_data/CYGNSS_Experiments/Evaluation/IVs/ASCL4_SMPL3_DAv8_M36_cd_TC_stats_201808_202405.mat\")\n",
    "\n",
    "# --------- 2) load .mat (squeeze to 1D vectors) ---------\n",
    "def _vec(x):\n",
    "    return np.asarray(x).squeeze()\n",
    "\n",
    "M0 = loadmat(p_cntl, squeeze_me=True, struct_as_record=False)\n",
    "M1 = loadmat(p_da,   squeeze_me=True, struct_as_record=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# expected vars: 'lons','lats','N_sm','Nmin','R2_TC_L3','R2_TC_ASC','R2_TC_mod',\n",
    "# 'sigma2_L3','sigma2_mod','sigma2_ASC','R_mod_L3','R_mod_ASC','R_ASC_L3',\n",
    "# 'C_L3_mod','C_mod_ASC','C_L3_ASC'\n",
    "\n",
    "def _vec(x): return np.asarray(x).squeeze()\n",
    "\n",
    "def grab(M, name):\n",
    "    if name not in M:\n",
    "        raise KeyError(f\"Missing '{name}' in file\")\n",
    "    return _vec(M[name])\n",
    "\n",
    "# --- grid shape from lons/lats ---\n",
    "lons = grab(M0, \"lons\")\n",
    "lats = grab(M0, \"lats\")\n",
    "\n",
    "if lons.ndim == 2 and lats.ndim == 2:\n",
    "    shp = lons.shape  # (nlon, nlat)\n",
    "else:\n",
    "    # If saved flat, set to your grid dims and reshape\n",
    "    nlon, nlat = 406, 964\n",
    "    shp = (nlon, nlat)\n",
    "    lons = lons.reshape(shp)\n",
    "    lats = lats.reshape(shp)\n",
    "\n",
    "# Helpers to coerce arrays to 2D grid\n",
    "def as_grid(M, key, shp):\n",
    "    a = grab(M, key)\n",
    "    if a.ndim == 2 and a.shape == shp:\n",
    "        return a\n",
    "    if a.size == np.prod(shp):\n",
    "        return a.reshape(shp)\n",
    "    # Some MATLAB saves may come as (nlat, nlon); handle simple transpose case\n",
    "    if a.ndim == 2 and a.shape == (shp[1], shp[0]):\n",
    "        return a.T\n",
    "    raise ValueError(f\"Field '{key}' has unexpected shape {a.shape}, cannot map to {shp}\")\n",
    "\n",
    "def get_fields(M, shp):\n",
    "    grid_keys = [\n",
    "        \"N_sm\",\n",
    "        \"R2_TC_L3\",\"R2_TC_ASC\",\"R2_TC_mod\",\n",
    "        \"sigma2_L3\",\"sigma2_mod\",\"sigma2_ASC\",\n",
    "        \"R_mod_L3\",\"R_mod_ASC\",\"R_ASC_L3\",\n",
    "        \"C_L3_mod\",\"C_mod_ASC\",\"C_L3_ASC\",\n",
    "    ]\n",
    "    out = {k: as_grid(M, k, shp) for k in grid_keys}\n",
    "    # Scalars\n",
    "    out[\"Nmin\"] = float(grab(M, \"Nmin\"))\n",
    "    return out\n",
    "\n",
    "S0 = get_fields(M0, shp)  # CNTL\n",
    "S1 = get_fields(M1, shp)  # CYG_DA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- 3) build common-valid mask ---------\n",
    "# same sampling threshold in both + all fields finite where needed\n",
    "Nmin = int(np.nanmax(S0[\"Nmin\"]))  # should be same value\n",
    "Mvalid = (\n",
    "    (S0[\"N_sm\"] >= Nmin) & (S1[\"N_sm\"] >= Nmin) &\n",
    "    np.isfinite(S0[\"R2_TC_mod\"]) & np.isfinite(S1[\"R2_TC_mod\"]) &\n",
    "    np.isfinite(S0[\"sigma2_mod\"]) & np.isfinite(S1[\"sigma2_mod\"])\n",
    ")\n",
    "\n",
    "# clamp any R2 slightly outside (0,1] due to rounding\n",
    "def clamp01(a):\n",
    "    out = a.copy()\n",
    "    out[(out <= 0) | (~np.isfinite(out))] = np.nan\n",
    "    out[out > 1] = 1.0\n",
    "    return out\n",
    "\n",
    "R2m0 = clamp01(S0[\"R2_TC_mod\"])\n",
    "R2m1 = clamp01(S1[\"R2_TC_mod\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- 4) compute metrics ---------\n",
    "# (a) change in R^2 (positive is better)\n",
    "dR2_mod = np.where(Mvalid, R2m1 - R2m0, np.nan)\n",
    "pct_R2 = np.where(Mvalid, 100.0*(R2m1/R2m0 - 1), np.nan)  # positive % is better\n",
    "\n",
    "def robust_sigma_t2(S, tol=1e-12, max_spread=50.0):\n",
    "    C_l3m  = S[\"C_L3_mod\"].astype(float)\n",
    "    C_ma   = S[\"C_mod_ASC\"].astype(float)\n",
    "    C_l3a  = S[\"C_L3_ASC\"].astype(float)\n",
    "\n",
    "    # three TC permutations for σ_t^2\n",
    "    s1 = (C_l3m * C_ma)  / C_l3a\n",
    "    s2 = (C_l3m * C_l3a) / C_ma\n",
    "    s3 = (C_ma  * C_l3a) / C_l3m\n",
    "    stack = np.stack([s1, s2, s3], 0)\n",
    "\n",
    "    # basic validity: finite and positive\n",
    "    valid = np.isfinite(stack) & (stack > tol)\n",
    "    sig_t2 = np.nanmedian(np.where(valid, stack, np.nan), axis=0)\n",
    "\n",
    "    # consistency check: drop pixels where permutations disagree wildly\n",
    "    smin = np.nanmin(np.where(valid, stack, np.nan), axis=0)\n",
    "    smax = np.nanmax(np.where(valid, stack, np.nan), axis=0)\n",
    "    spread = smax / smin\n",
    "    bad = (~np.isfinite(sig_t2)) | (sig_t2 <= tol) | (~np.isfinite(spread)) | (spread > max_spread)\n",
    "    sig_t2[bad] = np.nan\n",
    "    return sig_t2\n",
    "\n",
    "def direct_fMSE(S):\n",
    "    \"\"\"\n",
    "    Compute fractional MSE directly from TC covariances & error variances.\n",
    "    S must contain: 'sigma2_mod','sigma2_L3','sigma2_ASC',\n",
    "                    'C_L3_mod','C_mod_ASC','C_L3_ASC'\n",
    "    Returns: dict with fMSE_{mod,L3,ASC} and sigma_t2.\n",
    "    \"\"\"\n",
    "    C_L3_mod = S[\"C_L3_mod\"].astype(float)\n",
    "    C_mod_ASC= S[\"C_mod_ASC\"].astype(float)\n",
    "    C_L3_ASC = S[\"C_L3_ASC\"].astype(float)\n",
    "\n",
    "    # Truth (signal) variance from TC geometry\n",
    "    sigma_t2 = robust_sigma_t2(S)\n",
    "\n",
    "    bad = (~np.isfinite(sigma_t2)) | (sigma_t2 <= 0)\n",
    "    fMSE_mod = np.full_like(sigma_t2, np.nan)\n",
    "    fMSE_L3  = np.full_like(sigma_t2, np.nan)\n",
    "    fMSE_ASC = np.full_like(sigma_t2, np.nan)\n",
    "\n",
    "    ok = ~bad\n",
    "    # Require finite σ² as well\n",
    "    ok_mod = ok & np.isfinite(S[\"sigma2_mod\"])\n",
    "    ok_L3  = ok & np.isfinite(S[\"sigma2_L3\"])\n",
    "    ok_ASC = ok & np.isfinite(S[\"sigma2_ASC\"])\n",
    "\n",
    "    fMSE_mod[ok_mod] = S[\"sigma2_mod\"][ok_mod] / sigma_t2[ok_mod]\n",
    "    fMSE_L3[ok_L3]   = S[\"sigma2_L3\"][ok_L3]   / sigma_t2[ok_L3]\n",
    "    fMSE_ASC[ok_ASC] = S[\"sigma2_ASC\"][ok_ASC] / sigma_t2[ok_ASC]\n",
    "\n",
    "    # Nonphysical negatives -> NaN\n",
    "    fMSE_mod[fMSE_mod < 0] = np.nan\n",
    "    fMSE_L3[fMSE_L3   < 0] = np.nan\n",
    "    fMSE_ASC[fMSE_ASC < 0] = np.nan\n",
    "\n",
    "    return dict(fMSE_mod=fMSE_mod, fMSE_L3=fMSE_L3, fMSE_ASC=fMSE_ASC, sigma_t2=sigma_t2)\n",
    "\n",
    "\n",
    "def fMSE_from_R2(R2):\n",
    "    fm = (1 - R2) / R2\n",
    "    fm[(~np.isfinite(fm)) | (fm < 0)] = np.nan\n",
    "    return fm\n",
    "\n",
    "# Example usage on your loaded fields S0/S1 (CNTL/DA):\n",
    "direct0 = direct_fMSE(S0); direct1 = direct_fMSE(S1)\n",
    "fMSE0_R2 = fMSE_from_R2(S0[\"R2_TC_mod\"])\n",
    "diff_check = np.nanmax(np.abs(direct0[\"fMSE_mod\"] - fMSE0_R2))\n",
    "print(\"max |direct - via R2|:\", diff_check)\n",
    "\n",
    "\n",
    "# fMSE0 = fMSE_from_R2(R2m0)\n",
    "# fMSE1 = fMSE_from_R2(R2m1)\n",
    "# dfMSE = np.where(Mvalid, fMSE1 - fMSE0, np.nan)              # negative is good\n",
    "# pct_fMSE = np.where(Mvalid, 100.0*(fMSE1/fMSE0 - 1), np.nan) # negative % is good\n",
    "\n",
    "# Direct fMSE from TC covariances\n",
    "direct0 = direct_fMSE(S0)   # CNTL\n",
    "direct1 = direct_fMSE(S1)   # CYG_DA\n",
    "\n",
    "fMSE0 = direct0[\"fMSE_mod\"]\n",
    "fMSE1 = direct1[\"fMSE_mod\"]\n",
    "\n",
    "# Valid where both runs have finite fMSE and you already had Nmin, etc.\n",
    "Mvalid_fmse = Mvalid & np.isfinite(fMSE0) & np.isfinite(fMSE1)\n",
    "\n",
    "dfMSE = np.full_like(fMSE0, np.nan)\n",
    "dfMSE[Mvalid_fmse] = fMSE1[Mvalid_fmse] - fMSE0[Mvalid_fmse]      # negative is good\n",
    "\n",
    "pct_fMSE = np.full_like(fMSE0, np.nan)\n",
    "ratio = np.full_like(fMSE0, np.nan)\n",
    "ratio[Mvalid_fmse] = fMSE1[Mvalid_fmse] / fMSE0[Mvalid_fmse]\n",
    "pct_fMSE[Mvalid_fmse] = 100.0 * (ratio[Mvalid_fmse] - 1.0)        # negative % is good\n",
    "\n",
    "# (c) change in model error variance (σ^2_mod) and % change\n",
    "sig20 = S0[\"sigma2_mod\"]; sig21 = S1[\"sigma2_mod\"]\n",
    "dsig2 = np.where(Mvalid, sig21 - sig20, np.nan)                  # negative is good\n",
    "\n",
    "# 1) mask tiny baseline sigma2 before % change\n",
    "p10 = np.nanpercentile(sig20, 10)\n",
    "baseline_floor = max(1e-8, p10)\n",
    "good_base = Mvalid & np.isfinite(sig20) & (sig20 > baseline_floor)\n",
    "\n",
    "pct_sig2 = np.full_like(sig20, np.nan)\n",
    "pct_sig2[good_base] = 100.0 * (sig21[good_base]/sig20[good_base] - 1.0)\n",
    "\n",
    "# 2) Robust summaries (don’t use mean±std)\n",
    "def robust_summary(a, m):\n",
    "    x = a[m & np.isfinite(a)]\n",
    "    if x.size == 0: return {\"median\": np.nan, \"IQR\": np.nan, \"n\": 0, \"improved_frac\": np.nan}\n",
    "    q25, q50, q75 = np.nanpercentile(x, [25, 50, 75])\n",
    "    return {\n",
    "        \"median\": float(q50),\n",
    "        \"IQR\": float(q75 - q25),\n",
    "        \"n\": int(x.size),\n",
    "        \"improved_frac\": float(np.nanmean((x < 0)))  # negative % = reduction\n",
    "    }\n",
    "\n",
    "summ_pct = robust_summary(pct_sig2, good_base)\n",
    "summ_dR2 = robust_summary(dR2_mod, Mvalid)\n",
    "\n",
    "print(\"ΔR²_mod  (median, IQR):\", summ_dR2[\"median\"], summ_dR2[\"IQR\"])\n",
    "print(\"Fraction tiles with R² improved:\", 1 - summ_dR2[\"improved_frac\"])\n",
    "print(\"%Δσ²_mod (median, IQR):\", summ_pct[\"median\"], summ_pct[\"IQR\"])\n",
    "print(\"Fraction tiles with σ² reduced:\", summ_pct[\"improved_frac\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- 5) quick global summaries ---------\n",
    "def masked_stats(arr, mask):\n",
    "    x = arr[mask & np.isfinite(arr)]\n",
    "    if x.size == 0:\n",
    "        return dict(mean=np.nan, median=np.nan, n=0)\n",
    "    return dict(mean=float(np.nanmean(x)), median=float(np.nanmedian(x)), n=int(x.size))\n",
    "\n",
    "summ = {\n",
    "    \"dR2_mod\": masked_stats(dR2_mod, Mvalid),\n",
    "    \"dfMSE\": masked_stats(dfMSE, Mvalid),\n",
    "    \"pct_fMSE\": masked_stats(pct_fMSE, Mvalid),\n",
    "    \"dsig2\": masked_stats(dsig2, Mvalid),\n",
    "    \"pct_sig2\": masked_stats(pct_sig2, Mvalid),\n",
    "    \"frac_tiles_improved_R2\": float(np.nanmean((dR2_mod > 0)[Mvalid])),\n",
    "    \"frac_tiles_improved_sig2\": float(np.nanmean((dsig2 < 0)[Mvalid])),\n",
    "}\n",
    "\n",
    "print(\"Global summaries:\", summ)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --------- 6) pack to xarray Dataset (easier to save/plot) ---------\n",
    "ds = xr.Dataset(\n",
    "    {\n",
    "        \"R2_mod_CNTL\": ((\"lon\",\"lat\"), R2m0),\n",
    "        \"R2_mod_DA\":   ((\"lon\",\"lat\"), R2m1),\n",
    "        \"dR2_mod\":     ((\"lon\",\"lat\"), dR2_mod),\n",
    "\n",
    "        \"fMSE_CNTL\":   ((\"lon\",\"lat\"), fMSE0),\n",
    "        \"fMSE_DA\":     ((\"lon\",\"lat\"), fMSE1),\n",
    "        \"dfMSE\":       ((\"lon\",\"lat\"), dfMSE),\n",
    "        \"pct_fMSE\":    ((\"lon\",\"lat\"), pct_fMSE),\n",
    "\n",
    "        \"sigma2_CNTL\": ((\"lon\",\"lat\"), sig20),\n",
    "        \"sigma2_DA\":   ((\"lon\",\"lat\"), sig21),\n",
    "        \"dsigma2\":     ((\"lon\",\"lat\"), dsig2),\n",
    "        \"pct_sigma2\":  ((\"lon\",\"lat\"), pct_sig2),\n",
    "\n",
    "        \"N_sm_CNTL\":   ((\"lon\",\"lat\"), S0[\"N_sm\"]),\n",
    "        \"N_sm_DA\":     ((\"lon\",\"lat\"), S1[\"N_sm\"]),\n",
    "        \"valid_mask\":  ((\"lon\",\"lat\"), Mvalid),\n",
    "    },\n",
    "    coords={\"lon\": ((\"lon\",\"lat\"), lons), \"lat\": ((\"lon\",\"lat\"), lats)},\n",
    "    attrs={\"note\": \"TC-based DA impact metrics (CNTL vs CYG_DA). Positive dR2_mod is improvement; negative dfMSE/pct_sigma2 is improvement.\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_array = np.full((lons.size, 3), np.nan)\n",
    "map_array[:, 1] = lons.flatten()\n",
    "map_array[:, 2] = lats.flatten()\n",
    "\n",
    "sig_cntl = S0[\"sigma2_mod\"].flatten()\n",
    "map_array[:, 0] = sig_cntl\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'CNTL Surface Soil Moisture Skill (σ²_mod) \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='-',\n",
    "    cmin=-0.00,\n",
    "    cmax=0.001\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "map_array = np.full((lons.size, 3), np.nan)\n",
    "map_array[:, 1] = lons.flatten()\n",
    "map_array[:, 2] = lats.flatten()\n",
    "\n",
    "\n",
    "\n",
    "dsig2_vec = dsig2.flatten()\n",
    "map_array[:, 0] = dsig2_vec\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'CYG_DA minus CNTL: Surface Soil Moisture Skill (Δ σ²_mod) \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='-',\n",
    "    cmin=-0.001,\n",
    "    cmax=0.001,\n",
    "    cmap='RdBu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pct_sig2_vec = pct_sig2.flatten()\n",
    "\n",
    "pct_sig2_plot = pct_sig2_vec.copy()\n",
    "\n",
    "lo, hi = np.nanpercentile(pct_sig2_vec, [1, 99])\n",
    "# pct_sig2_plot = np.clip(pct_sig2_vec, lo, hi)\n",
    "\n",
    "map_array[:, 0] = pct_sig2_plot\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'CYG_DA minus CNTL: Surface Soil Moisture Skill (% Δ σ²_mod) \\n (Median: {summ_pct[\"median\"]:.3g} IQR: {summ_pct[\"IQR\"]:.3g} Improved frac: {summ_pct[\"improved_frac\"]:.3g})',\n",
    "    units='%',\n",
    "    cmin=-100.0,\n",
    "    cmax=100.0,\n",
    "    cmap='RdBu_r'\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dR2_mod_vec = dR2_mod.flatten()\n",
    "map_array[:, 0] = dR2_mod_vec\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'CYG_DA minus CNTL: Surface Soil Moisture Skill (Δ R²_mod) \\n (Median: {summ_dR2[\"median\"]:.3g} IQR: {summ_dR2[\"IQR\"]:.3g} Improved frac: {1 -summ_dR2[\"improved_frac\"]:.3g})',\n",
    "    units='-',\n",
    "    cmin=-0.4,\n",
    "    cmax=0.4,\n",
    "    cmap='RdBu'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fraction_between_0_and_1(arr):\n",
    "    valid = np.isfinite(arr)  # Exclude NaN values\n",
    "    between_0_and_1 = (arr > 0) & (arr < 1)\n",
    "    return np.sum(between_0_and_1[valid]) / np.sum(valid)\n",
    "\n",
    "fractions = {\n",
    "    \"R2m0\": fraction_between_0_and_1(R2m0),\n",
    "    \"R2m1\": fraction_between_0_and_1(R2m1),\n",
    "    \"fMSE0\": fraction_between_0_and_1(fMSE0),\n",
    "    \"fMSE1\": fraction_between_0_and_1(fMSE1),\n",
    "    \"dR2_mod\": fraction_between_0_and_1(dR2_mod),\n",
    "    \"dfMSE\": fraction_between_0_and_1(dfMSE),\n",
    "    \"pct_fMSE\": fraction_between_0_and_1(pct_fMSE),\n",
    "    \"dsig2\": fraction_between_0_and_1(dsig2),\n",
    "    \"pct_sig2\": fraction_between_0_and_1(pct_sig2),\n",
    "}\n",
    "\n",
    "print(\"Fractions of elements between 0 and 1:\", fractions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma2_ASC = grab(M0, \"sigma2_ASC\")\n",
    "\n",
    "map_array[:, 0] = (np.sqrt(sigma2_ASC))\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'ASCAT Obs Err Std Dev \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='m3/m3',\n",
    "    cmin=0.00,\n",
    "    cmax=0.05\n",
    ")\n",
    "\n",
    "map_array[:, 0] = (np.sqrt(sigma2_ASC)) * 200\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'ASCAT Obs Err Std Dev \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='%',\n",
    "    cmin=0.00,\n",
    "    cmax=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "\n",
    "# Plot PDF/histogram of sqrt(sigma2_ASC)\n",
    "# Assumes `sigma2_ASC` and `plt` are available in the notebook namespace.\n",
    "\n",
    "sd = np.sqrt(sigma2_ASC)            # elementwise sqrt\n",
    "sd_valid = sd[np.isfinite(sd)]      # drop NaNs/infs\n",
    "\n",
    "# Optional: remove extreme outliers to focus plot (keep main bulk)\n",
    "sd_valid = sd_valid[sd_valid <= 0.5]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(sd_valid, bins=200, density=True, alpha=0.6, color=\"C0\", label=\"histogram\")\n",
    "\n",
    "# Overlay KDE if scipy is available\n",
    "try:\n",
    "    kde = gaussian_kde(sd_valid)\n",
    "    xs = np.linspace(np.nanmin(sd_valid), np.nanmax(sd_valid), 512)\n",
    "    plt.plot(xs, kde(xs), color=\"C1\", lw=1.5, label=\"KDE\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "plt.xlabel(\"Obs Err Std Dev (m3/m3)\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "# add mean and median to title (handle empty arrays)\n",
    "if sd_valid.size:\n",
    "    mean_sd = float(np.nanmean(sd_valid))\n",
    "    med_sd = float(np.nanmedian(sd_valid))\n",
    "    plt.title(f\"PDF of sqrt(sigma2_ASC) — mean={mean_sd:.3g}, median={med_sd:.3g}\")\n",
    "else:\n",
    "    plt.title(\"PDF of sqrt(sigma2_ASC) — no valid samples\")\n",
    "\n",
    "# Set x-limit to 99th percentile to avoid extreme tail stretch\n",
    "if sd_valid.size:\n",
    "    plt.xlim(0, float(np.nanpercentile(sd_valid, 99)))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Set x-limit to 99th percentile to avoid extreme tail stretch\n",
    "if sd_valid.size:\n",
    "    plt.xlim(0, float(np.nanpercentile(sd_valid, 99)))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_tc_obs   = Path(\"../test_data/CYGNSS_Experiments/Evaluation/IVs/ASCL4_SMPL3_CYGL3_OLv8_M36_cd_TC_stats_201808_202405.mat\")\n",
    "M2 = loadmat(p_tc_obs, squeeze_me=True, struct_as_record=False)\n",
    "\n",
    "# --- grid shape from lons/lats ---\n",
    "lons = grab(M2, \"lons\")\n",
    "lats = grab(M2, \"lats\")\n",
    "sigma2_CYG = grab(M2, \"sigma2_CYG\")\n",
    "sigma2_L3 = grab(M2, \"sigma2_L3\")\n",
    "sigma2_ASC = grab(M2, \"sigma2_ASC\")\n",
    "\n",
    "map_array = np.empty([len(lons), 3])\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 1] = lons\n",
    "map_array[:, 2] = lats\n",
    "\n",
    "map_array[:, 0] = np.sqrt(sigma2_CYG)\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'CYG L3 Obs Err Std Dev \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='m3/m3',\n",
    "    cmin=0.00,\n",
    "    cmax=0.05\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "map_array[:, 0] = np.sqrt(sigma2_L3)\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'SMAP L3 Obs Err Std Dev \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='m3/m3',\n",
    "    cmin=0.00,\n",
    "    cmax=0.05\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "map_array[:, 0] = (np.sqrt(sigma2_ASC))\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'ASCAT Obs (scaled) Err Std Dev \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='m3/m3',\n",
    "    cmin=0.00,\n",
    "    cmax=0.05\n",
    ")\n",
    "fig.tight_layout()\n",
    "\n",
    "map_array[:, 0] = (np.sqrt(sigma2_ASC)) * 200\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f'ASCAT Obs Err Std Dev \\n (Max: {maxval:.3g} Min: {minval:.3g})',\n",
    "    units='%',\n",
    "    cmin=0.00,\n",
    "    cmax=20.0\n",
    ")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sd = np.sqrt(sigma2_ASC)            # elementwise sqrt\n",
    "sd_valid = sd[np.isfinite(sd)]      # drop NaNs/infs\n",
    "\n",
    "# Optional: remove extreme outliers to focus plot (keep main bulk)\n",
    "sd_valid = sd_valid[sd_valid <= 0.5]\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.hist(sd_valid, bins=200, density=True, alpha=0.6, color=\"C0\", label=\"histogram\")\n",
    "\n",
    "# Overlay KDE if scipy is available\n",
    "try:\n",
    "    kde = gaussian_kde(sd_valid)\n",
    "    xs = np.linspace(np.nanmin(sd_valid), np.nanmax(sd_valid), 512)\n",
    "    plt.plot(xs, kde(xs), color=\"C1\", lw=1.5, label=\"KDE\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "plt.xlabel(\"Obs Err Std Dev (m3/m3)\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "# add mean and median to title (handle empty arrays)\n",
    "if sd_valid.size:\n",
    "    mean_sd = float(np.nanmean(sd_valid))\n",
    "    med_sd = float(np.nanmedian(sd_valid))\n",
    "    plt.title(f\"PDF of sqrt(sigma2_ASC) — mean={mean_sd:.3g}, median={med_sd:.3g}\")\n",
    "else:\n",
    "    plt.title(\"PDF of sqrt(sigma2_ASC) — no valid samples\")\n",
    "\n",
    "# Set x-limit to 99th percentile to avoid extreme tail stretch\n",
    "if sd_valid.size:\n",
    "    plt.xlim(0, float(np.nanpercentile(sd_valid, 99)))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Set x-limit to 99th percentile to avoid extreme tail stretch\n",
    "if sd_valid.size:\n",
    "    plt.xlim(0, float(np.nanpercentile(sd_valid, 99)))\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the fMSE arrays and remove NaN values\n",
    "CYG_sd = np.sqrt(sigma2_CYG)\n",
    "SMP_sd = np.sqrt(sigma2_L3)\n",
    "\n",
    "CYG_sd_clean = CYG_sd[np.isfinite(CYG_sd)]\n",
    "SMP_sd_clean = SMP_sd[np.isfinite(SMP_sd)]\n",
    "\n",
    "# Replace any values greater than 0.5 with NaN\n",
    "CYG_sd_clean = CYG_sd_clean[CYG_sd_clean <= 0.5]\n",
    "SMP_sd_clean = SMP_sd_clean[SMP_sd_clean <= 0.5]\n",
    "\n",
    "# Plot histograms and KDEs\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(CYG_sd_clean, bins=200, kde=True, color='blue', label='CYG_sd', stat='density', alpha=0.6)\n",
    "sns.histplot(SMP_sd_clean, bins=200, kde=True, color='orange', label='SMP_sd', stat='density', alpha=0.6)\n",
    "\n",
    "plt.title('Probability Distributions of CYG_sd and SMP_sd')\n",
    "plt.xlabel('Obs Err Std Dev (m3/m3)')\n",
    "plt.ylabel('Density')\n",
    "plt.xlim(0, 0.1)  # Limit x-axis to focus on the main distribution\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/Evaluation/IVs/aridity_indices_model_net_rad_20180801_20240630.nc4\"\n",
    "\n",
    "# open dataset and inspect\n",
    "ds = xr.open_dataset(fn, decode_times=True)\n",
    "print(ds)                 # quick view of variables / coords\n",
    "print(\"time values:\", ds['time'].values)\n",
    "\n",
    "ai = ds['AI_clim'].values   # shape (tile,)\n",
    "lon = ds['lon'].isel(time=1).values                      # coords usually constant per tile\n",
    "lat = ds['lat'].isel(time=1).values\n",
    "title_time = \"Climatology\"\n",
    "\n",
    "print('max.min of lon, lat, ai:')\n",
    "print(np.nanmax(lon), np.nanmin(lon))\n",
    "print(np.nanmax(lat), np.nanmin(lat))\n",
    "print(np.nanmax(ai), np.nanmin(ai))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_flat = np.squeeze(ai)\n",
    "lon_flat = np.squeeze(lon)\n",
    "lat_flat = np.squeeze(lat)\n",
    "n = ai_flat.size\n",
    "\n",
    "map_array = np.empty((n, 3), dtype=float)\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 0] = ai_flat\n",
    "map_array[:, 1] = lon_flat\n",
    "map_array[:, 2] = lat_flat\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "print(f\"AI_clim {title_time} max {maxval:.3g} min {minval:.3g}\")\n",
    "\n",
    "# 21 bin edges (same thresholds as the legend)\n",
    "ai_edges = np.array([\n",
    "    0.00, 0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60,\n",
    "    0.70, 0.80, 0.90, 1.00, 1.10, 1.20, 1.30, 1.40,\n",
    "    1.50, 1.75, 2.00, 3.00, 5.00, 10.00\n",
    "])\n",
    "\n",
    "# --- Example usage with an array 'AI' (same shape as your map) --\n",
    "# Create a colormap with 20 colors (one for each bin)\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=False,\n",
    "    plot_title=f\"Mean Annual Aridity Index (P/PET) \\n  Max: {maxval:.3g} Min: {minval:.3g}\",\n",
    "    units='AI',\n",
    "    cmin=0,\n",
    "    cmax=0.6,\n",
    "    discrete_edges=ai_edges,     # <<< turn on discrete Spectral\n",
    "    base_cmap=\"Spectral\"\n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean_lai_clim from the dataset\n",
    "mean_lai_clim = ds['mean_lai_clim'].values  # shape (tile,)\n",
    "\n",
    "# Flatten and build map array expected by plot_region: columns [value, lon, lat]\n",
    "mean_lai_flat = np.squeeze(mean_lai_clim)\n",
    "map_array = np.empty((n, 3), dtype=float)\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 0] = mean_lai_flat\n",
    "map_array[:, 1] = lon_flat\n",
    "map_array[:, 2] = lat_flat\n",
    "\n",
    "# Calculate max and min values for the plot\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "print(f\"mean_lai_clim max {maxval:.3g} min {minval:.3g}\")\n",
    "\n",
    "# Plot the map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=False,\n",
    "    plot_title=f\"Mean Annual LAI \\n Max: {maxval:.3g} Min: {minval:.3g}\",\n",
    "    units='LAI',\n",
    "    cmin=0,\n",
    "    cmax=6,\n",
    "    cmap=\"YlGn\"\n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract max_lai_clim from the dataset\n",
    "max_lai_clim = ds['max_lai_clim'].values  # shape (tile,)\n",
    "\n",
    "# Flatten and build map array expected by plot_region: columns [value, lon, lat]\n",
    "max_lai_flat = np.squeeze(max_lai_clim)\n",
    "map_array = np.empty((n, 3), dtype=float)\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 0] = max_lai_flat\n",
    "map_array[:, 1] = lon_flat\n",
    "map_array[:, 2] = lat_flat\n",
    "\n",
    "# Calculate max and min values for the plot\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "print(f\"max_lai_clim max {maxval:.3g} min {minval:.3g}\")\n",
    "\n",
    "# Plot the map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=False,\n",
    "    plot_title=f\"Max LAI \\n Max: {maxval:.3g} Min: {minval:.3g}\",\n",
    "    units='LAI',\n",
    "    cmin=0,\n",
    "    cmax=6,\n",
    "    cmap=\"YlGn\"\n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract mean_greeness_clim from the dataset\n",
    "mean_greeness_clim = ds['mean_greeness_clim'].values  # shape (tile,)\n",
    "\n",
    "# Flatten and build map array expected by plot_region: columns [value, lon, lat]\n",
    "mean_greeness_flat = np.squeeze(mean_greeness_clim)\n",
    "map_array = np.empty((n, 3), dtype=float)\n",
    "map_array.fill(np.nan)\n",
    "map_array[:, 0] = mean_greeness_flat\n",
    "map_array[:, 1] = lon_flat\n",
    "map_array[:, 2] = lat_flat\n",
    "\n",
    "# Calculate max and min values for the plot\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "print(f\"mean_greeness_clim max {maxval:.3g} min {minval:.3g}\")\n",
    "\n",
    "# Plot the map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=False,\n",
    "    plot_title=f\"Mean Annual Greenness \\n Max: {maxval:.3g} Min: {minval:.3g}\",\n",
    "    units='Greenness',\n",
    "    cmin=0,\n",
    "    cmax=1,\n",
    "    cmap=\"Greens\"\n",
    ")\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/OLv8_M36_cd/OLv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/cat/ens_avg/expt_means_20180801_20240630.nc4\"\n",
    "\n",
    "# open dataset and inspect\n",
    "ds = xr.open_dataset(fn, decode_times=True)\n",
    "print(ds)                 # quick view of variables / coords\n",
    "print(\"Data variables in dataset:\", list(ds.data_vars))\n",
    "\n",
    "\n",
    "\n",
    "map_array[:,0] = ds['SFMC_mean'].values\n",
    "\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f\"Mean Surface SM (SFMC) \\n Max: {maxval:.3g} Min: {minval:.3g}\",\n",
    "    units='m3/m3',\n",
    "    cmin=0,\n",
    "    cmax=0.8,\n",
    "    cmap=\"YlGnBu\"\n",
    ")\n",
    "\n",
    "# and std dev\n",
    "map_array[:,0] = ds['SFMC_std'].values\n",
    "maxval = np.nanmax(map_array[:, 0])\n",
    "minval = np.nanmin(map_array[:, 0])\n",
    "# Plot group map\n",
    "fig, ax = plot_region(\n",
    "    map_array,\n",
    "    region_bounds=REGION_BOUNDS['cygnss'],\n",
    "    meanflag=True,\n",
    "    plot_title=f\"Std Dev Surface SM (SFMC) \\n Max: {maxval:.3g} Min: {minval:.3g}\",\n",
    "    units='m3/m3',\n",
    "    cmin=0,\n",
    "    cmax=0.12,\n",
    "    cmap=\"YlGnBu\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ...existing code...\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "# inputs expected in notebook namespace: lons_vec, lats_vec, lon_flat, lat_flat, pct_sig2_vec, sigma2_CYG\n",
    "# build points\n",
    "vec_pts = np.column_stack((np.ravel(lons_vec), np.ravel(lats_vec)))\n",
    "flat_pts = np.column_stack((np.ravel(lon_flat), np.ravel(lat_flat)))\n",
    "\n",
    "# build KDTree and query\n",
    "tree = cKDTree(vec_pts)\n",
    "dists, idx = tree.query(flat_pts, k=1)\n",
    "\n",
    "# tolerance (degrees). Adjust if needed.\n",
    "tol = 1e-4  # ~11 m at equator\n",
    "bad = np.where(dists > tol)[0]\n",
    "if bad.size:\n",
    "    print(f\"Warning: {bad.size} lon/lat pairs did not match within tol={tol} deg (max dist={dists.max():.6g}).\")\n",
    "    # Optionally inspect first few mismatches\n",
    "    for i in bad[:5]:\n",
    "        print(f\"  mismatch idx {i}: flat ({flat_pts[i,0]:.6f},{flat_pts[i,1]:.6f}) nearest vec_idx {idx[i]} vec ({vec_pts[idx[i],0]:.6f},{vec_pts[idx[i],1]:.6f}) dist={dists[i]:.6g}\")\n",
    "\n",
    "# idx are indices into the flattened lons_vec/lats_vec arrays\n",
    "idx = idx.astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "target_dR2 = np.ravel(dR2_mod_vec)[idx]\n",
    "target_dR2_name = \"Δ R²_mod (DA - CNTL)\"\n",
    "# Clip extreme outliers, keep between 1 and 99 percentiles\n",
    "p_low, p_high = np.nanpercentile(target_dR2, [1, 99])\n",
    "target_dR2 = np.where((target_dR2 < p_low) | (target_dR2 > p_high), np.nan, target_dR2)\n",
    "print(f\"target_dR2 clipped to 1-99% range: {p_low:.3g} to {p_high:.3g}\")\n",
    "\n",
    "target_pct_sig2 = np.ravel(pct_sig2_vec)[idx]\n",
    "target_pct_sig2_name = \"% Δ σ²_mod (DA vs CNTL)\"\n",
    "# Clip extreme outliers, keep between 1 and 99 percentiles\n",
    "p_low, p_high = np.nanpercentile(target_pct_sig2, [1, 99])\n",
    "target_pct_sig2 = np.where((target_pct_sig2 < p_low) | (target_pct_sig2 > p_high), np.nan, target_pct_sig2)\n",
    "print(f\"target_pct_sig2 clipped to 1-99% range: {p_low:.3g} to {p_high:.3g}\")\n",
    "\n",
    "pred_sigma2_CYG = np.ravel(sigma2_CYG)[idx]\n",
    "p_low, p_high = np.nanpercentile(pred_sigma2_CYG, [1, 99])\n",
    "pred_sigma2_CYG = np.where((pred_sigma2_CYG < p_low) | (pred_sigma2_CYG > p_high), np.nan, pred_sigma2_CYG)\n",
    "pred_sigma2_CYG_name = \"CYG L3 Obs Err Variance\"\n",
    "\n",
    "pred_ai = np.ravel(ai_flat)\n",
    "p_low, p_high = np.nanpercentile(pred_ai, [1, 99])\n",
    "pred_ai = np.where((pred_ai < p_low) | (pred_ai > p_high), np.nan, pred_ai)\n",
    "pred_ai_name = \"Aridity Index (P/PET)\"\n",
    "\n",
    "pred_mean_lai = np.ravel(mean_lai_flat)\n",
    "p_low, p_high = np.nanpercentile(pred_mean_lai, [1, 99])\n",
    "pred_mean_lai = np.where((pred_mean_lai < p_low) | (pred_mean_lai > p_high), np.nan, pred_mean_lai)\n",
    "pred_mean_lai_name = \"Mean Annual LAI (m2/m2)\"\n",
    "\n",
    "pred_mean_greeness = np.ravel(mean_greeness_flat)\n",
    "p_low, p_high = np.nanpercentile(pred_mean_greeness, [1, 99])\n",
    "pred_mean_greeness = np.where((pred_mean_greeness < p_low) | (pred_mean_greeness > p_high), np.nan, pred_mean_greeness)\n",
    "pred_mean_greeness_name = \"Mean Annual Greenness\"\n",
    "\n",
    "pred_mean_sm = np.ravel(ds['SFMC_mean'].values)\n",
    "p_low, p_high = np.nanpercentile(pred_mean_sm, [1, 99])\n",
    "pred_mean_sm = np.where((pred_mean_sm < p_low) | (pred_mean_sm > p_high), np.nan, pred_mean_sm)\n",
    "pred_mean_sm_name = \"Mean Surface SM (SFMC)\"\n",
    "\n",
    "pred_std_sm = np.ravel(ds['SFMC_std'].values)\n",
    "p_low, p_high = np.nanpercentile(pred_std_sm, [1, 99])\n",
    "pred_std_sm = np.where((pred_std_sm < p_low) | (pred_std_sm > p_high), np.nan, pred_std_sm)\n",
    "pred_std_sm_name = \"Std Dev Surface SM (SFMC)\"\n",
    "\n",
    "pred_sigma2_mod0 = np.ravel(S0['sigma2_mod'])[idx]\n",
    "p_low, p_high = np.nanpercentile(pred_sigma2_mod0, [1, 99])\n",
    "pred_sigma2_mod0 = np.where((pred_sigma2_mod0 < p_low) | (pred_sigma2_mod0 > p_high), np.nan, pred_sigma2_mod0)\n",
    "pred_sigma2_mod0_name = \"CNTL Model Error Variance\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def analyze_and_plot(pred_vec, pred_name, target, target_name, show=True):\n",
    "    pred_vec = np.asarray(pred_vec).ravel()\n",
    "    target = np.asarray(target).ravel()\n",
    "\n",
    "    if pred_vec.size != target.size:\n",
    "        print(f\"Size mismatch: target={target.size}, predictor '{pred_name}'={pred_vec.size}. Skipping.\")\n",
    "        return None\n",
    "\n",
    "    mask = np.isfinite(target) & np.isfinite(pred_vec)\n",
    "    if mask.sum() == 0:\n",
    "        print(f\"{pred_name}: no valid samples\")\n",
    "        return None\n",
    "\n",
    "    x = pred_vec[mask]\n",
    "    y = target[mask]\n",
    "\n",
    "    pear_r, pear_p = stats.pearsonr(x, y)\n",
    "    spear_r, spear_p = stats.spearmanr(x, y)\n",
    "    lm = stats.linregress(x, y)\n",
    "\n",
    "    result = {\n",
    "        \"n\": int(mask.sum()),\n",
    "        \"pearson_r\": float(pear_r), \"pearson_p\": float(pear_p),\n",
    "        \"spearman_r\": float(spear_r), \"spearman_p\": float(spear_p),\n",
    "        \"slope\": float(lm.slope), \"intercept\": float(lm.intercept),\n",
    "        \"lm_r\": float(lm.rvalue), \"lm_p\": float(lm.pvalue)\n",
    "    }\n",
    "\n",
    "    if show:\n",
    "        plt.figure(figsize=(5,4))\n",
    "        sns.scatterplot(x=x, y=y, s=10, alpha=0.4)\n",
    "        xs = np.linspace(np.nanmin(x), np.nanmax(x), 200)\n",
    "        plt.plot(xs, lm.intercept + lm.slope*xs, color=\"red\", linewidth=1)\n",
    "        plt.xlabel(pred_name)\n",
    "        plt.ylabel(target_name)\n",
    "        plt.title(f\"{pred_name} vs {target_name}\\ n={result['n']}  pearson r={pear_r:.2f} (p={pear_p:.2g})\")\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- bundle predictors ----\n",
    "predictors = [\n",
    "    (pred_sigma2_CYG,    pred_sigma2_CYG_name),\n",
    "    (pred_ai,            pred_ai_name),\n",
    "    (pred_mean_lai,      pred_mean_lai_name),\n",
    "    (pred_mean_greeness, pred_mean_greeness_name),\n",
    "    (pred_mean_sm,       pred_mean_sm_name),\n",
    "    (pred_std_sm,        pred_std_sm_name),\n",
    "    (pred_sigma2_mod0,   pred_sigma2_mod0_name),\n",
    "]\n",
    "\n",
    "# ---- bundle targets ----\n",
    "targets = [\n",
    "    (target_dR2,       target_dR2_name),\n",
    "    (target_pct_sig2,  target_pct_sig2_name),\n",
    "]\n",
    "\n",
    "# ---- run all pairs, no plots first (show=False), collect results ----\n",
    "rows = []\n",
    "for t_vec, t_name in targets:\n",
    "    for x_vec, x_name in predictors:\n",
    "        res = analyze_and_plot(x_vec, x_name, t_vec, t_name, show=False)\n",
    "        if res is None:\n",
    "            continue\n",
    "        rows.append({\n",
    "            \"target\": t_name,\n",
    "            \"predictor\": x_name,\n",
    "            **res\n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "\n",
    "# display a quick summary sorted by |Pearson r| within each target\n",
    "def summarize(df, target_name):\n",
    "    sub = df[df[\"target\"] == target_name].copy()\n",
    "    if sub.empty:\n",
    "        print(f\"No results for {target_name}\")\n",
    "        return sub\n",
    "    sub[\"abs_pearson_r\"] = sub[\"pearson_r\"].abs()\n",
    "    sub = sub.sort_values(\"abs_pearson_r\", ascending=False)\n",
    "    print(f\"\\n=== Summary for {target_name} (sorted by |Pearson r|) ===\")\n",
    "    print(sub[[\"predictor\",\"n\",\"pearson_r\",\"pearson_p\",\"spearman_r\",\"spearman_p\",\"slope\",\"intercept\"]])\n",
    "    return sub\n",
    "\n",
    "_ = summarize(results_df, target_dR2_name)\n",
    "_ = summarize(results_df, target_pct_sig2_name)\n",
    "\n",
    "# ---- (optional) make scatter plots for the top-K predictors per target ----\n",
    "TOP_K = 3\n",
    "for t_vec, t_name in targets:\n",
    "    sub = results_df[results_df[\"target\"] == t_name].copy()\n",
    "    if sub.empty:\n",
    "        continue\n",
    "    top_pred_names = sub.assign(abs_r=sub[\"pearson_r\"].abs()) \\\n",
    "                        .sort_values(\"abs_r\", ascending=False) \\\n",
    "                        .head(TOP_K)[\"predictor\"].tolist()\n",
    "    print(f\"\\nPlotting top {TOP_K} predictors for: {t_name}\")\n",
    "    for x_vec, x_name in predictors:\n",
    "        if x_name in top_pred_names:\n",
    "            analyze_and_plot(x_vec, x_name, t_vec, t_name, show=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def multivar_summary_np(target, target_name):\n",
    "    \"\"\"\n",
    "    Standardized (beta) coefficients and R^2 using only NumPy.\n",
    "    Z-scores X and y, solves least-squares, reports betas sorted by |beta|.\n",
    "    \"\"\"\n",
    "    # Build DataFrame (align NaNs)\n",
    "    df = pd.DataFrame({\n",
    "        \"target\": target,\n",
    "        \"CYG_errvar\": pred_sigma2_CYG,\n",
    "        \"CNTL_errvar\": pred_sigma2_mod0,\n",
    "        \"Greenness\": pred_mean_greeness,\n",
    "        \"LAI\": pred_mean_lai,\n",
    "        \"MeanSM\": pred_mean_sm,\n",
    "        \"StdSM\": pred_std_sm,\n",
    "        # add more predictors here if you want\n",
    "    }).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "\n",
    "    if df.empty:\n",
    "        print(f\"{target_name}: no valid rows\")\n",
    "        return None\n",
    "\n",
    "    y = df[\"target\"].values.astype(float)\n",
    "    X = df.drop(columns=[\"target\"]).values.astype(float)\n",
    "    names = df.drop(columns=[\"target\"]).columns.to_list()\n",
    "\n",
    "    # Z-score (standardize)\n",
    "    Xmean = np.nanmean(X, axis=0); Xstd = np.nanstd(X, axis=0, ddof=0)\n",
    "    ymean = np.nanmean(y);         ystd = np.nanstd(y, ddof=0)\n",
    "\n",
    "    # guard against zero std\n",
    "    Xstd = np.where(Xstd == 0, 1.0, Xstd)\n",
    "    ystd = 1.0 if ystd == 0 else ystd\n",
    "\n",
    "    Xz = (X - Xmean) / Xstd\n",
    "    yz = (y - ymean) / ystd\n",
    "\n",
    "    # Least-squares: betas on standardized vars\n",
    "    # (no intercept needed because standardized)\n",
    "    betas, residuals, rank, s = np.linalg.lstsq(Xz, yz, rcond=None)\n",
    "\n",
    "    # R^2 on standardized variables\n",
    "    yhat = Xz @ betas\n",
    "    ss_res = np.sum((yz - yhat) ** 2)\n",
    "    ss_tot = np.sum((yz - yz.mean()) ** 2)  # yz.mean() ~ 0\n",
    "    r2 = 1.0 - ss_res / ss_tot if ss_tot > 0 else np.nan\n",
    "\n",
    "    out = pd.DataFrame({\"predictor\": names, \"std_beta\": betas})\n",
    "    out[\"abs_beta\"] = np.abs(out[\"std_beta\"])\n",
    "    out = out.sort_values(\"abs_beta\", ascending=False).drop(columns=\"abs_beta\")\n",
    "\n",
    "    print(f\"\\n{target_name}: standardized betas (abs-sorted), n={len(df)}, R²={r2:.3f}\")\n",
    "    print(out.to_string(index=False))\n",
    "    return out, r2\n",
    "\n",
    "_ = multivar_summary_np(target_dR2,      target_dR2_name)\n",
    "_ = multivar_summary_np(target_pct_sig2, target_pct_sig2_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys;       sys.path.append('../util/shared/python/')\n",
    "from read_GEOSldas          import read_tilecoord\n",
    "\n",
    "ftc = '/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/CYGNSS_Experiments/DAv8_M36_cd/' \\\n",
    "      'DAv8_M36_cd/output/SMAP_EASEv2_M36_GLOBAL/rc_out/DAv8_M36_cd.ldas_tilecoord.bin'\n",
    "tc = read_tilecoord(ftc)\n",
    "n_tile = tc['N_tile']\n",
    "com_lat = tc['com_lat']\n",
    "com_lon = tc['com_lon']\n",
    "tile_id = tc['tile_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "mosaic_path = \"/Users/amfox/Desktop/GEOSldas_diagnostics/test_data/mosaic_veg_typs_fracs\"\n",
    "tile_id = np.array(tile_id, dtype=int)   # your tiles\n",
    "\n",
    "# --- thresholds & codes ---\n",
    "PRIMARY_THRESH = 49.0\n",
    "BARE_MAX = 10.0          # total < 0.10  -> bare\n",
    "SPARSE_MAX = 20.0        # 0.10 <= total <= 0.20 -> sparse\n",
    "MIXED_MIN = 20.0         # total > 0.20 and primary <= 0.50 -> mixed\n",
    "\n",
    "BARE_CODE   = 0\n",
    "MIXED_CODE  = 7\n",
    "SPARSE_CODE = 8\n",
    "\n",
    "# --- read whitespace-delimited text file ---\n",
    "cols = [\"tile_index\",\"pfaf_code\",\"primary_veg_type\",\"secondary_veg_type\",\n",
    "        \"primary_veg_frac\",\"secondary_veg_frac\",\"canopy_height\",\"ASCATz0\"]\n",
    "\n",
    "records = []\n",
    "with open(mosaic_path, \"r\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        parts = line.split()\n",
    "        if len(parts) != 8:\n",
    "            parts = parts[-8:]  # keep the last 8 fields if a leading counter exists\n",
    "        ti, pf, pty, sty = map(int, parts[:4])\n",
    "        pfra, sfra, canh, z0 = map(float, parts[4:])\n",
    "        records.append((ti, pf, pty, sty, pfra, sfra, canh, z0))\n",
    "\n",
    "df = pd.DataFrame(records, columns=cols).set_index(\"tile_index\")\n",
    "\n",
    "# --- align to tile_id order ---\n",
    "sub = df.reindex(tile_id)\n",
    "\n",
    "p_type = sub[\"primary_veg_type\"].astype(\"float\")\n",
    "p_frac = sub[\"primary_veg_frac\"]\n",
    "s_frac = sub[\"secondary_veg_frac\"]\n",
    "tot_frac = p_frac + s_frac\n",
    "\n",
    "veg_code = np.full(len(sub), np.nan)\n",
    "\n",
    "# Rule A: bare if total < 0.10\n",
    "mask_bare = tot_frac < BARE_MAX\n",
    "veg_code[mask_bare] = BARE_CODE\n",
    "\n",
    "# Rule B: sparse if 0.10 <= total <= 0.20\n",
    "mask_sparse = (~mask_bare) & (tot_frac <= SPARSE_MAX)\n",
    "veg_code[mask_sparse] = SPARSE_CODE\n",
    "\n",
    "# Rule C: primary type if primary > 0.50 (and not bare/sparse)\n",
    "mask_primary = np.isnan(veg_code) & (p_frac > PRIMARY_THRESH)\n",
    "veg_code[mask_primary] = p_type[mask_primary]\n",
    "\n",
    "# Rule D: mixed if total > 0.20 and primary <= 0.50 (and not already set)\n",
    "mask_mixed = np.isnan(veg_code) & (tot_frac > MIXED_MIN) & (p_frac <= PRIMARY_THRESH)\n",
    "veg_code[mask_mixed] = MIXED_CODE\n",
    "\n",
    "# Fallback: any remaining (e.g., missing tiles) -> sparse (or choose another)\n",
    "veg_code[np.isnan(veg_code)] = SPARSE_CODE\n",
    "\n",
    "veg_type_out = veg_code.astype(int)\n",
    "total_fraction = tot_frac.fillna(0.0).to_numpy()\n",
    "\n",
    "# Outputs:\n",
    "#  - veg_type_out: integer array aligned with tile_id (1–6 from file, plus 7=mixed, 8=sparse, 0=bare)\n",
    "#  - total_fraction: float array aligned with tile_id (primary + secondary)\n",
    "\n",
    "print(len(veg_type_out), veg_type_out)\n",
    "\n",
    "print(\"minimum primary fraction:\", np.nanmin(p_frac))\n",
    "print(\"minimum primary + secondary fraction:\", np.nanmin(total_fraction))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "lat = np.asarray(com_lat)\n",
    "lon = np.asarray(com_lon)\n",
    "\n",
    "# bring longitudes to [-180, 180]\n",
    "lon = np.where(lon > 180.0, lon - 360.0, lon)\n",
    "\n",
    "# ---- labels for legend (codes from your mosaic definition + mixed/sparse/bare) ----\n",
    "label_map = {\n",
    "    0: \"Bare\",\n",
    "    1: \"Broadleaf Evergreen\",\n",
    "    2: \"Broadleaf Deciduous\",\n",
    "    3: \"Needleleaf\",\n",
    "    4: \"Grassland\",\n",
    "    5: \"Broadleaf Shrubs\",\n",
    "    6: \"Dwarf Trees\",\n",
    "    7: \"Mixed\",\n",
    "    8: \"Sparse\",\n",
    "}\n",
    "\n",
    "# only plot classes that appear\n",
    "classes_present = np.unique(veg_type_out[np.isfinite(veg_type_out)])\n",
    "\n",
    "# ---- figure ----\n",
    "proj = ccrs.PlateCarree()\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes(projection=proj)\n",
    "\n",
    "# set extent with small padding\n",
    "lat_min, lat_max = np.nanmin(lat), np.nanmax(lat)\n",
    "lon_min, lon_max = np.nanmin(lon), np.nanmax(lon)\n",
    "dlat = max(2.0, 0.05 * (lat_max - lat_min + 1e-6))\n",
    "dlon = max(2.0, 0.05 * (lon_max - lon_min + 1e-6))\n",
    "ax.set_extent([lon_min - dlon, lon_max + dlon, lat_min - dlat, lat_max + dlat], crs=proj)\n",
    "\n",
    "# map features\n",
    "ax.add_feature(cfeature.COASTLINE, linewidth=0.6)\n",
    "ax.add_feature(cfeature.BORDERS, linewidth=0.4)\n",
    "gl = ax.gridlines(draw_labels=True, x_inline=False, y_inline=False, linewidth=0.3)\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "# plot each class as its own scatter (lets Matplotlib assign distinct default colors)\n",
    "handles = []\n",
    "labels = []\n",
    "for code in classes_present:\n",
    "    mask = veg_type_out == code\n",
    "    if not np.any(mask):\n",
    "        continue\n",
    "    sc = ax.scatter(lon[mask], lat[mask], s=10, transform=proj, label=label_map.get(int(code), f\"Class {int(code)}\"))\n",
    "    handles.append(sc)\n",
    "    labels.append(label_map.get(int(code), f\"Class {int(code)}\"))\n",
    "\n",
    "# legend\n",
    "leg = ax.legend(handles, labels, title=\"Vegetation Type\", loc=\"lower left\", frameon=True, fontsize=8, title_fontsize=9)\n",
    "\n",
    "ax.set_title(\"Primary Vegetation Type (with Mixed/Sparse/Bare) for Experiment Tiles\", fontsize=12, pad=10)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def box_by_veg(y, yname):\n",
    "    label_map = {\n",
    "        0: \"Bare\", 1: \"Broadleaf Evergreen\", 2: \"Broadleaf Deciduous\",\n",
    "        3: \"Needleleaf\", 4: \"Grassland\", 5: \"Broadleaf Shrubs\",\n",
    "        6: \"Dwarf Trees\", 7: \"Mixed\", 8: \"Sparse\",\n",
    "    }\n",
    "    order = [1,2,3,4,5,6,7,8,0]  # tweak if you like\n",
    "    data, labels = [], []\n",
    "    for k in order:\n",
    "        sel = np.isfinite(veg_type_out) & (veg_type_out == k) & np.isfinite(y)\n",
    "        if sel.any():\n",
    "            data.append(y[sel])\n",
    "            labels.append(f\"{label_map[k]} (n={sel.sum():,})\")\n",
    "    plt.figure(figsize=(11,4))\n",
    "    plt.boxplot(data, labels=labels, showfliers=True)\n",
    "    plt.axhline(0, ls=\"--\", lw=1)\n",
    "    plt.title(yname)\n",
    "    plt.xticks(rotation=20, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "box_by_veg(target_dR2, target_dR2_name)\n",
    "box_by_veg(target_pct_sig2, target_pct_sig2_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs assumed to exist:\n",
    "#   pred_ai, pred_ai_name\n",
    "#   pred_mean_lai, pred_mean_lai_name\n",
    "#   pred_mean_greeness, pred_mean_greeness_name\n",
    "#   target_dR2, target_dR2_name\n",
    "#   target_pct_sig2, target_pct_sig2_name\n",
    "\n",
    "def bin_and_plot(predictor, predictor_name, targets, q=5, dropna=True,\n",
    "                 bins=None, labels=None, include_lowest=True, right=True):\n",
    "    \"\"\"\n",
    "    Bin a predictor and plot target distributions per bin.\n",
    "\n",
    "    If `bins` is provided (list-like), uses fixed bins via pd.cut.\n",
    "    Otherwise, uses quantile bins via pd.qcut with q quantiles.\n",
    "\n",
    "    targets = list of (target_array, target_name) tuples.\n",
    "    \"\"\"\n",
    "    # assemble DataFrame\n",
    "    df = pd.DataFrame({predictor_name: predictor})\n",
    "    for t_arr, t_name in targets:\n",
    "        df[t_name] = t_arr\n",
    "\n",
    "    # clean NaNs/infs\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    if dropna:\n",
    "        df = df.dropna(subset=[predictor_name])\n",
    "    if df.empty:\n",
    "        print(f\"{predictor_name}: no valid rows after dropna.\")\n",
    "        return\n",
    "\n",
    "    # choose binning method\n",
    "    if bins is not None:\n",
    "        # fixed bins\n",
    "        df[\"bin\"] = pd.cut(df[predictor_name], bins=bins, labels=labels,\n",
    "                           include_lowest=include_lowest, right=right)\n",
    "        bin_order = df[\"bin\"].cat.categories\n",
    "        bin_desc = f\"fixed bins ({len(bin_order)})\"\n",
    "    else:\n",
    "        # quantile bins; reduce q if duplicates happen\n",
    "        q_use = q\n",
    "        while True:\n",
    "            try:\n",
    "                df[\"bin\"] = pd.qcut(df[predictor_name], q=q_use, duplicates=\"drop\")\n",
    "                break\n",
    "            except ValueError:\n",
    "                q_use -= 1\n",
    "                if q_use < 2:\n",
    "                    df[\"bin\"] = pd.cut(df[predictor_name], bins=1)\n",
    "                    break\n",
    "        bin_order = df[\"bin\"].cat.categories\n",
    "        bin_desc = f\"quantile bins (q={q_use})\"\n",
    "\n",
    "    # per-target plots and summaries\n",
    "    for t_arr, t_name in targets:\n",
    "        desc = (df.groupby(\"bin\")[t_name]\n",
    "                  .agg(count=\"count\",\n",
    "                       median=lambda x: np.nanmedian(x),\n",
    "                       mean=\"mean\",\n",
    "                       std=\"std\",\n",
    "                       q25=lambda x: np.nanpercentile(x, 25),\n",
    "                       q75=lambda x: np.nanpercentile(x, 75)))\n",
    "        print(f\"\\n=== {t_name} by {predictor_name} {bin_desc} ===\")\n",
    "        print(desc)\n",
    "\n",
    "        # prepare boxplot data & labels\n",
    "        data, xlabels = [], []\n",
    "        for b in bin_order:\n",
    "            vals = df.loc[df[\"bin\"] == b, t_name].dropna().values\n",
    "            data.append(vals)\n",
    "            xlabels.append(f\"{b}\\n(n={len(vals):,})\")\n",
    "\n",
    "        # plot\n",
    "        plt.figure(figsize=(10, 4))\n",
    "        plt.boxplot(data, labels=xlabels, showfliers=True)\n",
    "        plt.axhline(0.0, ls=\"--\", lw=1)\n",
    "        plt.title(f\"{t_name} by {predictor_name} — {bin_desc}\")\n",
    "        plt.xticks(rotation=15, ha=\"right\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "     \n",
    "\n",
    "\n",
    "targets_list = [\n",
    "    (target_dR2, target_dR2_name),\n",
    "    (target_pct_sig2, target_pct_sig2_name),\n",
    "]\n",
    "\n",
    "# 1) LAI with *fixed* bins (rounded, physically meaningful)\n",
    "lai_bins   = [0.0, 0.10, 0.50, 1.30, 2.60, np.inf]\n",
    "lai_labels = [\"0–0.10\", \"0.10–0.50\", \"0.50–1.30\", \"1.30–2.60\", \">2.60\"]\n",
    "bin_and_plot(pred_mean_lai, pred_mean_lai_name, targets_list,\n",
    "             bins=lai_bins, labels=lai_labels)\n",
    "\n",
    "# 2) Greenness with quantiles (unchanged)\n",
    "bin_and_plot(pred_mean_greeness, pred_mean_greeness_name, targets_list, q=5)\n",
    "\n",
    "# 3) Aridity Index with quantiles (unchanged) or supply your own thresholds\n",
    "bin_and_plot(pred_ai, pred_ai_name, targets_list, q=5)\n",
    "# e.g., fixed AI bins:\n",
    "# ai_bins   = [0, 0.2, 0.5, 1.0, 2.0, np.inf]\n",
    "# ai_labels = [\"≤0.2\",\"0.2–0.5\",\"0.5–1.0\",\"1.0–2.0\",\">2.0\"]\n",
    "# bin_and_plot(pred_ai, pred_ai_name, targets_list, bins=ai_bins, labels=ai_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
